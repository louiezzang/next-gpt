{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louiezzang/next-gpt/blob/main/examples/chatgpt_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o5OIi7jDa9K"
      },
      "source": [
        "# Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TMz3aiLECTk"
      },
      "source": [
        "What is RLHF? <br>\n",
        "See [this link](https://gist.github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093).\n",
        "\n",
        "<br>\n",
        "\n",
        "**Example of RLHF dataset**:\n",
        "\n",
        "Total 3 datasets are needed for training the 3 steps(SFT, RM and PPO)\n",
        "- [Example of dataset](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama#dataset-preparation)\n",
        "- [Example of dataset 1](https://huggingface.co/datasets/stanfordnlp/SHP)\n",
        "- [Example of dataset 2](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n",
        "\n",
        "step1) Dataset for SFT(Supervised Fine-tuning training)\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion\": \"\"        \n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "\n",
        "step2) Dataset for RM(Reward Model) training: There are multiple completetions with human rated ranking score for one prompt.\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion_1\": \"\",\n",
        "        \"completion_2\": \"\",\n",
        "        \"completion_3\": \"\",            \n",
        "        \"ranking\": [1, 0, 2]\n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "    \n",
        "step3) Dataset for PPO(RLHF) training: It only consists of prompt.\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\"\n",
        "    }, ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_5Fvkx9fH0"
      },
      "source": [
        "# Environment setup\n",
        "\n",
        "#### Installation (python>=3.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdbMmQE5Zsjw",
        "outputId": "f3083e74-c9d1-45a3-fc96-14b838b849bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'next-gpt'...\n",
            "remote: Enumerating objects: 761, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 761 (delta 4), reused 10 (delta 4), pack-reused 745\u001b[K\n",
            "Receiving objects: 100% (761/761), 216.96 KiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (445/445), done.\n",
            "/content/next-gpt\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/next-gpt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (4.65.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loralib\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.136-py3-none-any.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 KB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (1.22.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (2023.3.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (1.4.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (9.0.0)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (1.4.47)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (8.2.2)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->next-gpt==1.0.0) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->next-gpt==1.0.0) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->next-gpt==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (1.26.15)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain->next-gpt==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->next-gpt==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->next-gpt==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->next-gpt==1.0.0) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: next-gpt\n",
            "  Building wheel for next-gpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for next-gpt: filename=next_gpt-1.0.0-py3-none-any.whl size=48856 sha256=555a950d135dc727796d586fde333ef4af887ab241296960ec8419fd7ea7b410\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/0d/a2/307ec9a6214260bfd63facee827d7bbef5c1ba9618277ea1b5\n",
            "Successfully built next-gpt\n",
            "Installing collected packages: tokenizers, xxhash, mypy-extensions, multidict, marshmallow, loralib, frozenlist, dill, async-timeout, yarl, typing-inspect, tiktoken, responses, openapi-schema-pydantic, multiprocess, marshmallow-enum, huggingface-hub, aiosignal, transformers, dataclasses-json, aiohttp, langchain, datasets, next-gpt\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.4 langchain-0.0.136 loralib-0.1.1 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 next-gpt-1.0.0 openapi-schema-pydantic-1.2.4 responses-0.18.0 tiktoken-0.3.3 tokenizers-0.13.3 transformers-4.27.4 typing-inspect-0.8.0 xxhash-3.2.0 yarl-1.8.2\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Install next-gpt lib.\n",
        "!rm -rf ./next-gpt/\n",
        "!git clone https://github.com/louiezzang/next-gpt.git\n",
        "%cd next-gpt/\n",
        "!pip install .\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JezJ8wz3_A7B"
      },
      "source": [
        "# Step 1) SFT: Surpervised Fine-tuning\n",
        "Build a Supervised Fine-tuning model to answer well to the question.\n",
        "\n",
        "- Refereneces\n",
        "  - [fine tuning code_1](https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb)\n",
        "  - [fine tuning code_2](https://github.com/Beomi/KoAlpaca/blob/main/train.py)\n",
        "\n",
        "\n",
        "- SFT(Supervised Fine Tuning)\n",
        "- Fine-tune a pretrained LLM on a specific domain or corpus of instructions and human demonstrations\n",
        "\n",
        "- Dataset example\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion\": \"\"        \n",
        "    }, ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpoPqaBfAkqW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import json\n",
        "import yaml\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import loralib as lora\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from nextgpt.dataset import SupervisedDataset, DataCollatorForSupervisedDataset\n",
        "from nextgpt.trainer import SFTTrainer\n",
        "from nextgpt.trainer.strategies import DDPStrategy, NaiveStrategy\n",
        "from nextgpt.models.bloom import BLOOMLM\n",
        "from nextgpt.models.gpt import GPTLM\n",
        "from nextgpt.models.opt import OPTLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = (\n",
        "  \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "  \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "  \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZhTIRVuOjjNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLJdNVzEsdJT",
        "outputId": "2a976c6a-512c-4380-f3a3-bbc59a89c5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(strategy='naive', model='gpt2', pretrain='gpt2', max_datasets_size=10000, need_optim_ckpt=False, max_epochs=3, batch_size=4, max_len=512, lora_rank=0, log_interval=100, lr=5e-06, accumulation_steps=8, output_dir='./output_1_sft')\n"
          ]
        }
      ],
      "source": [
        "# Define arguments.\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--strategy\",\n",
        "                    choices=[\"naive\", \"ddp\"],\n",
        "                    default=\"naive\")\n",
        "parser.add_argument(\"--model\", choices=[\"gpt2\", \"bloom\", \"opt\"], default=\"gpt2\")\n",
        "parser.add_argument(\"--pretrain\", type=str, default=None)\n",
        "parser.add_argument(\"--max_datasets_size\", type=int, default=None)\n",
        "parser.add_argument(\"--need_optim_ckpt\", type=bool, default=False)\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=3)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--max_len\", type=int, default=512)\n",
        "parser.add_argument(\"--lora_rank\", type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument(\"--log_interval\", type=int, default=100, help=\"how many steps to log\")\n",
        "parser.add_argument(\"--lr\", type=float, default=5e-6)\n",
        "parser.add_argument(\"--accumulation_steps\", type=int, default=8)\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"./output_1_sft\")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# For test.\n",
        "args.pretrain = \"gpt2\"\n",
        "args.max_datasets_size = 10000\n",
        "\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure strategy.\n",
        "if args.strategy == \"naive\":\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == \"ddp\":\n",
        "    strategy = DDPStrategy()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported strategy: {args.strategy}\")\n",
        "\n",
        "# Configure model.\n",
        "with strategy.model_init_context():\n",
        "    if args.model == \"bloom\":\n",
        "        model = BLOOMLM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    elif args.model == \"opt\":\n",
        "        model = OPTLM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    elif args.model == \"gpt2\":\n",
        "        model = GPTLM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {args.model}\")\n",
        "\n",
        "# Configure tokenizer.\n",
        "if args.model == \"gpt2\":\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "elif args.model == \"bloom\":\n",
        "    tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "elif args.model == \"opt\":\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported model: {args.model}\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Configure optimizer.\n",
        "optim = Adam(model.parameters(), lr=args.lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "23813f37715c4ad1b877a1d57e2d74a0",
            "a525a4474e0c4c549ef314a8a0998579",
            "973f1c072f864e70aae820df62223c81",
            "3e7620b80e5347ba9d5c0db86e5cbcee",
            "35e08fd17ceb42cf9341b011390c527d",
            "05f66a7767cd47599b23d400055c188e",
            "0f7d40c3ecd7415694916902ba5a2d24",
            "45e3e9be1e814326a96403066db9e719",
            "af494e8fd0ae44c0acc517fd127705f0",
            "efb3bba459904b5ab135e3f371ad945b",
            "c7974a3050cb4ba9ba046839bdbb8124",
            "7b0fa20cc654444395ef19521191e6ea",
            "1ba87586a8c54ac9a09a092c33f3d524",
            "4d4ef30aff9c447999ae5d9fbb494d72",
            "27f5be181eda4d03ab01d3ec20871420",
            "19be6f2114134623a7508be304fb82fd",
            "62db7ebafd4c49b2a0e97eab5aefe076",
            "7af0dda3eca44ebb90027753aa75d352",
            "98c3be5fc0bd4e688f4b4898b031365f",
            "e87f4d0735954ce1b6b9097291db59d8",
            "d5709d8bfd274098948c2c8437d1b40f",
            "33bf5c43a11047b7be33f272ea206888",
            "cf5d71dbf1e44166af41a21ff3aea166",
            "9c1e4fc7665a416a8fbd662a68901ec3",
            "5ee75301d35f43428caf99d01c46507f",
            "7739eea914e0413f9df74e05a81cb8e7",
            "38085f2e28b4406fb9b9296c94c37658",
            "f5eeaf36c58d40fd95d09de5d54d2247",
            "f413a7594fac48988540f9fd71f5a36e",
            "1e98d662ddfd41b9ad1ef1978e14a4a2",
            "3a3a636f66f0452299ad182d18e8be45",
            "62cea88a5a4d417db4e2a8f1f4b2e272",
            "59cfa7d1fd8b4b93860da3ea22f971f0",
            "ffaa26c17aa14a17a3760d321a243308",
            "871a2733046e4a78830dc08a3b2e5541",
            "8d6f43e221664f6ab72f8201786476c7",
            "6da3f0ccae9f4b0d8299e28fb40d4d10",
            "c6bda0b7bd2647c7aea05d22fd420631",
            "ccf407823e784af4a81848a224e27d0c",
            "c27aea12489a4404b34940a0e936af31",
            "a10e37e8a7214ef3bd57b7665b6aba2e",
            "b5c59ae222c14e79ad6157e8be795eaf",
            "e6b8b97908ea46e88550d27678d0e44d",
            "dbeb4457f83744b1b0674108816bfb14",
            "37963ae473be413d80eaca2d0fc0e3b9",
            "e9272fe6c83245198cf067f5078f52e5",
            "be10c88a890a49eb9f429c4b05cd8280",
            "a7d0e190aef44e948a3e26dac9b2b9c2",
            "7e3e477b8192403ba8785db528965e83",
            "12cd0199c4a948f4916906c0d0d155ca",
            "28fbee74c88f4c118be87cf7abe0c9ed",
            "d72e9bf58b6949c597f115972a5fddb9",
            "bf7f314ddef547abab08bbd45222256f",
            "f8f914b6c4514fb9bc143673c501e812",
            "59c0b87b451e401694c9c91dafb38a84"
          ]
        },
        "id": "jUPPbygUgtlY",
        "outputId": "517c8faa-3962-450c-be5f-0f2505d8648e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23813f37715c4ad1b877a1d57e2d74a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b0fa20cc654444395ef19521191e6ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf5d71dbf1e44166af41a21ff3aea166"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffaa26c17aa14a17a3760d321a243308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37963ae473be413d80eaca2d0fc0e3b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure dataset.\n",
        "dataset_webgpt_comp = load_dataset(\"openai/webgpt_comparisons\", split=\"train[:20%]\")\n",
        "\n",
        "data_list = []\n",
        "for row in dataset_webgpt_comp:\n",
        "    question = row[\"question\"][\"full_text\"]\n",
        "    answer_0 = row[\"answer_0\"]\n",
        "    data_list.append({\n",
        "        \"instruction\": question,\n",
        "        \"completion\": answer_0\n",
        "    })\n",
        "\n",
        "dataset = SupervisedDataset(\n",
        "    dataset=data_list,\n",
        "    tokenizer=tokenizer, \n",
        "    prompt_template=PROMPT_TEMPLATE,\n",
        "    completion_field=\"completion\",\n",
        "    max_datasets_size=args.max_datasets_size,\n",
        "    max_length=args.max_len,\n",
        "    verbose=True)\n",
        "\n",
        "# Split train and eval dataset.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "eval_size = len(dataset) - train_size\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, eval_size])\n",
        "\n",
        "# Data collator.\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391,
          "referenced_widgets": [
            "b3e584eb332d40e591bbd137425f7ca0",
            "faff620243a848fc8ea80641de803700",
            "033d650c770b422f978728f8fc2cbf91",
            "7ebd156d221b4583b1ad3dd91efb05d4",
            "ec6cd75ebbb24402ad67d240390ae440",
            "8f1c40904f5744a091553a178f115959",
            "777f0040704a4945ac4eec3a5521a44d",
            "81c88111208c405c9e232bced2ec62d6",
            "c4d4e21d5fd54105b1e9feefdc2ea86e",
            "d4536a268a194c3b83b39c8297e92b0c",
            "b58352f103ce401d95c02740dc051963",
            "a1bce7344b5243f6b720042e29fede12",
            "6d398abbda1341699a36a27538085e40",
            "22b5a1f2a1a84e13be0cc51e6f8dd397",
            "3fc2d8b9de7b443eae5c71c7d1c6c320",
            "1a3c90959c0442f8a327d4780940c956",
            "17daab5a62ef48668398f3d3751af932",
            "dbd1a3b7be4f4c1f9273f38fc6913ae3",
            "43b02cf02e8f436fa5192d987704f899",
            "265243c8b8ca41929c143f91909b8293",
            "90bf12470ac94f37b6547d5e7ced7728",
            "ee35e990aa644aa593362b60ce4b0261",
            "edcc21da1d8c41778e6b5eb9bada896f",
            "9d8223f11a59444287302b1b63cc3ce3",
            "0f9502e9597a4af1b4b84a08e140a20e",
            "c1c0e195b52b40649d421dc4ff81f036",
            "65c282bbe0e24a8b87aee6c84bc44fe8",
            "9fd60f15ea9c417e87dc284f253caa09",
            "9639d15f824744e8aa31b04561398566",
            "d0ac70ec3efd41c49b6e523ef7d53c2a",
            "9da26a42eb834054888d327198f64aaf",
            "74d9e5dc00204d728120a553a5d4e478",
            "879d9c536d7f42518668e7ea6ce56809",
            "f9caf69d54b54fc69831130181570f2b",
            "fd89bd3f2e2d448ea49de075ccb98a53",
            "761f682003fc4f5788409b3e37a5aed4",
            "8e4adfba7f6c4f5c94204848d6ca1cca",
            "a45bc9b1f5374b33a82aae809182ede1",
            "ffbbf097acac4a90ba2a90fd8d202099",
            "251663e256394491afd74fdfe0b102ff",
            "cc2279b8c57848e999bd0c7349877623",
            "1dd3e06c412f47c3b76fd70f70274efe",
            "036ad51ce40a4417bde64cbbc0f1c50e",
            "7e64a358d26744c880b0f711269e2faa"
          ]
        },
        "id": "62HB_iNujVAj",
        "outputId": "d48d2949-85f2-4d4a-a6c8-de191ccc6b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.74k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3e584eb332d40e591bbd137425f7ca0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1bce7344b5243f6b720042e29fede12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset webgpt_comparisons/default to /root/.cache/huggingface/datasets/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/279M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edcc21da1d8c41778e6b5eb9bada896f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9caf69d54b54fc69831130181570f2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset webgpt_comparisons downloaded and prepared to /root/.cache/huggingface/datasets/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a. Subsequent calls will reuse this data.\n",
            "Loading data...\n",
            "Limiting dataset to 10000 examples.\n",
            "Formatting inputs...\n",
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Voiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?\n",
            "\n",
            "### Response:\n",
            "The Simpsons character that was possibly based on Ted Koppel is Kent Brockman.  He is a local news anchor in Springfield and is modeled after Ted Koppel. [1]<|endoftext|>\n",
            "Tokenizing inputs... This may take some time...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confiture dataloader.\n",
        "if dist.is_initialized() and dist.get_world_size() > 1:\n",
        "    print(\"DDP\")\n",
        "    train_sampler = DistributedSampler(train_dataset,\n",
        "                                       shuffle=True,\n",
        "                                       seed=42,\n",
        "                                       drop_last=True,\n",
        "                                       rank=dist.get_rank(),\n",
        "                                       num_replicas=dist.get_world_size())\n",
        "    if eval_dataset is not None:\n",
        "        eval_sampler = DistributedSampler(eval_dataset,\n",
        "                                          shuffle=False,\n",
        "                                          seed=42,\n",
        "                                          drop_last=False,\n",
        "                                          rank=dist.get_rank(),\n",
        "                                          num_replicas=dist.get_world_size())\n",
        "else:\n",
        "    train_sampler = None\n",
        "    eval_sampler = None\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              shuffle=(train_sampler is None),\n",
        "                              sampler=train_sampler,\n",
        "                              batch_size=args.batch_size,\n",
        "                              collate_fn=data_collator,\n",
        "                              pin_memory=True)\n",
        "if eval_dataset is not None:\n",
        "    eval_dataloader = DataLoader(eval_dataset,\n",
        "                                 shuffle=(eval_sampler is None),\n",
        "                                 sampler=eval_sampler,\n",
        "                                 batch_size=args.batch_size,\n",
        "                                 collate_fn=data_collator,\n",
        "                                 pin_memory=True)\n",
        "else:\n",
        "    eval_dataloader = None"
      ],
      "metadata": {
        "id": "g_x_bbTPjT-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train!!!\n",
        "trainer = SFTTrainer(model=model,\n",
        "                     strategy=strategy,\n",
        "                     optim=optim,\n",
        "                     train_dataloader=train_dataloader,\n",
        "                     eval_dataloader=eval_dataloader,\n",
        "                     batch_size=args.batch_size,\n",
        "                     max_epochs=args.max_epochs,\n",
        "                     accumulation_steps=args.accumulation_steps)\n",
        "\n",
        "trainer.fit(logger=None, log_interval=args.log_interval)\n",
        "\n",
        "# Save model checkpoint after fitting on only rank0.\n",
        "trainer.save_model(path=args.output_dir, only_rank0=True, tokenizer=tokenizer)\n",
        "# Save optimizer checkpoint on all ranks.\n",
        "if args.need_optim_ckpt:\n",
        "    strategy.save_optimizer(trainer.optimizer,\n",
        "                            \"sft_optim_checkpoint_%d.pt\" % (torch.cuda.current_device()),\n",
        "                            only_rank0=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VutB4LDdkdRp",
        "outputId": "61d62de1-40ce-46f2-d7d5-ed627a033935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "steps:   0%|          | 0/291 [00:00<?, ?it/s]\u001b[A\n",
            "steps:   0%|          | 1/291 [00:01<07:01,  1.45s/it]\u001b[A\n",
            "steps:   0%|          | 1/291 [00:01<07:01,  1.45s/it, loss=0.401, lr=5.56e-7, epoch=0, batch_id=7]\u001b[A\n",
            "steps:   1%|          | 2/291 [00:02<04:53,  1.01s/it, loss=0.401, lr=5.56e-7, epoch=0, batch_id=7]\u001b[A\n",
            "steps:   1%|          | 2/291 [00:02<04:53,  1.01s/it, loss=0.391, lr=1.11e-6, epoch=0, batch_id=15]\u001b[A\n",
            "steps:   1%|          | 3/291 [00:02<04:08,  1.16it/s, loss=0.391, lr=1.11e-6, epoch=0, batch_id=15]\u001b[A\n",
            "steps:   1%|          | 3/291 [00:02<04:08,  1.16it/s, loss=0.391, lr=1.67e-6, epoch=0, batch_id=23]\u001b[A\n",
            "steps:   1%|▏         | 4/291 [00:03<03:51,  1.24it/s, loss=0.391, lr=1.67e-6, epoch=0, batch_id=23]\u001b[A\n",
            "steps:   1%|▏         | 4/291 [00:03<03:51,  1.24it/s, loss=0.411, lr=2.22e-6, epoch=0, batch_id=31]\u001b[A\n",
            "steps:   2%|▏         | 5/291 [00:04<03:39,  1.31it/s, loss=0.411, lr=2.22e-6, epoch=0, batch_id=31]\u001b[A\n",
            "steps:   2%|▏         | 5/291 [00:04<03:39,  1.31it/s, loss=0.411, lr=2.78e-6, epoch=0, batch_id=39]\u001b[A\n",
            "steps:   2%|▏         | 6/291 [00:05<03:39,  1.30it/s, loss=0.411, lr=2.78e-6, epoch=0, batch_id=39]\u001b[A\n",
            "steps:   2%|▏         | 6/291 [00:05<03:39,  1.30it/s, loss=0.371, lr=3.33e-6, epoch=0, batch_id=47]\u001b[A\n",
            "steps:   2%|▏         | 7/291 [00:05<03:37,  1.30it/s, loss=0.371, lr=3.33e-6, epoch=0, batch_id=47]\u001b[A\n",
            "steps:   2%|▏         | 7/291 [00:05<03:37,  1.30it/s, loss=0.382, lr=3.89e-6, epoch=0, batch_id=55]\u001b[A\n",
            "steps:   3%|▎         | 8/291 [00:06<03:31,  1.34it/s, loss=0.382, lr=3.89e-6, epoch=0, batch_id=55]\u001b[A\n",
            "steps:   3%|▎         | 8/291 [00:06<03:31,  1.34it/s, loss=0.392, lr=4.44e-6, epoch=0, batch_id=63]\u001b[A\n",
            "steps:   3%|▎         | 9/291 [00:07<03:29,  1.34it/s, loss=0.392, lr=4.44e-6, epoch=0, batch_id=63]\u001b[A\n",
            "steps:   3%|▎         | 9/291 [00:07<03:29,  1.34it/s, loss=0.402, lr=5e-6, epoch=0, batch_id=71]   \u001b[A\n",
            "steps:   3%|▎         | 10/291 [00:07<03:26,  1.36it/s, loss=0.402, lr=5e-6, epoch=0, batch_id=71]\u001b[A\n",
            "steps:   3%|▎         | 10/291 [00:07<03:26,  1.36it/s, loss=0.384, lr=5e-6, epoch=0, batch_id=79]\u001b[A\n",
            "steps:   4%|▍         | 11/291 [00:08<03:20,  1.40it/s, loss=0.384, lr=5e-6, epoch=0, batch_id=79]\u001b[A\n",
            "steps:   4%|▍         | 11/291 [00:08<03:20,  1.40it/s, loss=0.368, lr=5e-6, epoch=0, batch_id=87]\u001b[A\n",
            "steps:   4%|▍         | 12/291 [00:09<03:16,  1.42it/s, loss=0.368, lr=5e-6, epoch=0, batch_id=87]\u001b[A\n",
            "steps:   4%|▍         | 12/291 [00:09<03:16,  1.42it/s, loss=0.375, lr=5e-6, epoch=0, batch_id=95]\u001b[A\n",
            "steps:   4%|▍         | 13/291 [00:09<03:13,  1.44it/s, loss=0.375, lr=5e-6, epoch=0, batch_id=95]\u001b[A\n",
            "steps:   4%|▍         | 13/291 [00:09<03:13,  1.44it/s, loss=0.382, lr=5e-6, epoch=0, batch_id=103]\u001b[A\n",
            "steps:   5%|▍         | 14/291 [00:10<03:15,  1.41it/s, loss=0.382, lr=5e-6, epoch=0, batch_id=103]\u001b[A\n",
            "steps:   5%|▍         | 14/291 [00:10<03:15,  1.41it/s, loss=0.38, lr=5e-6, epoch=0, batch_id=111] \u001b[A\n",
            "steps:   5%|▌         | 15/291 [00:11<03:10,  1.45it/s, loss=0.38, lr=5e-6, epoch=0, batch_id=111]\u001b[A\n",
            "steps:   5%|▌         | 15/291 [00:11<03:10,  1.45it/s, loss=0.374, lr=4.99e-6, epoch=0, batch_id=119]\u001b[A\n",
            "steps:   5%|▌         | 16/291 [00:12<03:07,  1.47it/s, loss=0.374, lr=4.99e-6, epoch=0, batch_id=119]\u001b[A\n",
            "steps:   5%|▌         | 16/291 [00:12<03:07,  1.47it/s, loss=0.381, lr=4.99e-6, epoch=0, batch_id=127]\u001b[A\n",
            "steps:   6%|▌         | 17/291 [00:12<03:11,  1.43it/s, loss=0.381, lr=4.99e-6, epoch=0, batch_id=127]\u001b[A\n",
            "steps:   6%|▌         | 17/291 [00:12<03:11,  1.43it/s, loss=0.402, lr=4.99e-6, epoch=0, batch_id=135]\u001b[A\n",
            "steps:   6%|▌         | 18/291 [00:13<03:10,  1.44it/s, loss=0.402, lr=4.99e-6, epoch=0, batch_id=135]\u001b[A\n",
            "steps:   6%|▌         | 18/291 [00:13<03:10,  1.44it/s, loss=0.374, lr=4.99e-6, epoch=0, batch_id=143]\u001b[A\n",
            "steps:   7%|▋         | 19/291 [00:14<03:04,  1.47it/s, loss=0.374, lr=4.99e-6, epoch=0, batch_id=143]\u001b[A\n",
            "steps:   7%|▋         | 19/291 [00:14<03:04,  1.47it/s, loss=0.374, lr=4.98e-6, epoch=0, batch_id=151]\u001b[A\n",
            "steps:   7%|▋         | 20/291 [00:14<03:05,  1.46it/s, loss=0.374, lr=4.98e-6, epoch=0, batch_id=151]\u001b[A\n",
            "steps:   7%|▋         | 20/291 [00:14<03:05,  1.46it/s, loss=0.38, lr=4.98e-6, epoch=0, batch_id=159] \u001b[A\n",
            "steps:   7%|▋         | 21/291 [00:15<03:04,  1.46it/s, loss=0.38, lr=4.98e-6, epoch=0, batch_id=159]\u001b[A\n",
            "steps:   7%|▋         | 21/291 [00:15<03:04,  1.46it/s, loss=0.361, lr=4.98e-6, epoch=0, batch_id=167]\u001b[A\n",
            "steps:   8%|▊         | 22/291 [00:16<03:02,  1.48it/s, loss=0.361, lr=4.98e-6, epoch=0, batch_id=167]\u001b[A\n",
            "steps:   8%|▊         | 22/291 [00:16<03:02,  1.48it/s, loss=0.367, lr=4.97e-6, epoch=0, batch_id=175]\u001b[A\n",
            "steps:   8%|▊         | 23/291 [00:16<03:02,  1.47it/s, loss=0.367, lr=4.97e-6, epoch=0, batch_id=175]\u001b[A\n",
            "steps:   8%|▊         | 23/291 [00:16<03:02,  1.47it/s, loss=0.389, lr=4.97e-6, epoch=0, batch_id=183]\u001b[A\n",
            "steps:   8%|▊         | 24/291 [00:17<02:59,  1.49it/s, loss=0.389, lr=4.97e-6, epoch=0, batch_id=183]\u001b[A\n",
            "steps:   8%|▊         | 24/291 [00:17<02:59,  1.49it/s, loss=0.366, lr=4.97e-6, epoch=0, batch_id=191]\u001b[A\n",
            "steps:   9%|▊         | 25/291 [00:18<03:02,  1.45it/s, loss=0.366, lr=4.97e-6, epoch=0, batch_id=191]\u001b[A\n",
            "steps:   9%|▊         | 25/291 [00:18<03:02,  1.45it/s, loss=0.377, lr=4.96e-6, epoch=0, batch_id=199]\u001b[A\n",
            "steps:   9%|▉         | 26/291 [00:18<03:00,  1.47it/s, loss=0.377, lr=4.96e-6, epoch=0, batch_id=199]\u001b[A\n",
            "steps:   9%|▉         | 26/291 [00:18<03:00,  1.47it/s, loss=0.376, lr=4.96e-6, epoch=0, batch_id=207]\u001b[A\n",
            "steps:   9%|▉         | 27/291 [00:19<03:01,  1.45it/s, loss=0.376, lr=4.96e-6, epoch=0, batch_id=207]\u001b[A\n",
            "steps:   9%|▉         | 27/291 [00:19<03:01,  1.45it/s, loss=0.383, lr=4.95e-6, epoch=0, batch_id=215]\u001b[A\n",
            "steps:  10%|▉         | 28/291 [00:20<03:04,  1.42it/s, loss=0.383, lr=4.95e-6, epoch=0, batch_id=215]\u001b[A\n",
            "steps:  10%|▉         | 28/291 [00:20<03:04,  1.42it/s, loss=0.378, lr=4.94e-6, epoch=0, batch_id=223]\u001b[A\n",
            "steps:  10%|▉         | 29/291 [00:21<03:03,  1.43it/s, loss=0.378, lr=4.94e-6, epoch=0, batch_id=223]\u001b[A\n",
            "steps:  10%|▉         | 29/291 [00:21<03:03,  1.43it/s, loss=0.378, lr=4.94e-6, epoch=0, batch_id=231]\u001b[A\n",
            "steps:  10%|█         | 30/291 [00:21<03:06,  1.40it/s, loss=0.378, lr=4.94e-6, epoch=0, batch_id=231]\u001b[A\n",
            "steps:  10%|█         | 30/291 [00:21<03:06,  1.40it/s, loss=0.364, lr=4.93e-6, epoch=0, batch_id=239]\u001b[A\n",
            "steps:  11%|█         | 31/291 [00:22<03:11,  1.36it/s, loss=0.364, lr=4.93e-6, epoch=0, batch_id=239]\u001b[A\n",
            "steps:  11%|█         | 31/291 [00:22<03:11,  1.36it/s, loss=0.36, lr=4.93e-6, epoch=0, batch_id=247] \u001b[A\n",
            "steps:  11%|█         | 32/291 [00:23<03:04,  1.40it/s, loss=0.36, lr=4.93e-6, epoch=0, batch_id=247]\u001b[A\n",
            "steps:  11%|█         | 32/291 [00:23<03:04,  1.40it/s, loss=0.363, lr=4.92e-6, epoch=0, batch_id=255]\u001b[A\n",
            "steps:  11%|█▏        | 33/291 [00:23<02:59,  1.43it/s, loss=0.363, lr=4.92e-6, epoch=0, batch_id=255]\u001b[A\n",
            "steps:  11%|█▏        | 33/291 [00:23<02:59,  1.43it/s, loss=0.365, lr=4.91e-6, epoch=0, batch_id=263]\u001b[A\n",
            "steps:  12%|█▏        | 34/291 [00:24<02:59,  1.44it/s, loss=0.365, lr=4.91e-6, epoch=0, batch_id=263]\u001b[A\n",
            "steps:  12%|█▏        | 34/291 [00:24<02:59,  1.44it/s, loss=0.374, lr=4.9e-6, epoch=0, batch_id=271] \u001b[A\n",
            "steps:  12%|█▏        | 35/291 [00:25<02:56,  1.45it/s, loss=0.374, lr=4.9e-6, epoch=0, batch_id=271]\u001b[A\n",
            "steps:  12%|█▏        | 35/291 [00:25<02:56,  1.45it/s, loss=0.371, lr=4.9e-6, epoch=0, batch_id=279]\u001b[A\n",
            "steps:  12%|█▏        | 36/291 [00:25<02:56,  1.45it/s, loss=0.371, lr=4.9e-6, epoch=0, batch_id=279]\u001b[A\n",
            "steps:  12%|█▏        | 36/291 [00:25<02:56,  1.45it/s, loss=0.364, lr=4.89e-6, epoch=0, batch_id=287]\u001b[A\n",
            "steps:  13%|█▎        | 37/291 [00:26<02:59,  1.41it/s, loss=0.364, lr=4.89e-6, epoch=0, batch_id=287]\u001b[A\n",
            "steps:  13%|█▎        | 37/291 [00:26<02:59,  1.41it/s, loss=0.35, lr=4.88e-6, epoch=0, batch_id=295] \u001b[A\n",
            "steps:  13%|█▎        | 38/291 [00:27<02:57,  1.43it/s, loss=0.35, lr=4.88e-6, epoch=0, batch_id=295]\u001b[A\n",
            "steps:  13%|█▎        | 38/291 [00:27<02:57,  1.43it/s, loss=0.366, lr=4.87e-6, epoch=0, batch_id=303]\u001b[A\n",
            "steps:  13%|█▎        | 39/291 [00:28<03:01,  1.39it/s, loss=0.366, lr=4.87e-6, epoch=0, batch_id=303]\u001b[A\n",
            "steps:  13%|█▎        | 39/291 [00:28<03:01,  1.39it/s, loss=0.39, lr=4.86e-6, epoch=0, batch_id=311] \u001b[A\n",
            "steps:  14%|█▎        | 40/291 [00:28<03:01,  1.38it/s, loss=0.39, lr=4.86e-6, epoch=0, batch_id=311]\u001b[A\n",
            "steps:  14%|█▎        | 40/291 [00:28<03:01,  1.38it/s, loss=0.371, lr=4.85e-6, epoch=0, batch_id=319]\u001b[A\n",
            "steps:  14%|█▍        | 41/291 [00:29<02:55,  1.42it/s, loss=0.371, lr=4.85e-6, epoch=0, batch_id=319]\u001b[A\n",
            "steps:  14%|█▍        | 41/291 [00:29<02:55,  1.42it/s, loss=0.361, lr=4.84e-6, epoch=0, batch_id=327]\u001b[A\n",
            "steps:  14%|█▍        | 42/291 [00:30<02:55,  1.42it/s, loss=0.361, lr=4.84e-6, epoch=0, batch_id=327]\u001b[A\n",
            "steps:  14%|█▍        | 42/291 [00:30<02:55,  1.42it/s, loss=0.376, lr=4.83e-6, epoch=0, batch_id=335]\u001b[A\n",
            "steps:  15%|█▍        | 43/291 [00:30<02:58,  1.39it/s, loss=0.376, lr=4.83e-6, epoch=0, batch_id=335]\u001b[A\n",
            "steps:  15%|█▍        | 43/291 [00:30<02:58,  1.39it/s, loss=0.364, lr=4.82e-6, epoch=0, batch_id=343]\u001b[A\n",
            "steps:  15%|█▌        | 44/291 [00:31<02:54,  1.42it/s, loss=0.364, lr=4.82e-6, epoch=0, batch_id=343]\u001b[A\n",
            "steps:  15%|█▌        | 44/291 [00:31<02:54,  1.42it/s, loss=0.363, lr=4.81e-6, epoch=0, batch_id=351]\u001b[A\n",
            "steps:  15%|█▌        | 45/291 [00:32<02:52,  1.42it/s, loss=0.363, lr=4.81e-6, epoch=0, batch_id=351]\u001b[A\n",
            "steps:  15%|█▌        | 45/291 [00:32<02:52,  1.42it/s, loss=0.373, lr=4.8e-6, epoch=0, batch_id=359] \u001b[A\n",
            "steps:  16%|█▌        | 46/291 [00:33<02:50,  1.43it/s, loss=0.373, lr=4.8e-6, epoch=0, batch_id=359]\u001b[A\n",
            "steps:  16%|█▌        | 46/291 [00:33<02:50,  1.43it/s, loss=0.363, lr=4.79e-6, epoch=0, batch_id=367]\u001b[A\n",
            "steps:  16%|█▌        | 47/291 [00:33<02:52,  1.41it/s, loss=0.363, lr=4.79e-6, epoch=0, batch_id=367]\u001b[A\n",
            "steps:  16%|█▌        | 47/291 [00:33<02:52,  1.41it/s, loss=0.355, lr=4.78e-6, epoch=0, batch_id=375]\u001b[A\n",
            "steps:  16%|█▋        | 48/291 [00:34<02:51,  1.41it/s, loss=0.355, lr=4.78e-6, epoch=0, batch_id=375]\u001b[A\n",
            "steps:  16%|█▋        | 48/291 [00:34<02:51,  1.41it/s, loss=0.369, lr=4.77e-6, epoch=0, batch_id=383]\u001b[A\n",
            "steps:  17%|█▋        | 49/291 [00:35<02:58,  1.36it/s, loss=0.369, lr=4.77e-6, epoch=0, batch_id=383]\u001b[A\n",
            "steps:  17%|█▋        | 49/291 [00:35<02:58,  1.36it/s, loss=0.354, lr=4.76e-6, epoch=0, batch_id=391]\u001b[A\n",
            "steps:  17%|█▋        | 50/291 [00:35<02:51,  1.40it/s, loss=0.354, lr=4.76e-6, epoch=0, batch_id=391]\u001b[A\n",
            "steps:  17%|█▋        | 50/291 [00:35<02:51,  1.40it/s, loss=0.357, lr=4.74e-6, epoch=0, batch_id=399]\u001b[A\n",
            "steps:  18%|█▊        | 51/291 [00:36<02:53,  1.38it/s, loss=0.357, lr=4.74e-6, epoch=0, batch_id=399]\u001b[A\n",
            "steps:  18%|█▊        | 51/291 [00:36<02:53,  1.38it/s, loss=0.358, lr=4.73e-6, epoch=0, batch_id=407]\u001b[A\n",
            "steps:  18%|█▊        | 52/291 [00:37<02:50,  1.40it/s, loss=0.358, lr=4.73e-6, epoch=0, batch_id=407]\u001b[A\n",
            "steps:  18%|█▊        | 52/291 [00:37<02:50,  1.40it/s, loss=0.369, lr=4.72e-6, epoch=0, batch_id=415]\u001b[A\n",
            "steps:  18%|█▊        | 53/291 [00:38<02:47,  1.42it/s, loss=0.369, lr=4.72e-6, epoch=0, batch_id=415]\u001b[A\n",
            "steps:  18%|█▊        | 53/291 [00:38<02:47,  1.42it/s, loss=0.374, lr=4.71e-6, epoch=0, batch_id=423]\u001b[A\n",
            "steps:  19%|█▊        | 54/291 [00:38<02:45,  1.43it/s, loss=0.374, lr=4.71e-6, epoch=0, batch_id=423]\u001b[A\n",
            "steps:  19%|█▊        | 54/291 [00:38<02:45,  1.43it/s, loss=0.36, lr=4.69e-6, epoch=0, batch_id=431] \u001b[A\n",
            "steps:  19%|█▉        | 55/291 [00:39<02:45,  1.43it/s, loss=0.36, lr=4.69e-6, epoch=0, batch_id=431]\u001b[A\n",
            "steps:  19%|█▉        | 55/291 [00:39<02:45,  1.43it/s, loss=0.343, lr=4.68e-6, epoch=0, batch_id=439]\u001b[A\n",
            "steps:  19%|█▉        | 56/291 [00:40<02:44,  1.43it/s, loss=0.343, lr=4.68e-6, epoch=0, batch_id=439]\u001b[A\n",
            "steps:  19%|█▉        | 56/291 [00:40<02:44,  1.43it/s, loss=0.358, lr=4.67e-6, epoch=0, batch_id=447]\u001b[A\n",
            "steps:  20%|█▉        | 57/291 [00:40<02:45,  1.42it/s, loss=0.358, lr=4.67e-6, epoch=0, batch_id=447]\u001b[A\n",
            "steps:  20%|█▉        | 57/291 [00:40<02:45,  1.42it/s, loss=0.36, lr=4.65e-6, epoch=0, batch_id=455] \u001b[A\n",
            "steps:  20%|█▉        | 58/291 [00:41<02:45,  1.41it/s, loss=0.36, lr=4.65e-6, epoch=0, batch_id=455]\u001b[A\n",
            "steps:  20%|█▉        | 58/291 [00:41<02:45,  1.41it/s, loss=0.382, lr=4.64e-6, epoch=0, batch_id=463]\u001b[A\n",
            "steps:  20%|██        | 59/291 [00:42<02:42,  1.43it/s, loss=0.382, lr=4.64e-6, epoch=0, batch_id=463]\u001b[A\n",
            "steps:  20%|██        | 59/291 [00:42<02:42,  1.43it/s, loss=0.35, lr=4.62e-6, epoch=0, batch_id=471] \u001b[A\n",
            "steps:  21%|██        | 60/291 [00:43<02:46,  1.39it/s, loss=0.35, lr=4.62e-6, epoch=0, batch_id=471]\u001b[A\n",
            "steps:  21%|██        | 60/291 [00:43<02:46,  1.39it/s, loss=0.361, lr=4.61e-6, epoch=0, batch_id=479]\u001b[A\n",
            "steps:  21%|██        | 61/291 [00:43<02:47,  1.38it/s, loss=0.361, lr=4.61e-6, epoch=0, batch_id=479]\u001b[A\n",
            "steps:  21%|██        | 61/291 [00:43<02:47,  1.38it/s, loss=0.375, lr=4.59e-6, epoch=0, batch_id=487]\u001b[A\n",
            "steps:  21%|██▏       | 62/291 [00:44<02:48,  1.36it/s, loss=0.375, lr=4.59e-6, epoch=0, batch_id=487]\u001b[A\n",
            "steps:  21%|██▏       | 62/291 [00:44<02:48,  1.36it/s, loss=0.364, lr=4.58e-6, epoch=0, batch_id=495]\u001b[A\n",
            "steps:  22%|██▏       | 63/291 [00:45<02:42,  1.40it/s, loss=0.364, lr=4.58e-6, epoch=0, batch_id=495]\u001b[A\n",
            "steps:  22%|██▏       | 63/291 [00:45<02:42,  1.40it/s, loss=0.377, lr=4.56e-6, epoch=0, batch_id=503]\u001b[A\n",
            "steps:  22%|██▏       | 64/291 [00:45<02:46,  1.36it/s, loss=0.377, lr=4.56e-6, epoch=0, batch_id=503]\u001b[A\n",
            "steps:  22%|██▏       | 64/291 [00:45<02:46,  1.36it/s, loss=0.344, lr=4.55e-6, epoch=0, batch_id=511]\u001b[A\n",
            "steps:  22%|██▏       | 65/291 [00:46<02:42,  1.39it/s, loss=0.344, lr=4.55e-6, epoch=0, batch_id=511]\u001b[A\n",
            "steps:  22%|██▏       | 65/291 [00:46<02:42,  1.39it/s, loss=0.359, lr=4.53e-6, epoch=0, batch_id=519]\u001b[A\n",
            "steps:  23%|██▎       | 66/291 [00:47<02:38,  1.42it/s, loss=0.359, lr=4.53e-6, epoch=0, batch_id=519]\u001b[A\n",
            "steps:  23%|██▎       | 66/291 [00:47<02:38,  1.42it/s, loss=0.352, lr=4.51e-6, epoch=0, batch_id=527]\u001b[A\n",
            "steps:  23%|██▎       | 67/291 [00:47<02:32,  1.47it/s, loss=0.352, lr=4.51e-6, epoch=0, batch_id=527]\u001b[A\n",
            "steps:  23%|██▎       | 67/291 [00:47<02:32,  1.47it/s, loss=0.343, lr=4.5e-6, epoch=0, batch_id=535] \u001b[A\n",
            "steps:  23%|██▎       | 68/291 [00:48<02:32,  1.46it/s, loss=0.343, lr=4.5e-6, epoch=0, batch_id=535]\u001b[A\n",
            "steps:  23%|██▎       | 68/291 [00:48<02:32,  1.46it/s, loss=0.353, lr=4.48e-6, epoch=0, batch_id=543]\u001b[A\n",
            "steps:  24%|██▎       | 69/291 [00:49<02:34,  1.44it/s, loss=0.353, lr=4.48e-6, epoch=0, batch_id=543]\u001b[A\n",
            "steps:  24%|██▎       | 69/291 [00:49<02:34,  1.44it/s, loss=0.347, lr=4.46e-6, epoch=0, batch_id=551]\u001b[A\n",
            "steps:  24%|██▍       | 70/291 [00:49<02:28,  1.48it/s, loss=0.347, lr=4.46e-6, epoch=0, batch_id=551]\u001b[A\n",
            "steps:  24%|██▍       | 70/291 [00:49<02:28,  1.48it/s, loss=0.372, lr=4.44e-6, epoch=0, batch_id=559]\u001b[A\n",
            "steps:  24%|██▍       | 71/291 [00:50<02:32,  1.44it/s, loss=0.372, lr=4.44e-6, epoch=0, batch_id=559]\u001b[A\n",
            "steps:  24%|██▍       | 71/291 [00:50<02:32,  1.44it/s, loss=0.368, lr=4.43e-6, epoch=0, batch_id=567]\u001b[A\n",
            "steps:  25%|██▍       | 72/291 [00:51<02:30,  1.46it/s, loss=0.368, lr=4.43e-6, epoch=0, batch_id=567]\u001b[A\n",
            "steps:  25%|██▍       | 72/291 [00:51<02:30,  1.46it/s, loss=0.354, lr=4.41e-6, epoch=0, batch_id=575]\u001b[A\n",
            "steps:  25%|██▌       | 73/291 [00:52<02:30,  1.45it/s, loss=0.354, lr=4.41e-6, epoch=0, batch_id=575]\u001b[A\n",
            "steps:  25%|██▌       | 73/291 [00:52<02:30,  1.45it/s, loss=0.381, lr=4.39e-6, epoch=0, batch_id=583]\u001b[A\n",
            "steps:  25%|██▌       | 74/291 [00:52<02:29,  1.45it/s, loss=0.381, lr=4.39e-6, epoch=0, batch_id=583]\u001b[A\n",
            "steps:  25%|██▌       | 74/291 [00:52<02:29,  1.45it/s, loss=0.367, lr=4.37e-6, epoch=0, batch_id=591]\u001b[A\n",
            "steps:  26%|██▌       | 75/291 [00:53<02:30,  1.43it/s, loss=0.367, lr=4.37e-6, epoch=0, batch_id=591]\u001b[A\n",
            "steps:  26%|██▌       | 75/291 [00:53<02:30,  1.43it/s, loss=0.357, lr=4.35e-6, epoch=0, batch_id=599]\u001b[A\n",
            "steps:  26%|██▌       | 76/291 [00:54<02:34,  1.39it/s, loss=0.357, lr=4.35e-6, epoch=0, batch_id=599]\u001b[A\n",
            "steps:  26%|██▌       | 76/291 [00:54<02:34,  1.39it/s, loss=0.371, lr=4.34e-6, epoch=0, batch_id=607]\u001b[A\n",
            "steps:  26%|██▋       | 77/291 [00:55<02:38,  1.35it/s, loss=0.371, lr=4.34e-6, epoch=0, batch_id=607]\u001b[A\n",
            "steps:  26%|██▋       | 77/291 [00:55<02:38,  1.35it/s, loss=0.366, lr=4.32e-6, epoch=0, batch_id=615]\u001b[A\n",
            "steps:  27%|██▋       | 78/291 [00:55<02:33,  1.38it/s, loss=0.366, lr=4.32e-6, epoch=0, batch_id=615]\u001b[A\n",
            "steps:  27%|██▋       | 78/291 [00:55<02:33,  1.38it/s, loss=0.354, lr=4.3e-6, epoch=0, batch_id=623] \u001b[A\n",
            "steps:  27%|██▋       | 79/291 [00:56<02:31,  1.40it/s, loss=0.354, lr=4.3e-6, epoch=0, batch_id=623]\u001b[A\n",
            "steps:  27%|██▋       | 79/291 [00:56<02:31,  1.40it/s, loss=0.361, lr=4.28e-6, epoch=0, batch_id=631]\u001b[A\n",
            "steps:  27%|██▋       | 80/291 [00:57<02:28,  1.42it/s, loss=0.361, lr=4.28e-6, epoch=0, batch_id=631]\u001b[A\n",
            "steps:  27%|██▋       | 80/291 [00:57<02:28,  1.42it/s, loss=0.364, lr=4.26e-6, epoch=0, batch_id=639]\u001b[A\n",
            "steps:  28%|██▊       | 81/291 [00:57<02:27,  1.42it/s, loss=0.364, lr=4.26e-6, epoch=0, batch_id=639]\u001b[A\n",
            "steps:  28%|██▊       | 81/291 [00:57<02:27,  1.42it/s, loss=0.367, lr=4.24e-6, epoch=0, batch_id=647]\u001b[A\n",
            "steps:  28%|██▊       | 82/291 [00:58<02:23,  1.45it/s, loss=0.367, lr=4.24e-6, epoch=0, batch_id=647]\u001b[A\n",
            "steps:  28%|██▊       | 82/291 [00:58<02:23,  1.45it/s, loss=0.375, lr=4.22e-6, epoch=0, batch_id=655]\u001b[A\n",
            "steps:  29%|██▊       | 83/291 [00:59<02:25,  1.43it/s, loss=0.375, lr=4.22e-6, epoch=0, batch_id=655]\u001b[A\n",
            "steps:  29%|██▊       | 83/291 [00:59<02:25,  1.43it/s, loss=0.342, lr=4.2e-6, epoch=0, batch_id=663] \u001b[A\n",
            "steps:  29%|██▉       | 84/291 [00:59<02:26,  1.41it/s, loss=0.342, lr=4.2e-6, epoch=0, batch_id=663]\u001b[A\n",
            "steps:  29%|██▉       | 84/291 [00:59<02:26,  1.41it/s, loss=0.357, lr=4.18e-6, epoch=0, batch_id=671]\u001b[A\n",
            "steps:  29%|██▉       | 85/291 [01:00<02:26,  1.40it/s, loss=0.357, lr=4.18e-6, epoch=0, batch_id=671]\u001b[A\n",
            "steps:  29%|██▉       | 85/291 [01:00<02:26,  1.40it/s, loss=0.336, lr=4.16e-6, epoch=0, batch_id=679]\u001b[A\n",
            "steps:  30%|██▉       | 86/291 [01:01<02:28,  1.38it/s, loss=0.336, lr=4.16e-6, epoch=0, batch_id=679]\u001b[A\n",
            "steps:  30%|██▉       | 86/291 [01:01<02:28,  1.38it/s, loss=0.349, lr=4.14e-6, epoch=0, batch_id=687]\u001b[A\n",
            "steps:  30%|██▉       | 87/291 [01:02<02:25,  1.40it/s, loss=0.349, lr=4.14e-6, epoch=0, batch_id=687]\u001b[A\n",
            "steps:  30%|██▉       | 87/291 [01:02<02:25,  1.40it/s, loss=0.341, lr=4.11e-6, epoch=0, batch_id=695]\u001b[A\n",
            "steps:  30%|███       | 88/291 [01:02<02:26,  1.39it/s, loss=0.341, lr=4.11e-6, epoch=0, batch_id=695]\u001b[A\n",
            "steps:  30%|███       | 88/291 [01:02<02:26,  1.39it/s, loss=0.351, lr=4.09e-6, epoch=0, batch_id=703]\u001b[A\n",
            "steps:  31%|███       | 89/291 [01:03<02:26,  1.38it/s, loss=0.351, lr=4.09e-6, epoch=0, batch_id=703]\u001b[A\n",
            "steps:  31%|███       | 89/291 [01:03<02:26,  1.38it/s, loss=0.359, lr=4.07e-6, epoch=0, batch_id=711]\u001b[A\n",
            "steps:  31%|███       | 90/291 [01:04<02:24,  1.40it/s, loss=0.359, lr=4.07e-6, epoch=0, batch_id=711]\u001b[A\n",
            "steps:  31%|███       | 90/291 [01:04<02:24,  1.40it/s, loss=0.363, lr=4.05e-6, epoch=0, batch_id=719]\u001b[A\n",
            "steps:  31%|███▏      | 91/291 [01:04<02:20,  1.43it/s, loss=0.363, lr=4.05e-6, epoch=0, batch_id=719]\u001b[A\n",
            "steps:  31%|███▏      | 91/291 [01:04<02:20,  1.43it/s, loss=0.358, lr=4.03e-6, epoch=0, batch_id=727]\u001b[A\n",
            "steps:  32%|███▏      | 92/291 [01:05<02:17,  1.45it/s, loss=0.358, lr=4.03e-6, epoch=0, batch_id=727]\u001b[A\n",
            "steps:  32%|███▏      | 92/291 [01:05<02:17,  1.45it/s, loss=0.351, lr=4.01e-6, epoch=0, batch_id=735]\u001b[A\n",
            "steps:  32%|███▏      | 93/291 [01:06<02:15,  1.46it/s, loss=0.351, lr=4.01e-6, epoch=0, batch_id=735]\u001b[A\n",
            "steps:  32%|███▏      | 93/291 [01:06<02:15,  1.46it/s, loss=0.366, lr=3.98e-6, epoch=0, batch_id=743]\u001b[A\n",
            "steps:  32%|███▏      | 94/291 [01:06<02:17,  1.43it/s, loss=0.366, lr=3.98e-6, epoch=0, batch_id=743]\u001b[A\n",
            "steps:  32%|███▏      | 94/291 [01:06<02:17,  1.43it/s, loss=0.353, lr=3.96e-6, epoch=0, batch_id=751]\u001b[A\n",
            "steps:  33%|███▎      | 95/291 [01:07<02:21,  1.38it/s, loss=0.353, lr=3.96e-6, epoch=0, batch_id=751]\u001b[A\n",
            "steps:  33%|███▎      | 95/291 [01:07<02:21,  1.38it/s, loss=0.358, lr=3.94e-6, epoch=0, batch_id=759]\u001b[A\n",
            "steps:  33%|███▎      | 96/291 [01:08<02:18,  1.41it/s, loss=0.358, lr=3.94e-6, epoch=0, batch_id=759]\u001b[A\n",
            "steps:  33%|███▎      | 96/291 [01:08<02:18,  1.41it/s, loss=0.343, lr=3.91e-6, epoch=0, batch_id=767]\u001b[A\n",
            "steps:  33%|███▎      | 97/291 [01:09<02:22,  1.36it/s, loss=0.343, lr=3.91e-6, epoch=0, batch_id=767]\u001b[A\n",
            "steps:  33%|███▎      | 97/291 [01:09<02:22,  1.36it/s, loss=0.344, lr=3.89e-6, epoch=0, batch_id=775]\u001b[A\n",
            "steps:  34%|███▎      | 98/291 [01:15<07:46,  2.42s/it, loss=0.344, lr=3.89e-6, epoch=0, batch_id=775]\u001b[A\n",
            "steps:  34%|███▎      | 98/291 [01:15<07:46,  2.42s/it, epoch=0, eval_loss=0.673]                     \u001b[A\n",
            "steps:  34%|███▍      | 99/291 [01:16<06:04,  1.90s/it, epoch=0, eval_loss=0.673]\u001b[A\n",
            "steps:  34%|███▍      | 99/291 [01:16<06:04,  1.90s/it, loss=0.679, lr=3.87e-6, epoch=1, batch_id=7]\u001b[A\n",
            "steps:  34%|███▍      | 100/291 [01:17<04:57,  1.56s/it, loss=0.679, lr=3.87e-6, epoch=1, batch_id=7]\u001b[A\n",
            "steps:  34%|███▍      | 100/291 [01:17<04:57,  1.56s/it, loss=0.341, lr=3.85e-6, epoch=1, batch_id=15]\u001b[A\n",
            "steps:  35%|███▍      | 101/291 [01:17<04:04,  1.29s/it, loss=0.341, lr=3.85e-6, epoch=1, batch_id=15]\u001b[A\n",
            "steps:  35%|███▍      | 101/291 [01:17<04:04,  1.29s/it, loss=0.36, lr=3.82e-6, epoch=1, batch_id=23] \u001b[A\n",
            "steps:  35%|███▌      | 102/291 [01:18<03:29,  1.11s/it, loss=0.36, lr=3.82e-6, epoch=1, batch_id=23]\u001b[A\n",
            "steps:  35%|███▌      | 102/291 [01:18<03:29,  1.11s/it, loss=0.362, lr=3.8e-6, epoch=1, batch_id=31]\u001b[A\n",
            "steps:  35%|███▌      | 103/291 [01:19<03:04,  1.02it/s, loss=0.362, lr=3.8e-6, epoch=1, batch_id=31]\u001b[A\n",
            "steps:  35%|███▌      | 103/291 [01:19<03:04,  1.02it/s, loss=0.361, lr=3.77e-6, epoch=1, batch_id=39]\u001b[A\n",
            "steps:  36%|███▌      | 104/291 [01:19<02:47,  1.12it/s, loss=0.361, lr=3.77e-6, epoch=1, batch_id=39]\u001b[A\n",
            "steps:  36%|███▌      | 104/291 [01:19<02:47,  1.12it/s, loss=0.357, lr=3.75e-6, epoch=1, batch_id=47]\u001b[A\n",
            "steps:  36%|███▌      | 105/291 [01:20<02:33,  1.22it/s, loss=0.357, lr=3.75e-6, epoch=1, batch_id=47]\u001b[A\n",
            "steps:  36%|███▌      | 105/291 [01:20<02:33,  1.22it/s, loss=0.353, lr=3.73e-6, epoch=1, batch_id=55]\u001b[A\n",
            "steps:  36%|███▋      | 106/291 [01:21<02:24,  1.28it/s, loss=0.353, lr=3.73e-6, epoch=1, batch_id=55]\u001b[A\n",
            "steps:  36%|███▋      | 106/291 [01:21<02:24,  1.28it/s, loss=0.356, lr=3.7e-6, epoch=1, batch_id=63] \u001b[A\n",
            "steps:  37%|███▋      | 107/291 [01:21<02:20,  1.31it/s, loss=0.356, lr=3.7e-6, epoch=1, batch_id=63]\u001b[A\n",
            "steps:  37%|███▋      | 107/291 [01:21<02:20,  1.31it/s, loss=0.346, lr=3.68e-6, epoch=1, batch_id=71]\u001b[A\n",
            "steps:  37%|███▋      | 108/291 [01:22<02:17,  1.33it/s, loss=0.346, lr=3.68e-6, epoch=1, batch_id=71]\u001b[A\n",
            "steps:  37%|███▋      | 108/291 [01:22<02:17,  1.33it/s, loss=0.367, lr=3.65e-6, epoch=1, batch_id=79]\u001b[A\n",
            "steps:  37%|███▋      | 109/291 [01:23<02:16,  1.33it/s, loss=0.367, lr=3.65e-6, epoch=1, batch_id=79]\u001b[A\n",
            "steps:  37%|███▋      | 109/291 [01:23<02:16,  1.33it/s, loss=0.351, lr=3.63e-6, epoch=1, batch_id=87]\u001b[A\n",
            "steps:  38%|███▊      | 110/291 [01:24<02:15,  1.34it/s, loss=0.351, lr=3.63e-6, epoch=1, batch_id=87]\u001b[A\n",
            "steps:  38%|███▊      | 110/291 [01:24<02:15,  1.34it/s, loss=0.359, lr=3.6e-6, epoch=1, batch_id=95] \u001b[A\n",
            "steps:  38%|███▊      | 111/291 [01:24<02:14,  1.33it/s, loss=0.359, lr=3.6e-6, epoch=1, batch_id=95]\u001b[A\n",
            "steps:  38%|███▊      | 111/291 [01:24<02:14,  1.33it/s, loss=0.356, lr=3.58e-6, epoch=1, batch_id=103]\u001b[A\n",
            "steps:  38%|███▊      | 112/291 [01:25<02:13,  1.34it/s, loss=0.356, lr=3.58e-6, epoch=1, batch_id=103]\u001b[A\n",
            "steps:  38%|███▊      | 112/291 [01:25<02:13,  1.34it/s, loss=0.37, lr=3.55e-6, epoch=1, batch_id=111] \u001b[A\n",
            "steps:  39%|███▉      | 113/291 [01:26<02:11,  1.35it/s, loss=0.37, lr=3.55e-6, epoch=1, batch_id=111]\u001b[A\n",
            "steps:  39%|███▉      | 113/291 [01:26<02:11,  1.35it/s, loss=0.355, lr=3.53e-6, epoch=1, batch_id=119]\u001b[A\n",
            "steps:  39%|███▉      | 114/291 [01:26<02:07,  1.39it/s, loss=0.355, lr=3.53e-6, epoch=1, batch_id=119]\u001b[A\n",
            "steps:  39%|███▉      | 114/291 [01:26<02:07,  1.39it/s, loss=0.361, lr=3.5e-6, epoch=1, batch_id=127] \u001b[A\n",
            "steps:  40%|███▉      | 115/291 [01:27<02:05,  1.40it/s, loss=0.361, lr=3.5e-6, epoch=1, batch_id=127]\u001b[A\n",
            "steps:  40%|███▉      | 115/291 [01:27<02:05,  1.40it/s, loss=0.343, lr=3.48e-6, epoch=1, batch_id=135]\u001b[A\n",
            "steps:  40%|███▉      | 116/291 [01:28<02:04,  1.41it/s, loss=0.343, lr=3.48e-6, epoch=1, batch_id=135]\u001b[A\n",
            "steps:  40%|███▉      | 116/291 [01:28<02:04,  1.41it/s, loss=0.346, lr=3.45e-6, epoch=1, batch_id=143]\u001b[A\n",
            "steps:  40%|████      | 117/291 [01:29<02:03,  1.41it/s, loss=0.346, lr=3.45e-6, epoch=1, batch_id=143]\u001b[A\n",
            "steps:  40%|████      | 117/291 [01:29<02:03,  1.41it/s, loss=0.361, lr=3.42e-6, epoch=1, batch_id=151]\u001b[A\n",
            "steps:  41%|████      | 118/291 [01:29<02:02,  1.41it/s, loss=0.361, lr=3.42e-6, epoch=1, batch_id=151]\u001b[A\n",
            "steps:  41%|████      | 118/291 [01:29<02:02,  1.41it/s, loss=0.335, lr=3.4e-6, epoch=1, batch_id=159] \u001b[A\n",
            "steps:  41%|████      | 119/291 [01:30<02:01,  1.42it/s, loss=0.335, lr=3.4e-6, epoch=1, batch_id=159]\u001b[A\n",
            "steps:  41%|████      | 119/291 [01:30<02:01,  1.42it/s, loss=0.345, lr=3.37e-6, epoch=1, batch_id=167]\u001b[A\n",
            "steps:  41%|████      | 120/291 [01:31<02:01,  1.41it/s, loss=0.345, lr=3.37e-6, epoch=1, batch_id=167]\u001b[A\n",
            "steps:  41%|████      | 120/291 [01:31<02:01,  1.41it/s, loss=0.36, lr=3.35e-6, epoch=1, batch_id=175] \u001b[A\n",
            "steps:  42%|████▏     | 121/291 [01:31<01:59,  1.42it/s, loss=0.36, lr=3.35e-6, epoch=1, batch_id=175]\u001b[A\n",
            "steps:  42%|████▏     | 121/291 [01:31<01:59,  1.42it/s, loss=0.361, lr=3.32e-6, epoch=1, batch_id=183]\u001b[A\n",
            "steps:  42%|████▏     | 122/291 [01:32<01:56,  1.46it/s, loss=0.361, lr=3.32e-6, epoch=1, batch_id=183]\u001b[A\n",
            "steps:  42%|████▏     | 122/291 [01:32<01:56,  1.46it/s, loss=0.344, lr=3.29e-6, epoch=1, batch_id=191]\u001b[A\n",
            "steps:  42%|████▏     | 123/291 [01:33<01:58,  1.42it/s, loss=0.344, lr=3.29e-6, epoch=1, batch_id=191]\u001b[A\n",
            "steps:  42%|████▏     | 123/291 [01:33<01:58,  1.42it/s, loss=0.372, lr=3.27e-6, epoch=1, batch_id=199]\u001b[A\n",
            "steps:  43%|████▎     | 124/291 [01:33<02:00,  1.38it/s, loss=0.372, lr=3.27e-6, epoch=1, batch_id=199]\u001b[A\n",
            "steps:  43%|████▎     | 124/291 [01:33<02:00,  1.38it/s, loss=0.338, lr=3.24e-6, epoch=1, batch_id=207]\u001b[A\n",
            "steps:  43%|████▎     | 125/291 [01:34<01:55,  1.43it/s, loss=0.338, lr=3.24e-6, epoch=1, batch_id=207]\u001b[A\n",
            "steps:  43%|████▎     | 125/291 [01:34<01:55,  1.43it/s, loss=0.355, lr=3.21e-6, epoch=1, batch_id=215]\u001b[A\n",
            "steps:  43%|████▎     | 126/291 [01:35<01:55,  1.42it/s, loss=0.355, lr=3.21e-6, epoch=1, batch_id=215]\u001b[A\n",
            "steps:  43%|████▎     | 126/291 [01:35<01:55,  1.42it/s, loss=0.347, lr=3.19e-6, epoch=1, batch_id=223]\u001b[A\n",
            "steps:  44%|████▎     | 127/291 [01:36<01:54,  1.44it/s, loss=0.347, lr=3.19e-6, epoch=1, batch_id=223]\u001b[A\n",
            "steps:  44%|████▎     | 127/291 [01:36<01:54,  1.44it/s, loss=0.351, lr=3.16e-6, epoch=1, batch_id=231]\u001b[A\n",
            "steps:  44%|████▍     | 128/291 [01:36<01:54,  1.43it/s, loss=0.351, lr=3.16e-6, epoch=1, batch_id=231]\u001b[A\n",
            "steps:  44%|████▍     | 128/291 [01:36<01:54,  1.43it/s, loss=0.346, lr=3.13e-6, epoch=1, batch_id=239]\u001b[A\n",
            "steps:  44%|████▍     | 129/291 [01:37<01:53,  1.43it/s, loss=0.346, lr=3.13e-6, epoch=1, batch_id=239]\u001b[A\n",
            "steps:  44%|████▍     | 129/291 [01:37<01:53,  1.43it/s, loss=0.378, lr=3.11e-6, epoch=1, batch_id=247]\u001b[A\n",
            "steps:  45%|████▍     | 130/291 [01:38<01:50,  1.45it/s, loss=0.378, lr=3.11e-6, epoch=1, batch_id=247]\u001b[A\n",
            "steps:  45%|████▍     | 130/291 [01:38<01:50,  1.45it/s, loss=0.324, lr=3.08e-6, epoch=1, batch_id=255]\u001b[A\n",
            "steps:  45%|████▌     | 131/291 [01:38<01:52,  1.42it/s, loss=0.324, lr=3.08e-6, epoch=1, batch_id=255]\u001b[A\n",
            "steps:  45%|████▌     | 131/291 [01:38<01:52,  1.42it/s, loss=0.346, lr=3.05e-6, epoch=1, batch_id=263]\u001b[A\n",
            "steps:  45%|████▌     | 132/291 [01:39<01:53,  1.40it/s, loss=0.346, lr=3.05e-6, epoch=1, batch_id=263]\u001b[A\n",
            "steps:  45%|████▌     | 132/291 [01:39<01:53,  1.40it/s, loss=0.361, lr=3.03e-6, epoch=1, batch_id=271]\u001b[A\n",
            "steps:  46%|████▌     | 133/291 [01:40<01:51,  1.42it/s, loss=0.361, lr=3.03e-6, epoch=1, batch_id=271]\u001b[A\n",
            "steps:  46%|████▌     | 133/291 [01:40<01:51,  1.42it/s, loss=0.341, lr=3e-6, epoch=1, batch_id=279]   \u001b[A\n",
            "steps:  46%|████▌     | 134/291 [01:40<01:51,  1.41it/s, loss=0.341, lr=3e-6, epoch=1, batch_id=279]\u001b[A\n",
            "steps:  46%|████▌     | 134/291 [01:40<01:51,  1.41it/s, loss=0.341, lr=2.97e-6, epoch=1, batch_id=287]\u001b[A\n",
            "steps:  46%|████▋     | 135/291 [01:41<01:51,  1.40it/s, loss=0.341, lr=2.97e-6, epoch=1, batch_id=287]\u001b[A\n",
            "steps:  46%|████▋     | 135/291 [01:41<01:51,  1.40it/s, loss=0.354, lr=2.94e-6, epoch=1, batch_id=295]\u001b[A\n",
            "steps:  47%|████▋     | 136/291 [01:42<01:50,  1.40it/s, loss=0.354, lr=2.94e-6, epoch=1, batch_id=295]\u001b[A\n",
            "steps:  47%|████▋     | 136/291 [01:42<01:50,  1.40it/s, loss=0.363, lr=2.92e-6, epoch=1, batch_id=303]\u001b[A\n",
            "steps:  47%|████▋     | 137/291 [01:43<01:52,  1.37it/s, loss=0.363, lr=2.92e-6, epoch=1, batch_id=303]\u001b[A\n",
            "steps:  47%|████▋     | 137/291 [01:43<01:52,  1.37it/s, loss=0.358, lr=2.89e-6, epoch=1, batch_id=311]\u001b[A\n",
            "steps:  47%|████▋     | 138/291 [01:43<01:48,  1.40it/s, loss=0.358, lr=2.89e-6, epoch=1, batch_id=311]\u001b[A\n",
            "steps:  47%|████▋     | 138/291 [01:43<01:48,  1.40it/s, loss=0.36, lr=2.86e-6, epoch=1, batch_id=319] \u001b[A\n",
            "steps:  48%|████▊     | 139/291 [01:44<01:46,  1.43it/s, loss=0.36, lr=2.86e-6, epoch=1, batch_id=319]\u001b[A\n",
            "steps:  48%|████▊     | 139/291 [01:44<01:46,  1.43it/s, loss=0.335, lr=2.83e-6, epoch=1, batch_id=327]\u001b[A\n",
            "steps:  48%|████▊     | 140/291 [01:45<01:48,  1.39it/s, loss=0.335, lr=2.83e-6, epoch=1, batch_id=327]\u001b[A\n",
            "steps:  48%|████▊     | 140/291 [01:45<01:48,  1.39it/s, loss=0.355, lr=2.81e-6, epoch=1, batch_id=335]\u001b[A\n",
            "steps:  48%|████▊     | 141/291 [01:45<01:46,  1.41it/s, loss=0.355, lr=2.81e-6, epoch=1, batch_id=335]\u001b[A\n",
            "steps:  48%|████▊     | 141/291 [01:45<01:46,  1.41it/s, loss=0.332, lr=2.78e-6, epoch=1, batch_id=343]\u001b[A\n",
            "steps:  49%|████▉     | 142/291 [01:46<01:44,  1.42it/s, loss=0.332, lr=2.78e-6, epoch=1, batch_id=343]\u001b[A\n",
            "steps:  49%|████▉     | 142/291 [01:46<01:44,  1.42it/s, loss=0.366, lr=2.75e-6, epoch=1, batch_id=351]\u001b[A\n",
            "steps:  49%|████▉     | 143/291 [01:47<01:48,  1.37it/s, loss=0.366, lr=2.75e-6, epoch=1, batch_id=351]\u001b[A\n",
            "steps:  49%|████▉     | 143/291 [01:47<01:48,  1.37it/s, loss=0.36, lr=2.72e-6, epoch=1, batch_id=359] \u001b[A\n",
            "steps:  49%|████▉     | 144/291 [01:48<01:46,  1.37it/s, loss=0.36, lr=2.72e-6, epoch=1, batch_id=359]\u001b[A\n",
            "steps:  49%|████▉     | 144/291 [01:48<01:46,  1.37it/s, loss=0.361, lr=2.69e-6, epoch=1, batch_id=367]\u001b[A\n",
            "steps:  50%|████▉     | 145/291 [01:48<01:44,  1.40it/s, loss=0.361, lr=2.69e-6, epoch=1, batch_id=367]\u001b[A\n",
            "steps:  50%|████▉     | 145/291 [01:48<01:44,  1.40it/s, loss=0.363, lr=2.67e-6, epoch=1, batch_id=375]\u001b[A\n",
            "steps:  50%|█████     | 146/291 [01:49<01:42,  1.41it/s, loss=0.363, lr=2.67e-6, epoch=1, batch_id=375]\u001b[A\n",
            "steps:  50%|█████     | 146/291 [01:49<01:42,  1.41it/s, loss=0.35, lr=2.64e-6, epoch=1, batch_id=383] \u001b[A\n",
            "steps:  51%|█████     | 147/291 [01:50<01:43,  1.39it/s, loss=0.35, lr=2.64e-6, epoch=1, batch_id=383]\u001b[A\n",
            "steps:  51%|█████     | 147/291 [01:50<01:43,  1.39it/s, loss=0.353, lr=2.61e-6, epoch=1, batch_id=391]\u001b[A\n",
            "steps:  51%|█████     | 148/291 [01:50<01:41,  1.41it/s, loss=0.353, lr=2.61e-6, epoch=1, batch_id=391]\u001b[A\n",
            "steps:  51%|█████     | 148/291 [01:51<01:41,  1.41it/s, loss=0.354, lr=2.58e-6, epoch=1, batch_id=399]\u001b[A\n",
            "steps:  51%|█████     | 149/291 [01:51<01:39,  1.42it/s, loss=0.354, lr=2.58e-6, epoch=1, batch_id=399]\u001b[A\n",
            "steps:  51%|█████     | 149/291 [01:51<01:39,  1.42it/s, loss=0.349, lr=2.56e-6, epoch=1, batch_id=407]\u001b[A\n",
            "steps:  52%|█████▏    | 150/291 [01:52<01:38,  1.43it/s, loss=0.349, lr=2.56e-6, epoch=1, batch_id=407]\u001b[A\n",
            "steps:  52%|█████▏    | 150/291 [01:52<01:38,  1.43it/s, loss=0.338, lr=2.53e-6, epoch=1, batch_id=415]\u001b[A\n",
            "steps:  52%|█████▏    | 151/291 [01:53<01:38,  1.42it/s, loss=0.338, lr=2.53e-6, epoch=1, batch_id=415]\u001b[A\n",
            "steps:  52%|█████▏    | 151/291 [01:53<01:38,  1.42it/s, loss=0.347, lr=2.5e-6, epoch=1, batch_id=423] \u001b[A\n",
            "steps:  52%|█████▏    | 152/291 [01:53<01:39,  1.39it/s, loss=0.347, lr=2.5e-6, epoch=1, batch_id=423]\u001b[A\n",
            "steps:  52%|█████▏    | 152/291 [01:53<01:39,  1.39it/s, loss=0.337, lr=2.47e-6, epoch=1, batch_id=431]\u001b[A\n",
            "steps:  53%|█████▎    | 153/291 [01:54<01:36,  1.43it/s, loss=0.337, lr=2.47e-6, epoch=1, batch_id=431]\u001b[A\n",
            "steps:  53%|█████▎    | 153/291 [01:54<01:36,  1.43it/s, loss=0.359, lr=2.44e-6, epoch=1, batch_id=439]\u001b[A\n",
            "steps:  53%|█████▎    | 154/291 [01:55<01:37,  1.40it/s, loss=0.359, lr=2.44e-6, epoch=1, batch_id=439]\u001b[A\n",
            "steps:  53%|█████▎    | 154/291 [01:55<01:37,  1.40it/s, loss=0.337, lr=2.42e-6, epoch=1, batch_id=447]\u001b[A\n",
            "steps:  53%|█████▎    | 155/291 [01:55<01:38,  1.38it/s, loss=0.337, lr=2.42e-6, epoch=1, batch_id=447]\u001b[A\n",
            "steps:  53%|█████▎    | 155/291 [01:55<01:38,  1.38it/s, loss=0.386, lr=2.39e-6, epoch=1, batch_id=455]\u001b[A\n",
            "steps:  54%|█████▎    | 156/291 [01:56<01:37,  1.39it/s, loss=0.386, lr=2.39e-6, epoch=1, batch_id=455]\u001b[A\n",
            "steps:  54%|█████▎    | 156/291 [01:56<01:37,  1.39it/s, loss=0.353, lr=2.36e-6, epoch=1, batch_id=463]\u001b[A\n",
            "steps:  54%|█████▍    | 157/291 [01:57<01:37,  1.38it/s, loss=0.353, lr=2.36e-6, epoch=1, batch_id=463]\u001b[A\n",
            "steps:  54%|█████▍    | 157/291 [01:57<01:37,  1.38it/s, loss=0.348, lr=2.33e-6, epoch=1, batch_id=471]\u001b[A\n",
            "steps:  54%|█████▍    | 158/291 [01:58<01:36,  1.38it/s, loss=0.348, lr=2.33e-6, epoch=1, batch_id=471]\u001b[A\n",
            "steps:  54%|█████▍    | 158/291 [01:58<01:36,  1.38it/s, loss=0.372, lr=2.31e-6, epoch=1, batch_id=479]\u001b[A\n",
            "steps:  55%|█████▍    | 159/291 [01:58<01:34,  1.39it/s, loss=0.372, lr=2.31e-6, epoch=1, batch_id=479]\u001b[A\n",
            "steps:  55%|█████▍    | 159/291 [01:58<01:34,  1.39it/s, loss=0.344, lr=2.28e-6, epoch=1, batch_id=487]\u001b[A\n",
            "steps:  55%|█████▍    | 160/291 [01:59<01:35,  1.37it/s, loss=0.344, lr=2.28e-6, epoch=1, batch_id=487]\u001b[A\n",
            "steps:  55%|█████▍    | 160/291 [01:59<01:35,  1.37it/s, loss=0.36, lr=2.25e-6, epoch=1, batch_id=495] \u001b[A\n",
            "steps:  55%|█████▌    | 161/291 [02:00<01:31,  1.42it/s, loss=0.36, lr=2.25e-6, epoch=1, batch_id=495]\u001b[A\n",
            "steps:  55%|█████▌    | 161/291 [02:00<01:31,  1.42it/s, loss=0.349, lr=2.22e-6, epoch=1, batch_id=503]\u001b[A\n",
            "steps:  56%|█████▌    | 162/291 [02:00<01:31,  1.40it/s, loss=0.349, lr=2.22e-6, epoch=1, batch_id=503]\u001b[A\n",
            "steps:  56%|█████▌    | 162/291 [02:00<01:31,  1.40it/s, loss=0.358, lr=2.19e-6, epoch=1, batch_id=511]\u001b[A\n",
            "steps:  56%|█████▌    | 163/291 [02:01<01:29,  1.43it/s, loss=0.358, lr=2.19e-6, epoch=1, batch_id=511]\u001b[A\n",
            "steps:  56%|█████▌    | 163/291 [02:01<01:29,  1.43it/s, loss=0.347, lr=2.17e-6, epoch=1, batch_id=519]\u001b[A\n",
            "steps:  56%|█████▋    | 164/291 [02:02<01:29,  1.41it/s, loss=0.347, lr=2.17e-6, epoch=1, batch_id=519]\u001b[A\n",
            "steps:  56%|█████▋    | 164/291 [02:02<01:29,  1.41it/s, loss=0.358, lr=2.14e-6, epoch=1, batch_id=527]\u001b[A\n",
            "steps:  57%|█████▋    | 165/291 [02:03<01:29,  1.40it/s, loss=0.358, lr=2.14e-6, epoch=1, batch_id=527]\u001b[A\n",
            "steps:  57%|█████▋    | 165/291 [02:03<01:29,  1.40it/s, loss=0.367, lr=2.11e-6, epoch=1, batch_id=535]\u001b[A\n",
            "steps:  57%|█████▋    | 166/291 [02:03<01:29,  1.40it/s, loss=0.367, lr=2.11e-6, epoch=1, batch_id=535]\u001b[A\n",
            "steps:  57%|█████▋    | 166/291 [02:03<01:29,  1.40it/s, loss=0.376, lr=2.08e-6, epoch=1, batch_id=543]\u001b[A\n",
            "steps:  57%|█████▋    | 167/291 [02:04<01:27,  1.42it/s, loss=0.376, lr=2.08e-6, epoch=1, batch_id=543]\u001b[A\n",
            "steps:  57%|█████▋    | 167/291 [02:04<01:27,  1.42it/s, loss=0.335, lr=2.06e-6, epoch=1, batch_id=551]\u001b[A\n",
            "steps:  58%|█████▊    | 168/291 [02:05<01:26,  1.43it/s, loss=0.335, lr=2.06e-6, epoch=1, batch_id=551]\u001b[A\n",
            "steps:  58%|█████▊    | 168/291 [02:05<01:26,  1.43it/s, loss=0.375, lr=2.03e-6, epoch=1, batch_id=559]\u001b[A\n",
            "steps:  58%|█████▊    | 169/291 [02:05<01:24,  1.44it/s, loss=0.375, lr=2.03e-6, epoch=1, batch_id=559]\u001b[A\n",
            "steps:  58%|█████▊    | 169/291 [02:05<01:24,  1.44it/s, loss=0.354, lr=2e-6, epoch=1, batch_id=567]   \u001b[A\n",
            "steps:  58%|█████▊    | 170/291 [02:06<01:25,  1.41it/s, loss=0.354, lr=2e-6, epoch=1, batch_id=567]\u001b[A\n",
            "steps:  58%|█████▊    | 170/291 [02:06<01:25,  1.41it/s, loss=0.362, lr=1.97e-6, epoch=1, batch_id=575]\u001b[A\n",
            "steps:  59%|█████▉    | 171/291 [02:07<01:23,  1.45it/s, loss=0.362, lr=1.97e-6, epoch=1, batch_id=575]\u001b[A\n",
            "steps:  59%|█████▉    | 171/291 [02:07<01:23,  1.45it/s, loss=0.373, lr=1.95e-6, epoch=1, batch_id=583]\u001b[A\n",
            "steps:  59%|█████▉    | 172/291 [02:07<01:19,  1.49it/s, loss=0.373, lr=1.95e-6, epoch=1, batch_id=583]\u001b[A\n",
            "steps:  59%|█████▉    | 172/291 [02:07<01:19,  1.49it/s, loss=0.366, lr=1.92e-6, epoch=1, batch_id=591]\u001b[A\n",
            "steps:  59%|█████▉    | 173/291 [02:08<01:19,  1.49it/s, loss=0.366, lr=1.92e-6, epoch=1, batch_id=591]\u001b[A\n",
            "steps:  59%|█████▉    | 173/291 [02:08<01:19,  1.49it/s, loss=0.36, lr=1.89e-6, epoch=1, batch_id=599] \u001b[A\n",
            "steps:  60%|█████▉    | 174/291 [02:09<01:20,  1.45it/s, loss=0.36, lr=1.89e-6, epoch=1, batch_id=599]\u001b[A\n",
            "steps:  60%|█████▉    | 174/291 [02:09<01:20,  1.45it/s, loss=0.353, lr=1.87e-6, epoch=1, batch_id=607]\u001b[A\n",
            "steps:  60%|██████    | 175/291 [02:10<01:21,  1.42it/s, loss=0.353, lr=1.87e-6, epoch=1, batch_id=607]\u001b[A\n",
            "steps:  60%|██████    | 175/291 [02:10<01:21,  1.42it/s, loss=0.355, lr=1.84e-6, epoch=1, batch_id=615]\u001b[A\n",
            "steps:  60%|██████    | 176/291 [02:10<01:22,  1.39it/s, loss=0.355, lr=1.84e-6, epoch=1, batch_id=615]\u001b[A\n",
            "steps:  60%|██████    | 176/291 [02:10<01:22,  1.39it/s, loss=0.356, lr=1.81e-6, epoch=1, batch_id=623]\u001b[A\n",
            "steps:  61%|██████    | 177/291 [02:11<01:22,  1.38it/s, loss=0.356, lr=1.81e-6, epoch=1, batch_id=623]\u001b[A\n",
            "steps:  61%|██████    | 177/291 [02:11<01:22,  1.38it/s, loss=0.371, lr=1.79e-6, epoch=1, batch_id=631]\u001b[A\n",
            "steps:  61%|██████    | 178/291 [02:12<01:21,  1.38it/s, loss=0.371, lr=1.79e-6, epoch=1, batch_id=631]\u001b[A\n",
            "steps:  61%|██████    | 178/291 [02:12<01:21,  1.38it/s, loss=0.356, lr=1.76e-6, epoch=1, batch_id=639]\u001b[A\n",
            "steps:  62%|██████▏   | 179/291 [02:13<01:22,  1.35it/s, loss=0.356, lr=1.76e-6, epoch=1, batch_id=639]\u001b[A\n",
            "steps:  62%|██████▏   | 179/291 [02:13<01:22,  1.35it/s, loss=0.358, lr=1.73e-6, epoch=1, batch_id=647]\u001b[A\n",
            "steps:  62%|██████▏   | 180/291 [02:13<01:22,  1.34it/s, loss=0.358, lr=1.73e-6, epoch=1, batch_id=647]\u001b[A\n",
            "steps:  62%|██████▏   | 180/291 [02:13<01:22,  1.34it/s, loss=0.354, lr=1.71e-6, epoch=1, batch_id=655]\u001b[A\n",
            "steps:  62%|██████▏   | 181/291 [02:14<01:20,  1.37it/s, loss=0.354, lr=1.71e-6, epoch=1, batch_id=655]\u001b[A\n",
            "steps:  62%|██████▏   | 181/291 [02:14<01:20,  1.37it/s, loss=0.35, lr=1.68e-6, epoch=1, batch_id=663] \u001b[A\n",
            "steps:  63%|██████▎   | 182/291 [02:15<01:19,  1.37it/s, loss=0.35, lr=1.68e-6, epoch=1, batch_id=663]\u001b[A\n",
            "steps:  63%|██████▎   | 182/291 [02:15<01:19,  1.37it/s, loss=0.358, lr=1.65e-6, epoch=1, batch_id=671]\u001b[A\n",
            "steps:  63%|██████▎   | 183/291 [02:15<01:18,  1.38it/s, loss=0.358, lr=1.65e-6, epoch=1, batch_id=671]\u001b[A\n",
            "steps:  63%|██████▎   | 183/291 [02:15<01:18,  1.38it/s, loss=0.341, lr=1.63e-6, epoch=1, batch_id=679]\u001b[A\n",
            "steps:  63%|██████▎   | 184/291 [02:16<01:16,  1.39it/s, loss=0.341, lr=1.63e-6, epoch=1, batch_id=679]\u001b[A\n",
            "steps:  63%|██████▎   | 184/291 [02:16<01:16,  1.39it/s, loss=0.332, lr=1.6e-6, epoch=1, batch_id=687] \u001b[A\n",
            "steps:  64%|██████▎   | 185/291 [02:17<01:15,  1.40it/s, loss=0.332, lr=1.6e-6, epoch=1, batch_id=687]\u001b[A\n",
            "steps:  64%|██████▎   | 185/291 [02:17<01:15,  1.40it/s, loss=0.352, lr=1.58e-6, epoch=1, batch_id=695]\u001b[A\n",
            "steps:  64%|██████▍   | 186/291 [02:18<01:14,  1.41it/s, loss=0.352, lr=1.58e-6, epoch=1, batch_id=695]\u001b[A\n",
            "steps:  64%|██████▍   | 186/291 [02:18<01:14,  1.41it/s, loss=0.36, lr=1.55e-6, epoch=1, batch_id=703] \u001b[A\n",
            "steps:  64%|██████▍   | 187/291 [02:18<01:14,  1.40it/s, loss=0.36, lr=1.55e-6, epoch=1, batch_id=703]\u001b[A\n",
            "steps:  64%|██████▍   | 187/291 [02:18<01:14,  1.40it/s, loss=0.347, lr=1.52e-6, epoch=1, batch_id=711]\u001b[A\n",
            "steps:  65%|██████▍   | 188/291 [02:19<01:13,  1.40it/s, loss=0.347, lr=1.52e-6, epoch=1, batch_id=711]\u001b[A\n",
            "steps:  65%|██████▍   | 188/291 [02:19<01:13,  1.40it/s, loss=0.365, lr=1.5e-6, epoch=1, batch_id=719] \u001b[A\n",
            "steps:  65%|██████▍   | 189/291 [02:20<01:11,  1.44it/s, loss=0.365, lr=1.5e-6, epoch=1, batch_id=719]\u001b[A\n",
            "steps:  65%|██████▍   | 189/291 [02:20<01:11,  1.44it/s, loss=0.35, lr=1.47e-6, epoch=1, batch_id=727]\u001b[A\n",
            "steps:  65%|██████▌   | 190/291 [02:20<01:08,  1.47it/s, loss=0.35, lr=1.47e-6, epoch=1, batch_id=727]\u001b[A\n",
            "steps:  65%|██████▌   | 190/291 [02:20<01:08,  1.47it/s, loss=0.355, lr=1.45e-6, epoch=1, batch_id=735]\u001b[A\n",
            "steps:  66%|██████▌   | 191/291 [02:21<01:09,  1.44it/s, loss=0.355, lr=1.45e-6, epoch=1, batch_id=735]\u001b[A\n",
            "steps:  66%|██████▌   | 191/291 [02:21<01:09,  1.44it/s, loss=0.366, lr=1.42e-6, epoch=1, batch_id=743]\u001b[A\n",
            "steps:  66%|██████▌   | 192/291 [02:22<01:09,  1.42it/s, loss=0.366, lr=1.42e-6, epoch=1, batch_id=743]\u001b[A\n",
            "steps:  66%|██████▌   | 192/291 [02:22<01:09,  1.42it/s, loss=0.354, lr=1.4e-6, epoch=1, batch_id=751] \u001b[A\n",
            "steps:  66%|██████▋   | 193/291 [02:22<01:09,  1.40it/s, loss=0.354, lr=1.4e-6, epoch=1, batch_id=751]\u001b[A\n",
            "steps:  66%|██████▋   | 193/291 [02:22<01:09,  1.40it/s, loss=0.35, lr=1.37e-6, epoch=1, batch_id=759]\u001b[A\n",
            "steps:  67%|██████▋   | 194/291 [02:23<01:10,  1.37it/s, loss=0.35, lr=1.37e-6, epoch=1, batch_id=759]\u001b[A\n",
            "steps:  67%|██████▋   | 194/291 [02:23<01:10,  1.37it/s, loss=0.35, lr=1.35e-6, epoch=1, batch_id=767]\u001b[A\n",
            "steps:  67%|██████▋   | 195/291 [02:24<01:08,  1.40it/s, loss=0.35, lr=1.35e-6, epoch=1, batch_id=767]\u001b[A\n",
            "steps:  67%|██████▋   | 195/291 [02:24<01:08,  1.40it/s, loss=0.362, lr=1.32e-6, epoch=1, batch_id=775]\u001b[A\n",
            "steps:  67%|██████▋   | 196/291 [02:30<03:47,  2.39s/it, loss=0.362, lr=1.32e-6, epoch=1, batch_id=775]\u001b[A\n",
            "steps:  67%|██████▋   | 196/291 [02:30<03:47,  2.39s/it, epoch=1, eval_loss=0.667]                     \u001b[A\n",
            "steps:  68%|██████▊   | 197/291 [02:31<02:58,  1.90s/it, epoch=1, eval_loss=0.667]\u001b[A\n",
            "steps:  68%|██████▊   | 197/291 [02:31<02:58,  1.90s/it, loss=0.672, lr=1.3e-6, epoch=2, batch_id=7]\u001b[A\n",
            "steps:  68%|██████▊   | 198/291 [02:32<02:24,  1.55s/it, loss=0.672, lr=1.3e-6, epoch=2, batch_id=7]\u001b[A\n",
            "steps:  68%|██████▊   | 198/291 [02:32<02:24,  1.55s/it, loss=0.355, lr=1.27e-6, epoch=2, batch_id=15]\u001b[A\n",
            "steps:  68%|██████▊   | 199/291 [02:32<01:56,  1.27s/it, loss=0.355, lr=1.27e-6, epoch=2, batch_id=15]\u001b[A\n",
            "steps:  68%|██████▊   | 199/291 [02:32<01:56,  1.27s/it, loss=0.357, lr=1.25e-6, epoch=2, batch_id=23]\u001b[A\n",
            "steps:  69%|██████▊   | 200/291 [02:33<01:38,  1.08s/it, loss=0.357, lr=1.25e-6, epoch=2, batch_id=23]\u001b[A\n",
            "steps:  69%|██████▊   | 200/291 [02:33<01:38,  1.08s/it, loss=0.339, lr=1.23e-6, epoch=2, batch_id=31]\u001b[A\n",
            "steps:  69%|██████▉   | 201/291 [02:34<01:26,  1.04it/s, loss=0.339, lr=1.23e-6, epoch=2, batch_id=31]\u001b[A\n",
            "steps:  69%|██████▉   | 201/291 [02:34<01:26,  1.04it/s, loss=0.354, lr=1.2e-6, epoch=2, batch_id=39] \u001b[A\n",
            "steps:  69%|██████▉   | 202/291 [02:34<01:16,  1.16it/s, loss=0.354, lr=1.2e-6, epoch=2, batch_id=39]\u001b[A\n",
            "steps:  69%|██████▉   | 202/291 [02:34<01:16,  1.16it/s, loss=0.353, lr=1.18e-6, epoch=2, batch_id=47]\u001b[A\n",
            "steps:  70%|██████▉   | 203/291 [02:35<01:11,  1.22it/s, loss=0.353, lr=1.18e-6, epoch=2, batch_id=47]\u001b[A\n",
            "steps:  70%|██████▉   | 203/291 [02:35<01:11,  1.22it/s, loss=0.357, lr=1.15e-6, epoch=2, batch_id=55]\u001b[A\n",
            "steps:  70%|███████   | 204/291 [02:36<01:07,  1.28it/s, loss=0.357, lr=1.15e-6, epoch=2, batch_id=55]\u001b[A\n",
            "steps:  70%|███████   | 204/291 [02:36<01:07,  1.28it/s, loss=0.351, lr=1.13e-6, epoch=2, batch_id=63]\u001b[A\n",
            "steps:  70%|███████   | 205/291 [02:36<01:05,  1.32it/s, loss=0.351, lr=1.13e-6, epoch=2, batch_id=63]\u001b[A\n",
            "steps:  70%|███████   | 205/291 [02:36<01:05,  1.32it/s, loss=0.36, lr=1.11e-6, epoch=2, batch_id=71] \u001b[A\n",
            "steps:  71%|███████   | 206/291 [02:37<01:02,  1.37it/s, loss=0.36, lr=1.11e-6, epoch=2, batch_id=71]\u001b[A\n",
            "steps:  71%|███████   | 206/291 [02:37<01:02,  1.37it/s, loss=0.351, lr=1.09e-6, epoch=2, batch_id=79]\u001b[A\n",
            "steps:  71%|███████   | 207/291 [02:38<01:02,  1.35it/s, loss=0.351, lr=1.09e-6, epoch=2, batch_id=79]\u001b[A\n",
            "steps:  71%|███████   | 207/291 [02:38<01:02,  1.35it/s, loss=0.372, lr=1.06e-6, epoch=2, batch_id=87]\u001b[A\n",
            "steps:  71%|███████▏  | 208/291 [02:39<01:00,  1.37it/s, loss=0.372, lr=1.06e-6, epoch=2, batch_id=87]\u001b[A\n",
            "steps:  71%|███████▏  | 208/291 [02:39<01:00,  1.37it/s, loss=0.342, lr=1.04e-6, epoch=2, batch_id=95]\u001b[A\n",
            "steps:  72%|███████▏  | 209/291 [02:39<01:01,  1.34it/s, loss=0.342, lr=1.04e-6, epoch=2, batch_id=95]\u001b[A\n",
            "steps:  72%|███████▏  | 209/291 [02:39<01:01,  1.34it/s, loss=0.34, lr=1.02e-6, epoch=2, batch_id=103]\u001b[A\n",
            "steps:  72%|███████▏  | 210/291 [02:40<01:00,  1.35it/s, loss=0.34, lr=1.02e-6, epoch=2, batch_id=103]\u001b[A\n",
            "steps:  72%|███████▏  | 210/291 [02:40<01:00,  1.35it/s, loss=0.347, lr=9.95e-7, epoch=2, batch_id=111]\u001b[A\n",
            "steps:  73%|███████▎  | 211/291 [02:41<00:59,  1.35it/s, loss=0.347, lr=9.95e-7, epoch=2, batch_id=111]\u001b[A\n",
            "steps:  73%|███████▎  | 211/291 [02:41<00:59,  1.35it/s, loss=0.356, lr=9.73e-7, epoch=2, batch_id=119]\u001b[A\n",
            "steps:  73%|███████▎  | 212/291 [02:41<00:57,  1.37it/s, loss=0.356, lr=9.73e-7, epoch=2, batch_id=119]\u001b[A\n",
            "steps:  73%|███████▎  | 212/291 [02:41<00:57,  1.37it/s, loss=0.357, lr=9.51e-7, epoch=2, batch_id=127]\u001b[A\n",
            "steps:  73%|███████▎  | 213/291 [02:42<00:55,  1.41it/s, loss=0.357, lr=9.51e-7, epoch=2, batch_id=127]\u001b[A\n",
            "steps:  73%|███████▎  | 213/291 [02:42<00:55,  1.41it/s, loss=0.374, lr=9.29e-7, epoch=2, batch_id=135]\u001b[A\n",
            "steps:  74%|███████▎  | 214/291 [02:43<00:55,  1.38it/s, loss=0.374, lr=9.29e-7, epoch=2, batch_id=135]\u001b[A\n",
            "steps:  74%|███████▎  | 214/291 [02:43<00:55,  1.38it/s, loss=0.359, lr=9.07e-7, epoch=2, batch_id=143]\u001b[A\n",
            "steps:  74%|███████▍  | 215/291 [02:44<00:53,  1.41it/s, loss=0.359, lr=9.07e-7, epoch=2, batch_id=143]\u001b[A\n",
            "steps:  74%|███████▍  | 215/291 [02:44<00:53,  1.41it/s, loss=0.349, lr=8.86e-7, epoch=2, batch_id=151]\u001b[A\n",
            "steps:  74%|███████▍  | 216/291 [02:44<00:53,  1.40it/s, loss=0.349, lr=8.86e-7, epoch=2, batch_id=151]\u001b[A\n",
            "steps:  74%|███████▍  | 216/291 [02:44<00:53,  1.40it/s, loss=0.348, lr=8.65e-7, epoch=2, batch_id=159]\u001b[A\n",
            "steps:  75%|███████▍  | 217/291 [02:45<00:49,  1.48it/s, loss=0.348, lr=8.65e-7, epoch=2, batch_id=159]\u001b[A\n",
            "steps:  75%|███████▍  | 217/291 [02:45<00:49,  1.48it/s, loss=0.345, lr=8.44e-7, epoch=2, batch_id=167]\u001b[A\n",
            "steps:  75%|███████▍  | 218/291 [02:46<00:49,  1.46it/s, loss=0.345, lr=8.44e-7, epoch=2, batch_id=167]\u001b[A\n",
            "steps:  75%|███████▍  | 218/291 [02:46<00:49,  1.46it/s, loss=0.336, lr=8.23e-7, epoch=2, batch_id=175]\u001b[A\n",
            "steps:  75%|███████▌  | 219/291 [02:46<00:49,  1.44it/s, loss=0.336, lr=8.23e-7, epoch=2, batch_id=175]\u001b[A\n",
            "steps:  75%|███████▌  | 219/291 [02:46<00:49,  1.44it/s, loss=0.346, lr=8.02e-7, epoch=2, batch_id=183]\u001b[A\n",
            "steps:  76%|███████▌  | 220/291 [02:47<00:48,  1.45it/s, loss=0.346, lr=8.02e-7, epoch=2, batch_id=183]\u001b[A\n",
            "steps:  76%|███████▌  | 220/291 [02:47<00:48,  1.45it/s, loss=0.362, lr=7.82e-7, epoch=2, batch_id=191]\u001b[A\n",
            "steps:  76%|███████▌  | 221/291 [02:48<00:48,  1.46it/s, loss=0.362, lr=7.82e-7, epoch=2, batch_id=191]\u001b[A\n",
            "steps:  76%|███████▌  | 221/291 [02:48<00:48,  1.46it/s, loss=0.351, lr=7.62e-7, epoch=2, batch_id=199]\u001b[A\n",
            "steps:  76%|███████▋  | 222/291 [02:48<00:47,  1.44it/s, loss=0.351, lr=7.62e-7, epoch=2, batch_id=199]\u001b[A\n",
            "steps:  76%|███████▋  | 222/291 [02:48<00:47,  1.44it/s, loss=0.358, lr=7.42e-7, epoch=2, batch_id=207]\u001b[A\n",
            "steps:  77%|███████▋  | 223/291 [02:49<00:46,  1.45it/s, loss=0.358, lr=7.42e-7, epoch=2, batch_id=207]\u001b[A\n",
            "steps:  77%|███████▋  | 223/291 [02:49<00:46,  1.45it/s, loss=0.352, lr=7.22e-7, epoch=2, batch_id=215]\u001b[A\n",
            "steps:  77%|███████▋  | 224/291 [02:50<00:44,  1.49it/s, loss=0.352, lr=7.22e-7, epoch=2, batch_id=215]\u001b[A\n",
            "steps:  77%|███████▋  | 224/291 [02:50<00:44,  1.49it/s, loss=0.338, lr=7.03e-7, epoch=2, batch_id=223]\u001b[A\n",
            "steps:  77%|███████▋  | 225/291 [02:50<00:45,  1.44it/s, loss=0.338, lr=7.03e-7, epoch=2, batch_id=223]\u001b[A\n",
            "steps:  77%|███████▋  | 225/291 [02:50<00:45,  1.44it/s, loss=0.348, lr=6.84e-7, epoch=2, batch_id=231]\u001b[A\n",
            "steps:  78%|███████▊  | 226/291 [02:51<00:46,  1.39it/s, loss=0.348, lr=6.84e-7, epoch=2, batch_id=231]\u001b[A\n",
            "steps:  78%|███████▊  | 226/291 [02:51<00:46,  1.39it/s, loss=0.368, lr=6.65e-7, epoch=2, batch_id=239]\u001b[A\n",
            "steps:  78%|███████▊  | 227/291 [02:52<00:46,  1.38it/s, loss=0.368, lr=6.65e-7, epoch=2, batch_id=239]\u001b[A\n",
            "steps:  78%|███████▊  | 227/291 [02:52<00:46,  1.38it/s, loss=0.361, lr=6.46e-7, epoch=2, batch_id=247]\u001b[A\n",
            "steps:  78%|███████▊  | 228/291 [02:53<00:45,  1.38it/s, loss=0.361, lr=6.46e-7, epoch=2, batch_id=247]\u001b[A\n",
            "steps:  78%|███████▊  | 228/291 [02:53<00:45,  1.38it/s, loss=0.345, lr=6.27e-7, epoch=2, batch_id=255]\u001b[A\n",
            "steps:  79%|███████▊  | 229/291 [02:53<00:44,  1.40it/s, loss=0.345, lr=6.27e-7, epoch=2, batch_id=255]\u001b[A\n",
            "steps:  79%|███████▊  | 229/291 [02:53<00:44,  1.40it/s, loss=0.349, lr=6.09e-7, epoch=2, batch_id=263]\u001b[A\n",
            "steps:  79%|███████▉  | 230/291 [02:54<00:43,  1.39it/s, loss=0.349, lr=6.09e-7, epoch=2, batch_id=263]\u001b[A\n",
            "steps:  79%|███████▉  | 230/291 [02:54<00:43,  1.39it/s, loss=0.341, lr=5.91e-7, epoch=2, batch_id=271]\u001b[A\n",
            "steps:  79%|███████▉  | 231/291 [02:55<00:43,  1.39it/s, loss=0.341, lr=5.91e-7, epoch=2, batch_id=271]\u001b[A\n",
            "steps:  79%|███████▉  | 231/291 [02:55<00:43,  1.39it/s, loss=0.354, lr=5.73e-7, epoch=2, batch_id=279]\u001b[A\n",
            "steps:  80%|███████▉  | 232/291 [02:56<00:42,  1.40it/s, loss=0.354, lr=5.73e-7, epoch=2, batch_id=279]\u001b[A\n",
            "steps:  80%|███████▉  | 232/291 [02:56<00:42,  1.40it/s, loss=0.349, lr=5.55e-7, epoch=2, batch_id=287]\u001b[A\n",
            "steps:  80%|████████  | 233/291 [02:56<00:41,  1.40it/s, loss=0.349, lr=5.55e-7, epoch=2, batch_id=287]\u001b[A\n",
            "steps:  80%|████████  | 233/291 [02:56<00:41,  1.40it/s, loss=0.357, lr=5.38e-7, epoch=2, batch_id=295]\u001b[A\n",
            "steps:  80%|████████  | 234/291 [02:57<00:39,  1.45it/s, loss=0.357, lr=5.38e-7, epoch=2, batch_id=295]\u001b[A\n",
            "steps:  80%|████████  | 234/291 [02:57<00:39,  1.45it/s, loss=0.335, lr=5.21e-7, epoch=2, batch_id=303]\u001b[A\n",
            "steps:  81%|████████  | 235/291 [02:58<00:39,  1.43it/s, loss=0.335, lr=5.21e-7, epoch=2, batch_id=303]\u001b[A\n",
            "steps:  81%|████████  | 235/291 [02:58<00:39,  1.43it/s, loss=0.339, lr=5.04e-7, epoch=2, batch_id=311]\u001b[A\n",
            "steps:  81%|████████  | 236/291 [02:58<00:39,  1.40it/s, loss=0.339, lr=5.04e-7, epoch=2, batch_id=311]\u001b[A\n",
            "steps:  81%|████████  | 236/291 [02:58<00:39,  1.40it/s, loss=0.359, lr=4.87e-7, epoch=2, batch_id=319]\u001b[A\n",
            "steps:  81%|████████▏ | 237/291 [02:59<00:38,  1.39it/s, loss=0.359, lr=4.87e-7, epoch=2, batch_id=319]\u001b[A\n",
            "steps:  81%|████████▏ | 237/291 [02:59<00:38,  1.39it/s, loss=0.363, lr=4.71e-7, epoch=2, batch_id=327]\u001b[A\n",
            "steps:  82%|████████▏ | 238/291 [03:00<00:37,  1.40it/s, loss=0.363, lr=4.71e-7, epoch=2, batch_id=327]\u001b[A\n",
            "steps:  82%|████████▏ | 238/291 [03:00<00:37,  1.40it/s, loss=0.345, lr=4.55e-7, epoch=2, batch_id=335]\u001b[A\n",
            "steps:  82%|████████▏ | 239/291 [03:00<00:37,  1.39it/s, loss=0.345, lr=4.55e-7, epoch=2, batch_id=335]\u001b[A\n",
            "steps:  82%|████████▏ | 239/291 [03:00<00:37,  1.39it/s, loss=0.346, lr=4.39e-7, epoch=2, batch_id=343]\u001b[A\n",
            "steps:  82%|████████▏ | 240/291 [03:01<00:36,  1.41it/s, loss=0.346, lr=4.39e-7, epoch=2, batch_id=343]\u001b[A\n",
            "steps:  82%|████████▏ | 240/291 [03:01<00:36,  1.41it/s, loss=0.359, lr=4.23e-7, epoch=2, batch_id=351]\u001b[A\n",
            "steps:  83%|████████▎ | 241/291 [03:02<00:35,  1.40it/s, loss=0.359, lr=4.23e-7, epoch=2, batch_id=351]\u001b[A\n",
            "steps:  83%|████████▎ | 241/291 [03:02<00:35,  1.40it/s, loss=0.346, lr=4.08e-7, epoch=2, batch_id=359]\u001b[A\n",
            "steps:  83%|████████▎ | 242/291 [03:03<00:34,  1.41it/s, loss=0.346, lr=4.08e-7, epoch=2, batch_id=359]\u001b[A\n",
            "steps:  83%|████████▎ | 242/291 [03:03<00:34,  1.41it/s, loss=0.353, lr=3.93e-7, epoch=2, batch_id=367]\u001b[A\n",
            "steps:  84%|████████▎ | 243/291 [03:03<00:34,  1.40it/s, loss=0.353, lr=3.93e-7, epoch=2, batch_id=367]\u001b[A\n",
            "steps:  84%|████████▎ | 243/291 [03:03<00:34,  1.40it/s, loss=0.342, lr=3.78e-7, epoch=2, batch_id=375]\u001b[A\n",
            "steps:  84%|████████▍ | 244/291 [03:04<00:33,  1.39it/s, loss=0.342, lr=3.78e-7, epoch=2, batch_id=375]\u001b[A\n",
            "steps:  84%|████████▍ | 244/291 [03:04<00:33,  1.39it/s, loss=0.318, lr=3.63e-7, epoch=2, batch_id=383]\u001b[A\n",
            "steps:  84%|████████▍ | 245/291 [03:05<00:31,  1.44it/s, loss=0.318, lr=3.63e-7, epoch=2, batch_id=383]\u001b[A\n",
            "steps:  84%|████████▍ | 245/291 [03:05<00:31,  1.44it/s, loss=0.346, lr=3.49e-7, epoch=2, batch_id=391]\u001b[A\n",
            "steps:  85%|████████▍ | 246/291 [03:05<00:30,  1.46it/s, loss=0.346, lr=3.49e-7, epoch=2, batch_id=391]\u001b[A\n",
            "steps:  85%|████████▍ | 246/291 [03:05<00:30,  1.46it/s, loss=0.369, lr=3.35e-7, epoch=2, batch_id=399]\u001b[A\n",
            "steps:  85%|████████▍ | 247/291 [03:06<00:32,  1.37it/s, loss=0.369, lr=3.35e-7, epoch=2, batch_id=399]\u001b[A\n",
            "steps:  85%|████████▍ | 247/291 [03:06<00:32,  1.37it/s, loss=0.363, lr=3.21e-7, epoch=2, batch_id=407]\u001b[A\n",
            "steps:  85%|████████▌ | 248/291 [03:07<00:31,  1.38it/s, loss=0.363, lr=3.21e-7, epoch=2, batch_id=407]\u001b[A\n",
            "steps:  85%|████████▌ | 248/291 [03:07<00:31,  1.38it/s, loss=0.353, lr=3.08e-7, epoch=2, batch_id=415]\u001b[A\n",
            "steps:  86%|████████▌ | 249/291 [03:08<00:30,  1.38it/s, loss=0.353, lr=3.08e-7, epoch=2, batch_id=415]\u001b[A\n",
            "steps:  86%|████████▌ | 249/291 [03:08<00:30,  1.38it/s, loss=0.331, lr=2.94e-7, epoch=2, batch_id=423]\u001b[A\n",
            "steps:  86%|████████▌ | 250/291 [03:08<00:29,  1.41it/s, loss=0.331, lr=2.94e-7, epoch=2, batch_id=423]\u001b[A\n",
            "steps:  86%|████████▌ | 250/291 [03:08<00:29,  1.41it/s, loss=0.329, lr=2.81e-7, epoch=2, batch_id=431]\u001b[A\n",
            "steps:  86%|████████▋ | 251/291 [03:09<00:27,  1.43it/s, loss=0.329, lr=2.81e-7, epoch=2, batch_id=431]\u001b[A\n",
            "steps:  86%|████████▋ | 251/291 [03:09<00:27,  1.43it/s, loss=0.349, lr=2.69e-7, epoch=2, batch_id=439]\u001b[A\n",
            "steps:  87%|████████▋ | 252/291 [03:10<00:27,  1.43it/s, loss=0.349, lr=2.69e-7, epoch=2, batch_id=439]\u001b[A\n",
            "steps:  87%|████████▋ | 252/291 [03:10<00:27,  1.43it/s, loss=0.366, lr=2.56e-7, epoch=2, batch_id=447]\u001b[A\n",
            "steps:  87%|████████▋ | 253/291 [03:10<00:26,  1.43it/s, loss=0.366, lr=2.56e-7, epoch=2, batch_id=447]\u001b[A\n",
            "steps:  87%|████████▋ | 253/291 [03:10<00:26,  1.43it/s, loss=0.361, lr=2.44e-7, epoch=2, batch_id=455]\u001b[A\n",
            "steps:  87%|████████▋ | 254/291 [03:11<00:25,  1.44it/s, loss=0.361, lr=2.44e-7, epoch=2, batch_id=455]\u001b[A\n",
            "steps:  87%|████████▋ | 254/291 [03:11<00:25,  1.44it/s, loss=0.358, lr=2.32e-7, epoch=2, batch_id=463]\u001b[A\n",
            "steps:  88%|████████▊ | 255/291 [03:12<00:25,  1.43it/s, loss=0.358, lr=2.32e-7, epoch=2, batch_id=463]\u001b[A\n",
            "steps:  88%|████████▊ | 255/291 [03:12<00:25,  1.43it/s, loss=0.364, lr=2.21e-7, epoch=2, batch_id=471]\u001b[A\n",
            "steps:  88%|████████▊ | 256/291 [03:12<00:24,  1.44it/s, loss=0.364, lr=2.21e-7, epoch=2, batch_id=471]\u001b[A\n",
            "steps:  88%|████████▊ | 256/291 [03:12<00:24,  1.44it/s, loss=0.358, lr=2.09e-7, epoch=2, batch_id=479]\u001b[A\n",
            "steps:  88%|████████▊ | 257/291 [03:13<00:24,  1.40it/s, loss=0.358, lr=2.09e-7, epoch=2, batch_id=479]\u001b[A\n",
            "steps:  88%|████████▊ | 257/291 [03:13<00:24,  1.40it/s, loss=0.364, lr=1.98e-7, epoch=2, batch_id=487]\u001b[A\n",
            "steps:  89%|████████▊ | 258/291 [03:14<00:23,  1.41it/s, loss=0.364, lr=1.98e-7, epoch=2, batch_id=487]\u001b[A\n",
            "steps:  89%|████████▊ | 258/291 [03:14<00:23,  1.41it/s, loss=0.349, lr=1.88e-7, epoch=2, batch_id=495]\u001b[A\n",
            "steps:  89%|████████▉ | 259/291 [03:15<00:22,  1.43it/s, loss=0.349, lr=1.88e-7, epoch=2, batch_id=495]\u001b[A\n",
            "steps:  89%|████████▉ | 259/291 [03:15<00:22,  1.43it/s, loss=0.358, lr=1.77e-7, epoch=2, batch_id=503]\u001b[A\n",
            "steps:  89%|████████▉ | 260/291 [03:15<00:21,  1.46it/s, loss=0.358, lr=1.77e-7, epoch=2, batch_id=503]\u001b[A\n",
            "steps:  89%|████████▉ | 260/291 [03:15<00:21,  1.46it/s, loss=0.354, lr=1.67e-7, epoch=2, batch_id=511]\u001b[A\n",
            "steps:  90%|████████▉ | 261/291 [03:16<00:20,  1.45it/s, loss=0.354, lr=1.67e-7, epoch=2, batch_id=511]\u001b[A\n",
            "steps:  90%|████████▉ | 261/291 [03:16<00:20,  1.45it/s, loss=0.355, lr=1.57e-7, epoch=2, batch_id=519]\u001b[A\n",
            "steps:  90%|█████████ | 262/291 [03:17<00:19,  1.46it/s, loss=0.355, lr=1.57e-7, epoch=2, batch_id=519]\u001b[A\n",
            "steps:  90%|█████████ | 262/291 [03:17<00:19,  1.46it/s, loss=0.358, lr=1.48e-7, epoch=2, batch_id=527]\u001b[A\n",
            "steps:  90%|█████████ | 263/291 [03:17<00:20,  1.39it/s, loss=0.358, lr=1.48e-7, epoch=2, batch_id=527]\u001b[A\n",
            "steps:  90%|█████████ | 263/291 [03:17<00:20,  1.39it/s, loss=0.374, lr=1.38e-7, epoch=2, batch_id=535]\u001b[A\n",
            "steps:  91%|█████████ | 264/291 [03:18<00:18,  1.42it/s, loss=0.374, lr=1.38e-7, epoch=2, batch_id=535]\u001b[A\n",
            "steps:  91%|█████████ | 264/291 [03:18<00:18,  1.42it/s, loss=0.374, lr=1.29e-7, epoch=2, batch_id=543]\u001b[A\n",
            "steps:  91%|█████████ | 265/291 [03:19<00:18,  1.42it/s, loss=0.374, lr=1.29e-7, epoch=2, batch_id=543]\u001b[A\n",
            "steps:  91%|█████████ | 265/291 [03:19<00:18,  1.42it/s, loss=0.359, lr=1.21e-7, epoch=2, batch_id=551]\u001b[A\n",
            "steps:  91%|█████████▏| 266/291 [03:20<00:18,  1.39it/s, loss=0.359, lr=1.21e-7, epoch=2, batch_id=551]\u001b[A\n",
            "steps:  91%|█████████▏| 266/291 [03:20<00:18,  1.39it/s, loss=0.334, lr=1.12e-7, epoch=2, batch_id=559]\u001b[A\n",
            "steps:  92%|█████████▏| 267/291 [03:20<00:17,  1.39it/s, loss=0.334, lr=1.12e-7, epoch=2, batch_id=559]\u001b[A\n",
            "steps:  92%|█████████▏| 267/291 [03:20<00:17,  1.39it/s, loss=0.339, lr=1.04e-7, epoch=2, batch_id=567]\u001b[A\n",
            "steps:  92%|█████████▏| 268/291 [03:21<00:16,  1.43it/s, loss=0.339, lr=1.04e-7, epoch=2, batch_id=567]\u001b[A\n",
            "steps:  92%|█████████▏| 268/291 [03:21<00:16,  1.43it/s, loss=0.366, lr=9.63e-8, epoch=2, batch_id=575]\u001b[A\n",
            "steps:  92%|█████████▏| 269/291 [03:22<00:15,  1.44it/s, loss=0.366, lr=9.63e-8, epoch=2, batch_id=575]\u001b[A\n",
            "steps:  92%|█████████▏| 269/291 [03:22<00:15,  1.44it/s, loss=0.35, lr=8.88e-8, epoch=2, batch_id=583] \u001b[A\n",
            "steps:  93%|█████████▎| 270/291 [03:22<00:14,  1.42it/s, loss=0.35, lr=8.88e-8, epoch=2, batch_id=583]\u001b[A\n",
            "steps:  93%|█████████▎| 270/291 [03:22<00:14,  1.42it/s, loss=0.355, lr=8.16e-8, epoch=2, batch_id=591]\u001b[A\n",
            "steps:  93%|█████████▎| 271/291 [03:23<00:13,  1.44it/s, loss=0.355, lr=8.16e-8, epoch=2, batch_id=591]\u001b[A\n",
            "steps:  93%|█████████▎| 271/291 [03:23<00:13,  1.44it/s, loss=0.355, lr=7.47e-8, epoch=2, batch_id=599]\u001b[A\n",
            "steps:  93%|█████████▎| 272/291 [03:24<00:13,  1.43it/s, loss=0.355, lr=7.47e-8, epoch=2, batch_id=599]\u001b[A\n",
            "steps:  93%|█████████▎| 272/291 [03:24<00:13,  1.43it/s, loss=0.35, lr=6.81e-8, epoch=2, batch_id=607] \u001b[A\n",
            "steps:  94%|█████████▍| 273/291 [03:24<00:12,  1.43it/s, loss=0.35, lr=6.81e-8, epoch=2, batch_id=607]\u001b[A\n",
            "steps:  94%|█████████▍| 273/291 [03:24<00:12,  1.43it/s, loss=0.343, lr=6.18e-8, epoch=2, batch_id=615]\u001b[A\n",
            "steps:  94%|█████████▍| 274/291 [03:25<00:12,  1.40it/s, loss=0.343, lr=6.18e-8, epoch=2, batch_id=615]\u001b[A\n",
            "steps:  94%|█████████▍| 274/291 [03:25<00:12,  1.40it/s, loss=0.35, lr=5.58e-8, epoch=2, batch_id=623] \u001b[A\n",
            "steps:  95%|█████████▍| 275/291 [03:26<00:11,  1.38it/s, loss=0.35, lr=5.58e-8, epoch=2, batch_id=623]\u001b[A\n",
            "steps:  95%|█████████▍| 275/291 [03:26<00:11,  1.38it/s, loss=0.352, lr=5.01e-8, epoch=2, batch_id=631]\u001b[A\n",
            "steps:  95%|█████████▍| 276/291 [03:27<00:10,  1.42it/s, loss=0.352, lr=5.01e-8, epoch=2, batch_id=631]\u001b[A\n",
            "steps:  95%|█████████▍| 276/291 [03:27<00:10,  1.42it/s, loss=0.363, lr=4.47e-8, epoch=2, batch_id=639]\u001b[A\n",
            "steps:  95%|█████████▌| 277/291 [03:27<00:09,  1.43it/s, loss=0.363, lr=4.47e-8, epoch=2, batch_id=639]\u001b[A\n",
            "steps:  95%|█████████▌| 277/291 [03:27<00:09,  1.43it/s, loss=0.35, lr=3.96e-8, epoch=2, batch_id=647] \u001b[A\n",
            "steps:  96%|█████████▌| 278/291 [03:28<00:09,  1.42it/s, loss=0.35, lr=3.96e-8, epoch=2, batch_id=647]\u001b[A\n",
            "steps:  96%|█████████▌| 278/291 [03:28<00:09,  1.42it/s, loss=0.337, lr=3.48e-8, epoch=2, batch_id=655]\u001b[A\n",
            "steps:  96%|█████████▌| 279/291 [03:29<00:08,  1.37it/s, loss=0.337, lr=3.48e-8, epoch=2, batch_id=655]\u001b[A\n",
            "steps:  96%|█████████▌| 279/291 [03:29<00:08,  1.37it/s, loss=0.359, lr=3.03e-8, epoch=2, batch_id=663]\u001b[A\n",
            "steps:  96%|█████████▌| 280/291 [03:29<00:07,  1.40it/s, loss=0.359, lr=3.03e-8, epoch=2, batch_id=663]\u001b[A\n",
            "steps:  96%|█████████▌| 280/291 [03:29<00:07,  1.40it/s, loss=0.338, lr=2.62e-8, epoch=2, batch_id=671]\u001b[A\n",
            "steps:  97%|█████████▋| 281/291 [03:30<00:07,  1.40it/s, loss=0.338, lr=2.62e-8, epoch=2, batch_id=671]\u001b[A\n",
            "steps:  97%|█████████▋| 281/291 [03:30<00:07,  1.40it/s, loss=0.357, lr=2.23e-8, epoch=2, batch_id=679]\u001b[A\n",
            "steps:  97%|█████████▋| 282/291 [03:31<00:06,  1.39it/s, loss=0.357, lr=2.23e-8, epoch=2, batch_id=679]\u001b[A\n",
            "steps:  97%|█████████▋| 282/291 [03:31<00:06,  1.39it/s, loss=0.368, lr=1.87e-8, epoch=2, batch_id=687]\u001b[A\n",
            "steps:  97%|█████████▋| 283/291 [03:32<00:05,  1.43it/s, loss=0.368, lr=1.87e-8, epoch=2, batch_id=687]\u001b[A\n",
            "steps:  97%|█████████▋| 283/291 [03:32<00:05,  1.43it/s, loss=0.355, lr=1.55e-8, epoch=2, batch_id=695]\u001b[A\n",
            "steps:  98%|█████████▊| 284/291 [03:32<00:04,  1.44it/s, loss=0.355, lr=1.55e-8, epoch=2, batch_id=695]\u001b[A\n",
            "steps:  98%|█████████▊| 284/291 [03:32<00:04,  1.44it/s, loss=0.348, lr=1.26e-8, epoch=2, batch_id=703]\u001b[A\n",
            "steps:  98%|█████████▊| 285/291 [03:33<00:04,  1.44it/s, loss=0.348, lr=1.26e-8, epoch=2, batch_id=703]\u001b[A\n",
            "steps:  98%|█████████▊| 285/291 [03:33<00:04,  1.44it/s, loss=0.334, lr=9.92e-9, epoch=2, batch_id=711]\u001b[A\n",
            "steps:  98%|█████████▊| 286/291 [03:34<00:03,  1.46it/s, loss=0.334, lr=9.92e-9, epoch=2, batch_id=711]\u001b[A\n",
            "steps:  98%|█████████▊| 286/291 [03:34<00:03,  1.46it/s, loss=0.348, lr=7.6e-9, epoch=2, batch_id=719] \u001b[A\n",
            "steps:  99%|█████████▊| 287/291 [03:34<00:02,  1.46it/s, loss=0.348, lr=7.6e-9, epoch=2, batch_id=719]\u001b[A\n",
            "steps:  99%|█████████▊| 287/291 [03:34<00:02,  1.46it/s, loss=0.353, lr=5.58e-9, epoch=2, batch_id=727]\u001b[A\n",
            "steps:  99%|█████████▉| 288/291 [03:35<00:02,  1.44it/s, loss=0.353, lr=5.58e-9, epoch=2, batch_id=727]\u001b[A\n",
            "steps:  99%|█████████▉| 288/291 [03:35<00:02,  1.44it/s, loss=0.347, lr=3.88e-9, epoch=2, batch_id=735]\u001b[A\n",
            "steps:  99%|█████████▉| 289/291 [03:36<00:01,  1.39it/s, loss=0.347, lr=3.88e-9, epoch=2, batch_id=735]\u001b[A\n",
            "steps:  99%|█████████▉| 289/291 [03:36<00:01,  1.39it/s, loss=0.34, lr=2.48e-9, epoch=2, batch_id=743] \u001b[A\n",
            "steps: 100%|█████████▉| 290/291 [03:36<00:00,  1.37it/s, loss=0.34, lr=2.48e-9, epoch=2, batch_id=743]\u001b[A\n",
            "steps: 100%|█████████▉| 290/291 [03:37<00:00,  1.37it/s, loss=0.341, lr=1.4e-9, epoch=2, batch_id=751]\u001b[A\n",
            "steps: 100%|██████████| 291/291 [03:37<00:00,  1.36it/s, loss=0.341, lr=1.4e-9, epoch=2, batch_id=751]\u001b[A\n",
            "steps: 100%|██████████| 291/291 [03:37<00:00,  1.36it/s, loss=0.351, lr=6.21e-10, epoch=2, batch_id=759]\u001b[A\n",
            "steps: 292it [03:38,  1.40it/s, loss=0.351, lr=6.21e-10, epoch=2, batch_id=759]                         \u001b[A\n",
            "steps: 292it [03:38,  1.40it/s, loss=0.346, lr=1.55e-10, epoch=2, batch_id=767]\u001b[A\n",
            "steps: 293it [03:39,  1.40it/s, loss=0.346, lr=1.55e-10, epoch=2, batch_id=767]\u001b[A\n",
            "steps: 293it [03:39,  1.40it/s, loss=0.362, lr=0, epoch=2, batch_id=775]       \u001b[A\n",
            "steps: 294it [03:45,  2.37s/it, loss=0.362, lr=0, epoch=2, batch_id=775]\u001b[A\n",
            "steps: 294it [03:45,  1.30it/s, epoch=2, eval_loss=0.668]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la ./output_1_sft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1HboVoaCdMi",
        "outputId": "a8c8add5-47ca-4f0e-f8bc-23715c3270d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 499884\n",
            "drwxr-xr-x 2 root root      4096 Apr 10 01:20 .\n",
            "drwxr-xr-x 1 root root      4096 Apr 10 01:20 ..\n",
            "-rw-r--r-- 1 root root       907 Apr 10 01:20 config.json\n",
            "-rw-r--r-- 1 root root       119 Apr 10 01:20 generation_config.json\n",
            "-rw-r--r-- 1 root root    456318 Apr 10 01:20 merges.txt\n",
            "-rw-r--r-- 1 root root 510398013 Apr 10 01:20 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root       470 Apr 10 01:20 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root       722 Apr 10 01:20 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    999186 Apr 10 01:20 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8rnWI0iWwLb1",
        "outputId": "15fb67a8-aaed-4d2c-e06e-0d725f3f2ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "completion: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "I've noticed when scanning my files for malware/viruses, the \"number of files scanned\" that pops up is almost always greater than the number of files I selected to scan. What is actually being scanned and why is it considered different files?\n",
            "\n",
            "### Response:There are many factors that influence the amount of information that a software program has to send out to a user. The most important is what type of file or directory you have in there. You can download files from any web site, so your computer's internet service provider will usually provide them as well. For example, if\n",
            "\n",
            "### Actual answer:\n",
            "Microsoft Defender Antivirus has multiple layers of protection to catch malware and viruses. These include quick scans, full scans, and on-access protection with cloud-delivered protection [1,2,3]. A quick scan checks the processes, memory, profiles, and certain locations on the device [1]. Real-time protection reviews files when they are opened and closed and whenever a user navigates to a folder [1,2]. On-access protection with cloud-delivered protection helps ensure that all the files accessed on the system are being scanned with the latest security intelligence and cloud machine learning models [3]. A full scan detects malware that was not detected by other scans, but it can take a while and use valuable system resources to complete [3]. It can also take longer to complete if the device is offline for an extended period of time [3].\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "completion: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "How the Obama talk, which has 159,313 upvotes, is not higher all-time than \"Test Post Please Ignore\" with 26,753 upvotes.\n",
            "\n",
            "I'm assuming the difference is that the Reddit system accounts and tries to correct massive upvotes, but why is it being so much harsher to the Obama AMA? Shouldn't it level out over time, not decrease?\n",
            "\n",
            "### Response:The reddit system, which was built in 2009, uses a process known as \"redrawing\", where users post comments on a subreddit and see what others think about them. Users then rank these comments based on the number of replies they've received from those members who agree with them.[1] Redrawing works by\n",
            "\n",
            "### Actual answer:\n",
            "Reddit uses a story algorithm to rank posts. This means that the number of votes and the time a link has been posted have the biggest impact on where a story will rank. Additionally, Reddit also ranks items by the number of votes they accumulate, as well as the age of the post compared to others. [1, 3]\n",
            " sulphReddit also uses a logarithm function in its algorithm. This means that after the first few minutes of the post going live, the initial reactions are crucial to its future survival. If the post instantly achieves upvotes right after posting, more users will be likely to see the post. If it happens later, then the relevance of the post is diminished, so reactions hold weight. [2, 3] This means that newer posts generally rank higher than older posts. This keeps the front page fresh, and ensures that links with thousands of up-votes aren’t stuck on the front page for weeks or months at a time. Stories that get a more equal range of up-votes and down-votes will generally be ranked lower. [3]\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "completion: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "if micro- and macro-physics equations are incompatible, at roughly what size does each start being descriptive? Is there overlap, and if not, are there \"in-between\" sizes that could be studied?\n",
            "\n",
            "Also, aside from string theory, what efforts are currently being made to bridge the gap?\n",
            "\n",
            "### Response:There are several theories on the origins of cosmological constants [1]. Some say that the universe itself began out of thin air [2]. Others suggest that this was the place where the origin of light came into existence [3]. These theories have been widely debated since the 1980s [4]. One possibility is that\n",
            "\n",
            "### Actual answer:\n",
            "The laws of physics are considered fundamental, although many of them refer to idealized or theoretical systems that are hard to replicate in the real world [3]. The behavior of particles in the micro-physical world is so unpredictable from the known laws that operate in the macro-physical world that Niels Bohr reputedly said, “Anyone who is not shocked by quantum mechanics has not really understood it” [1]. Schrodinger – a pioneer in quantum mechanics - reputedly said, “I don’t like it and I wish I had had nothing to do with it” [1].\n",
            "\n",
            "String theory and quantum gravitation are attempts to reconcile the two – among them string theory and quantum gravitation [2]. In fact, the marriage of quantum mechanics – the physics of the very small – with general relativity – the physics of the very large – is believed by some to be the crucial step in formulating a general ‘theory of everything’ that will hopefully contain all the basic laws of nature in one package [5]. Quantum mechanics has had extraordinary successes in explaining everything from the state of the universe immediately after the big bang, to the structure of DNA, to the colour of your socks [6].\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "completion: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "- You know how you can flick a switch on a rearview mirror and it reduces glare while still being reflective? How does that work?\n",
            "\n",
            "### Response:The lens of the front f/1.8 aperture produces a very wide angle of view compared to its equivalent focal length of 2.4 inches. When viewed at infinity, this narrows the field of view available for each image by approximately 50%. This effect is best seen in bright sunlight, when the sun is about\n",
            "\n",
            "### Actual answer:\n",
            "Rearview mirrors have two reflective surfaces, a regular mirror on the back, and a glass wedge in front of it that reflects only about four percent of the incoming light [1]. When you flip the switch on the bottom of the mirror, the glass wedge moves, changing the way light passes through it and how it's reflected [2][3]. In daytime driving mode, the back surface of the mirror reflects light and images [3]. When you flip the switch and change the orientation of the mirror glass, the front section is responsible for what you see [3]. Because the light and images must first travel through the back side of the glass before hitting the front and bouncing back to you, the image is dimmer and the glare of headlights behind you is greatly reduced [3][4].\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "completion: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "How does negaive mass work in physics?\n",
            "\n",
            "I saw the article below and wondered how it could be possible to have a negative mass. \n",
            "\n",
            "https://www.reddit.com/r/space/comments/a3a33c/scientists_may_have_solved_one_of_the_biggest/?utm_source=reddit-android\n",
            "\n",
            "How will it behave in a classical situation? How would gravity interact with a negative mass? \n",
            "\n",
            "### Response:A negative mass of zero means you can't actually move much at all. But if you go through the motions, the gravitational force pulling you towards the destination causes you to float on the ground, thus moving faster than you should. There are three ways to describe this phenomenon: Gravity, inertia, and electromagnetism\n",
            "\n",
            "### Actual answer:\n",
            "In theoretical physics, negative mass is a type of matter whose mass is of opposite sign to the mass of normal matter [1]. The mass of normal matter is defined as positive mass [1] so therefore negative mass is mass that is actually negative. To create negative mass, the research team at Washington State University cooled rubidium atoms to just a hair above absolute zero, creating what is known as a Bose-Einstein condensate [3]. In this state, particles move extremely slowly and, following the principles of quantum mechanics, behave like waves [3]. They also synchronize and move in unison as what is known as a superfluid, which flows without losing energy [3]. To create the negative mass, the researchers applied a second set of lasers that kicked the atoms back and forth and changed the way they spin [3].\n"
          ]
        }
      ],
      "source": [
        "# Inference test.\n",
        "generator = pipeline(\"text-generation\", model=args.output_dir, tokenizer=tokenizer)\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    max_new_tokens=64,\n",
        "    do_sample=True,\n",
        "    top_k=30,\n",
        "    top_p=0.95,\n",
        "    temperature=1.9, \n",
        "    #max_length=300, \n",
        "    #num_return_sequences=20\n",
        "    early_stopping=True,\n",
        ")\n",
        "\n",
        "test_list = data_list[-5:]\n",
        "\n",
        "test_prompt_list = []\n",
        "actual_completion_list = []\n",
        "for row in test_list:\n",
        "    text_input = row\n",
        "    prompt = PROMPT_TEMPLATE.format_map(text_input)\n",
        "    test_prompt_list.append(prompt)\n",
        "    actual_completion_list.append(text_input[\"completion\"])\n",
        "\n",
        "result_list = generator(test_prompt_list, **generation_args)\n",
        "for prompt, result, actual_response in zip(test_prompt_list, result_list, actual_completion_list):\n",
        "    print(\"\")\n",
        "    print(\"-\" * 70)\n",
        "    print((\"completion: %s\" % (result[0][\"generated_text\"])))\n",
        "    print(f\"\\n### Actual answer:\\n{actual_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JoJpv-wAvY6"
      },
      "source": [
        "# Step 2) RM: Reward Model\n",
        "Train Reward Model to generate the better answer by giving a reward to the better answer.\n",
        "- Dataset example\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion_1\": \"\",\n",
        "        \"completion_2\": \"\",\n",
        "        \"completion_3\": \"\",            \n",
        "        \"ranking\": [1, 0, 2]\n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "- Dataset sources\n",
        "  - [Dahoas/rm-static](https://huggingface.co/datasets/Dahoas/rm-static)\n",
        "  - [openai/webgpt_comparisons](https://huggingface.co/datasets/openai/webgpt_comparisons)\n",
        "  - [openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)\n",
        "  - [Dahoas/instruct-synthetic-prompt-responses](https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise)\n",
        "\n",
        "- References\n",
        "    - [train_reward_model.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_reward_model.py)\n",
        "    - [train_prompts.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esYui6hPCuF-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "import loralib as lora\n",
        "\n",
        "from nextgpt.dataset import RewardDataset\n",
        "from nextgpt.models.base import RewardModel\n",
        "from nextgpt.models.bloom import BLOOMRM\n",
        "from nextgpt.models.gpt import GPTRM\n",
        "from nextgpt.models.opt import OPTRM\n",
        "from nextgpt.models import LogExpLoss, LogSigLoss\n",
        "from nextgpt.trainer import RewardModelTrainer\n",
        "from nextgpt.trainer.strategies import DDPStrategy, NaiveStrategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGnVyFvLSAjR",
        "outputId": "956acd20-1bb3-42f6-8665-33341117072a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(output_dir='./output_2_rm', strategy='naive', model='gpt2', pretrain='gpt2', model_path=None, need_optim_ckpt=False, max_epochs=3, batch_size=4, lora_rank=0, loss_fn='log_sig', max_len=512, verbose=True)\n"
          ]
        }
      ],
      "source": [
        "# Define arguments.\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"./output_2_rm\")\n",
        "parser.add_argument(\"--strategy\",\n",
        "                    type=str, \n",
        "                    choices=[\"naive\", \"ddp\"],\n",
        "                    default=\"naive\")\n",
        "parser.add_argument(\"--model\", \n",
        "                    type=str, \n",
        "                    choices=[\"gpt2\", \"bloom\", \"opt\"], \n",
        "                    default=\"gpt2\")\n",
        "parser.add_argument(\"--pretrain\", type=str, default=\"gpt2\")\n",
        "parser.add_argument(\"--model_path\", type=str, default=None)\n",
        "parser.add_argument(\"--need_optim_ckpt\", type=bool, default=False)\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--lora_rank\", type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument(\"--loss_fn\", \n",
        "                    type=str, \n",
        "                    choices=[\"log_sig\", \"log_exp\"],\n",
        "                    default=\"log_sig\")\n",
        "parser.add_argument(\"--max_len\", type=int, default=512)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# For test.\n",
        "args.max_epochs = 3\n",
        "args.pretrain = \"gpt2\" # pretrained initial model.\n",
        "args.verbose = True\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHEdwfvCwZTi"
      },
      "outputs": [],
      "source": [
        "# Configure strategy.\n",
        "if args.strategy == \"naive\":\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == \"ddp\":\n",
        "    strategy = DDPStrategy()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported strategy: {args.strategy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "b3c0f8e79f5e49ee89ca7814ed67867d",
            "3766fafa089c4969a39e6137a8dfaef7",
            "76ed9ac281114e4894690cb459450d5b",
            "ca52f099b62f476fa97a69f01eed54f9",
            "6a99bea8b0bd42af9e329e5681a04e86",
            "89b3b0d550da4f6ea2739ccd82eaaba6",
            "da419feb0219474b9d4ab528a367f3d7",
            "2d64734e05c14085975cfb0afe0e7129",
            "9810ead6985147b184a04a4c9b458011",
            "7f3a6bd610ad4092b0de5b0519d6c7ad",
            "8b2c028b27bd4b599b7670cdbd7ad235"
          ]
        },
        "id": "jnR1YKD2Zuyo",
        "outputId": "f8cd9877-163e-48ea-c3eb-55522f9fb735"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3c0f8e79f5e49ee89ca7814ed67867d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})\n"
          ]
        }
      ],
      "source": [
        "# Configure model.\n",
        "with strategy.model_init_context():\n",
        "    if args.model == \"gpt2\":\n",
        "        model = GPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    elif args.model == \"bloom\":\n",
        "        model = BLOOMRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    elif args.model == \"opt\":\n",
        "        model = OPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device()) \n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {args.model}\")\n",
        "\n",
        "    # Load the supervised finetuning model state dict if it is specified.\n",
        "    # However, we will train the reward model from the initial language model instead of supervised finetuning model.\n",
        "    if args.model_path is not None:\n",
        "        state_dict = torch.load(args.model_path)\n",
        "        model.model.load_state_dict(state_dict)\n",
        "\n",
        "# This float16 or `model.half()` might cause loss NaN issue!!!\n",
        "# See:\n",
        "#   https://stackoverflow.com/questions/65332165/loss-is-nan-when-fine-tuning-huggingface-nli-model-both-roberta-bart\n",
        "#   https://github.com/huggingface/transformers/issues/9160\n",
        "# model = model.to(torch.float16)\n",
        "\n",
        "# Configure tokenizer.\n",
        "if args.model == \"gpt2\":\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        \"gpt2\", \n",
        "        # bos_token=\"<|startoftext|>\",\n",
        "        # eos_token=\"<|endoftext|>\", \n",
        "        # pad_token=\"<|pad|>\",\n",
        "        # padding_side=\"right\", \n",
        "        model_max_length=args.max_len,\n",
        "        )\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(tokenizer)\n",
        "    # model.resize_token_embeddings(len(tokenizer)) \n",
        "elif args.model == \"bloom\":\n",
        "    tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "elif args.model == \"opt\":\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")  \n",
        "    tokenizer.pad_token = tokenizer.eos_token    \n",
        "else:\n",
        "    raise ValueError(f\"Unsupported model: {args.model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQU-3QqH65FE",
        "outputId": "7facce11-f7de-40d6-cfc3-4ac66b7760f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset webgpt_comparisons (/root/.cache/huggingface/datasets/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)\n"
          ]
        }
      ],
      "source": [
        "# Get the dataset.\n",
        "dataset_webgpt_comp = load_dataset(\"openai/webgpt_comparisons\", split=\"train[:20%]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2H18pYX7akp",
        "outputId": "3813a100-02c0-4ddd-f38a-8c847b2bc2b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nVoiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?\\n\\n### Response:',\n",
              "  'completion_0': 'The Simpsons character that was possibly based on Ted Koppel is Kent Brockman.  He is a local news anchor in Springfield and is modeled after Ted Koppel. [1]',\n",
              "  'completion_1': \"Apu Nahasapeemapetilon is a recurring character in the American animated television series The Simpsons. He is an Indian immigrant proprietor who runs the Kwik-E-Mart, a popular convenience store in Springfield. [1] He was based on Peter Seller's character in the film The Party. [2]\",\n",
              "  'ranking': [0, 1]},\n",
              " {'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHeterophobia is the irrational fear of what\\n\\n### Response:',\n",
              "  'completion_0': ' Heterophobia is the irrational fear of the opposite sex, coined as Sexophobia [1]. This phobia can be caused by genetics, heredity, negative experiences with the opposite sex, or a combination of these [1].  Symptoms may result from encountering people of the opposite sex, including breathlessness, dizziness, excessive sweating, nausea, dry mouth, feeling sick, shaking, coronary heart palpitations, and anxiety [1].',\n",
              "  'completion_1': 'In modern times, there has been a rise in what is called heterophobia; the irrational fear of, discrimination against, or aversion to heterosexual people. [1][2] The word \"heterophobia\" is a play on the word \"homophobia,\" which describes the fear of homosexual people. [1] Like homophobia, heterophobia is promoted by those who wish to shame or bash heterosexuals, especially men who have sex with women. [2]',\n",
              "  'ranking': [0, 1]}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Convert data into ranking format.\n",
        "data_list_ranking = []\n",
        "for row in dataset_webgpt_comp:\n",
        "    question = row[\"question\"][\"full_text\"]\n",
        "    answer_0 = row[\"answer_0\"]\n",
        "    answer_1 = row[\"answer_1\"]\n",
        "    score_0 = row[\"score_0\"]\n",
        "    score_1 = row[\"score_1\"]\n",
        "    if answer_0 == \"\" or answer_1 == \"\" or (score_0 == score_1):\n",
        "        continue\n",
        "\n",
        "    ranking = [0 if score_0 > score_1 else 1, 0 if score_0 < score_1 else 1]\n",
        "    data_list_ranking.append({\n",
        "        \"prompt\": PROMPT_TEMPLATE.format_map({\"instruction\": question}),\n",
        "        \"completion_0\": answer_0,\n",
        "        \"completion_1\": answer_1,\n",
        "        \"ranking\": ranking\n",
        "    })\n",
        "\n",
        "data_list_ranking[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeTW6fIE_c2L",
        "outputId": "f32f47ca-536b-4855-af32-abdfcc528658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before data num: 2747\n",
            "after data num: 2747\n",
            "data example: \n",
            "{'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHeterophobia is the irrational fear of what\\n\\n### Response:', 'chosen': ' Heterophobia is the irrational fear of the opposite sex, coined as Sexophobia [1]. This phobia can be caused by genetics, heredity, negative experiences with the opposite sex, or a combination of these [1].  Symptoms may result from encountering people of the opposite sex, including breathlessness, dizziness, excessive sweating, nausea, dry mouth, feeling sick, shaking, coronary heart palpitations, and anxiety [1].', 'rejected': 'In modern times, there has been a rise in what is called heterophobia; the irrational fear of, discrimination against, or aversion to heterosexual people. [1][2] The word \"heterophobia\" is a play on the word \"homophobia,\" which describes the fear of homosexual people. [1] Like homophobia, heterophobia is promoted by those who wish to shame or bash heterosexuals, especially men who have sex with women. [2]'}\n"
          ]
        }
      ],
      "source": [
        "# Make ranking data to chosen, rejetced data for reward model dataset.\n",
        "total_data_ranking2chosen = []\n",
        "for tmp in data_list_ranking:\n",
        "    one_data_ranking2chosen = []\n",
        "\n",
        "    # data 1) 0 VS 1\n",
        "    data = {}\n",
        "    data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    if tmp[\"ranking\"][0] < tmp[\"ranking\"][1]:\n",
        "        data[\"chosen\"] = tmp[\"completion_0\"]\n",
        "        data[\"rejected\"] = tmp[\"completion_1\"]\n",
        "    else:\n",
        "        data[\"chosen\"] = tmp[\"completion_1\"]\n",
        "        data[\"rejected\"] = tmp[\"completion_0\"]\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # # data 2) 0 VS 2\n",
        "    # data = {}\n",
        "    # data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    # if tmp[\"ranking\"][0] < tmp[\"ranking\"][2]:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_0\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_2\"]\n",
        "    # else:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_2\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_0\"]\n",
        "    # one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # # data 1) 1 VS 2\n",
        "    # data = {}\n",
        "    # data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    # if tmp[\"ranking\"][1] < tmp[\"ranking\"][2]:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_1\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_2\"]\n",
        "    # else:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_2\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_1\"]\n",
        "    # one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
        "\n",
        "\n",
        "print(\"before data num: %d\" % (len(data_list_ranking)))\n",
        "print(\"after data num: %d\" % (len(total_data_ranking2chosen)))\n",
        "print(\"data example: \\n%s\" % total_data_ranking2chosen[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1FpHo5jAf81",
        "outputId": "47f1f149-01da-480d-e15a-4faf7df6ef5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow does one juice a prune? If prunes are just dehydrated plums, shouldn't prune juice just be plum juice?\\n\\n### Response:\", 'chosen': 'You can juice dried prunes by steaming or simmering them to rehydrate them, running them through a strainer to remove the pits, seeds and skin, and then adding more water to the resulting pruney paste. [1] You don’t have to do that, though, because you could also just juice a fresh prune. Contrary to popular belief, prunes aren’t simply dried plums, but a group of cultivars, or varieties, of plum that are well suited to drying. [2][3] ', 'rejected': 'While prunes are not simply dried plums, they are a type of dried plum. [2][3]  To juice a prune, you must first steam or simmer them to rehydrate them, and then run them through a strainer to remove the pits, seeds, and skin. [2][3]'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 451.13it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 520.23it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 508.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "## prompt ##\n",
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Why do major cell phone carriers allow companies like MetroPCS, Cricket Wireless, Boost Mobile, etc. to resell their network?\n",
            "\n",
            "And for a cheaper price, too? I don't understand.\n",
            "\n",
            "### Response:\n",
            "######################################################################\n",
            "## chosen ##\n",
            "These companies known as mobile virtual network operators or MVNOs are able to resell network services in bulk from a regular carrier and then resell them to end-users, usually for cheaper prices than that carrier [2,3]. That’s still profitable for MVNOs because they don’t have to pay anything for the upkeep and modernization of the wireless network they’re using, therefore they can afford to lower the rates on voice calls, messages and data in order to attract more customers [3]. Usually, they usually offer quite affordable pre-pay rates for these services and that’s definitely worth remembering [2]. As for regular carriers, without getting into too much detail, they’re still happy to make a profit from selling their services to MVNOs, even though they’re basically creating competitors with more customer-friendly offers – in some markets, governments require carriers to support MVNOs in order to create a competitive environment in the local mobile business [3]. \n",
            "######################################################################\n",
            "## rejected ##\n",
            "The big cell phone carriers allow smaller companies, called MVNOs (Mobile Virtual Network Operators), to resell their network [3]. They don't own the cell phone towers or the network but instead lease the network for their customers to use [3]. They are able to offer cheaper cell phone plans because they don't have the huge overhead and advertising costs that the big guys do [2]. They also have better customer service because they are smaller and less complex [1].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare for data and dataset.\n",
        "import random\n",
        "random.seed(230319)\n",
        "\n",
        "random.shuffle(total_data_ranking2chosen)\n",
        "print(total_data_ranking2chosen[1])\n",
        "\n",
        "# train_data = total_data_ranking2chosen[:-1000]\n",
        "# eval_data = total_data_ranking2chosen[-1000:0]\n",
        "# We just select very small set of data for a quicker training.\n",
        "train_data = total_data_ranking2chosen[:100]\n",
        "val_data = total_data_ranking2chosen[100:130]\n",
        "eval_data = total_data_ranking2chosen[130:160]\n",
        "\n",
        "train_dataset = RewardDataset(train_data, tokenizer, args.max_len)\n",
        "val_dataset = RewardDataset(val_data, tokenizer, args.max_len)\n",
        "eval_dataset = RewardDataset(eval_data, tokenizer, args.max_len)\n",
        "\n",
        "# Check\n",
        "idx = 10\n",
        "print(\"#\" * 70)\n",
        "print(\"## prompt ##\")\n",
        "print(train_data[idx][\"prompt\"])\n",
        "print(\"#\" * 70)\n",
        "print(\"## chosen ##\")\n",
        "print(train_data[idx][\"chosen\"])\n",
        "print(\"#\" * 70)\n",
        "print(\"## rejected ##\")\n",
        "print(train_data[idx][\"rejected\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqCnhM_SXw9Z"
      },
      "outputs": [],
      "source": [
        "# Configure optimizer.\n",
        "optim = Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Configure loss function.\n",
        "if args.loss_fn == \"log_sig\":\n",
        "    loss_fn = LogSigLoss()\n",
        "elif args.loss_fn == \"log_exp\":\n",
        "    loss_fn = LogExpLoss()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported loss function: {args.loss_fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC6Sf3qMX2A-"
      },
      "outputs": [],
      "source": [
        "trainer = RewardModelTrainer(model=model,\n",
        "                            strategy=strategy,\n",
        "                            optim=optim,\n",
        "                            loss_fn=loss_fn,\n",
        "                            train_dataset=train_dataset,\n",
        "                            valid_dataset=val_dataset,\n",
        "                            eval_dataset=eval_dataset,\n",
        "                            batch_size=args.batch_size,\n",
        "                            max_epochs=args.max_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJO46OBraGOy",
        "outputId": "b515f2ae-0336-4c7a-f83b-a36caacd6a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Train step of epoch 0:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 1/25 [00:00<00:08,  2.97it/s]\u001b[A\n",
            "Train step of epoch 0:   4%|▍         | 1/25 [00:00<00:08,  2.97it/s, loss=0.705, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 2/25 [00:00<00:06,  3.83it/s, loss=0.705, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:   8%|▊         | 2/25 [00:00<00:06,  3.83it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 3/25 [00:00<00:05,  4.12it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  12%|█▏        | 3/25 [00:00<00:05,  4.12it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 4/25 [00:00<00:04,  4.30it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  16%|█▌        | 4/25 [00:01<00:04,  4.30it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 5/25 [00:01<00:04,  4.40it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  20%|██        | 5/25 [00:01<00:04,  4.40it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 6/25 [00:01<00:04,  4.45it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  24%|██▍       | 6/25 [00:01<00:04,  4.45it/s, loss=0.69, dist=0, acc=0] \u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 7/25 [00:01<00:04,  4.50it/s, loss=0.69, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  28%|██▊       | 7/25 [00:01<00:04,  4.50it/s, loss=0.695, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 8/25 [00:01<00:03,  4.52it/s, loss=0.695, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  32%|███▏      | 8/25 [00:01<00:03,  4.52it/s, loss=0.693, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 9/25 [00:02<00:03,  4.54it/s, loss=0.693, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  36%|███▌      | 9/25 [00:02<00:03,  4.54it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 10/25 [00:02<00:03,  4.56it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  40%|████      | 10/25 [00:02<00:03,  4.56it/s, loss=0.697, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 11/25 [00:02<00:03,  4.57it/s, loss=0.697, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  44%|████▍     | 11/25 [00:02<00:03,  4.57it/s, loss=0.688, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 12/25 [00:02<00:02,  4.57it/s, loss=0.688, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  48%|████▊     | 12/25 [00:02<00:02,  4.57it/s, loss=0.692, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 13/25 [00:02<00:02,  4.57it/s, loss=0.692, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  52%|█████▏    | 13/25 [00:03<00:02,  4.57it/s, loss=0.69, dist=0, acc=0] \u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 14/25 [00:03<00:02,  4.57it/s, loss=0.69, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  56%|█████▌    | 14/25 [00:03<00:02,  4.57it/s, loss=0.694, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 15/25 [00:03<00:02,  4.56it/s, loss=0.694, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  60%|██████    | 15/25 [00:03<00:02,  4.56it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 16/25 [00:03<00:01,  4.56it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  64%|██████▍   | 16/25 [00:03<00:01,  4.56it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 17/25 [00:03<00:01,  4.53it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  68%|██████▊   | 17/25 [00:03<00:01,  4.53it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 18/25 [00:04<00:01,  4.53it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  72%|███████▏  | 18/25 [00:04<00:01,  4.53it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 19/25 [00:04<00:01,  4.54it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  76%|███████▌  | 19/25 [00:04<00:01,  4.54it/s, loss=0.705, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 20/25 [00:04<00:01,  4.56it/s, loss=0.705, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  80%|████████  | 20/25 [00:04<00:01,  4.56it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 21/25 [00:04<00:00,  4.55it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  84%|████████▍ | 21/25 [00:04<00:00,  4.55it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 22/25 [00:04<00:00,  4.56it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  88%|████████▊ | 22/25 [00:05<00:00,  4.56it/s, loss=0.698, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 23/25 [00:05<00:00,  4.57it/s, loss=0.698, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  92%|█████████▏| 23/25 [00:05<00:00,  4.57it/s, loss=0.693, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 24/25 [00:05<00:00,  4.56it/s, loss=0.693, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0:  96%|█████████▌| 24/25 [00:05<00:00,  4.56it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 0: 100%|██████████| 25/25 [00:05<00:00,  4.57it/s, loss=0.696, dist=0, acc=0]\u001b[A\n",
            "Train epoch:  33%|███▎      | 1/3 [00:06<00:12,  6.22s/it]\n",
            "Train step of epoch 0: 100%|██████████| 25/25 [00:06<00:00,  4.02it/s, dist=0.0051, acc=0.633]\n",
            "\n",
            "Train step of epoch 1:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Train step of epoch 1:   4%|▍         | 1/25 [00:00<00:03,  7.93it/s]\u001b[A\n",
            "Train step of epoch 1:   4%|▍         | 1/25 [00:00<00:03,  7.93it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:   8%|▊         | 2/25 [00:00<00:04,  5.52it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:   8%|▊         | 2/25 [00:00<00:04,  5.52it/s, loss=0.692, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  12%|█▏        | 3/25 [00:00<00:04,  5.07it/s, loss=0.692, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  12%|█▏        | 3/25 [00:00<00:04,  5.07it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  16%|█▌        | 4/25 [00:00<00:04,  4.88it/s, loss=0.691, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  16%|█▌        | 4/25 [00:00<00:04,  4.88it/s, loss=0.684, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  20%|██        | 5/25 [00:00<00:04,  4.75it/s, loss=0.684, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  20%|██        | 5/25 [00:01<00:04,  4.75it/s, loss=0.685, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  24%|██▍       | 6/25 [00:01<00:04,  4.70it/s, loss=0.685, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  24%|██▍       | 6/25 [00:01<00:04,  4.70it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  28%|██▊       | 7/25 [00:01<00:03,  4.67it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  28%|██▊       | 7/25 [00:01<00:03,  4.67it/s, loss=0.684, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  32%|███▏      | 8/25 [00:01<00:03,  4.63it/s, loss=0.684, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  32%|███▏      | 8/25 [00:01<00:03,  4.63it/s, loss=0.681, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  36%|███▌      | 9/25 [00:01<00:03,  4.62it/s, loss=0.681, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  36%|███▌      | 9/25 [00:01<00:03,  4.62it/s, loss=0.682, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  40%|████      | 10/25 [00:02<00:03,  4.60it/s, loss=0.682, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  40%|████      | 10/25 [00:02<00:03,  4.60it/s, loss=0.683, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  44%|████▍     | 11/25 [00:02<00:03,  4.59it/s, loss=0.683, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  44%|████▍     | 11/25 [00:02<00:03,  4.59it/s, loss=0.702, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  48%|████▊     | 12/25 [00:02<00:02,  4.59it/s, loss=0.702, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  48%|████▊     | 12/25 [00:02<00:02,  4.59it/s, loss=0.677, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  52%|█████▏    | 13/25 [00:02<00:02,  4.60it/s, loss=0.677, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  52%|█████▏    | 13/25 [00:02<00:02,  4.60it/s, loss=0.658, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  56%|█████▌    | 14/25 [00:02<00:02,  4.60it/s, loss=0.658, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  56%|█████▌    | 14/25 [00:03<00:02,  4.60it/s, loss=0.675, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  60%|██████    | 15/25 [00:03<00:02,  4.59it/s, loss=0.675, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  60%|██████    | 15/25 [00:03<00:02,  4.59it/s, loss=0.697, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  64%|██████▍   | 16/25 [00:03<00:01,  4.59it/s, loss=0.697, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  64%|██████▍   | 16/25 [00:03<00:01,  4.59it/s, loss=0.66, dist=0, acc=0] \u001b[A\n",
            "Train step of epoch 1:  68%|██████▊   | 17/25 [00:03<00:01,  4.59it/s, loss=0.66, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  68%|██████▊   | 17/25 [00:03<00:01,  4.59it/s, loss=0.655, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  72%|███████▏  | 18/25 [00:03<00:01,  4.58it/s, loss=0.655, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  72%|███████▏  | 18/25 [00:03<00:01,  4.58it/s, loss=0.685, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, loss=0.685, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, loss=0.644, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  80%|████████  | 20/25 [00:04<00:01,  4.57it/s, loss=0.644, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  80%|████████  | 20/25 [00:04<00:01,  4.57it/s, loss=0.666, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  84%|████████▍ | 21/25 [00:04<00:00,  4.58it/s, loss=0.666, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  84%|████████▍ | 21/25 [00:04<00:00,  4.58it/s, loss=0.669, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  88%|████████▊ | 22/25 [00:04<00:00,  4.58it/s, loss=0.669, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  88%|████████▊ | 22/25 [00:04<00:00,  4.58it/s, loss=0.646, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  92%|█████████▏| 23/25 [00:04<00:00,  4.58it/s, loss=0.646, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  92%|█████████▏| 23/25 [00:05<00:00,  4.58it/s, loss=0.644, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  96%|█████████▌| 24/25 [00:05<00:00,  4.58it/s, loss=0.644, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1:  96%|█████████▌| 24/25 [00:05<00:00,  4.58it/s, loss=0.679, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 1: 100%|██████████| 25/25 [00:05<00:00,  4.59it/s, loss=0.679, dist=0, acc=0]\u001b[A\n",
            "Train epoch:  67%|██████▋   | 2/3 [00:12<00:06,  6.10s/it]\n",
            "Train step of epoch 1: 100%|██████████| 25/25 [00:06<00:00,  4.16it/s, dist=0.126, acc=0.7]\n",
            "\n",
            "Train step of epoch 2:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Train step of epoch 2:   4%|▍         | 1/25 [00:00<00:03,  7.86it/s]\u001b[A\n",
            "Train step of epoch 2:   4%|▍         | 1/25 [00:00<00:03,  7.86it/s, loss=0.653, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:   8%|▊         | 2/25 [00:00<00:04,  5.53it/s, loss=0.653, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:   8%|▊         | 2/25 [00:00<00:04,  5.53it/s, loss=0.558, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  12%|█▏        | 3/25 [00:00<00:04,  5.06it/s, loss=0.558, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  12%|█▏        | 3/25 [00:00<00:04,  5.06it/s, loss=0.593, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  16%|█▌        | 4/25 [00:00<00:04,  4.84it/s, loss=0.593, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  16%|█▌        | 4/25 [00:00<00:04,  4.84it/s, loss=0.688, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  20%|██        | 5/25 [00:01<00:04,  4.75it/s, loss=0.688, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  20%|██        | 5/25 [00:01<00:04,  4.75it/s, loss=0.677, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s, loss=0.677, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s, loss=0.633, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  28%|██▊       | 7/25 [00:01<00:03,  4.65it/s, loss=0.633, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  28%|██▊       | 7/25 [00:01<00:03,  4.65it/s, loss=0.582, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  32%|███▏      | 8/25 [00:01<00:03,  4.62it/s, loss=0.582, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  32%|███▏      | 8/25 [00:01<00:03,  4.62it/s, loss=0.428, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  36%|███▌      | 9/25 [00:01<00:03,  4.62it/s, loss=0.428, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  36%|███▌      | 9/25 [00:01<00:03,  4.62it/s, loss=0.516, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  40%|████      | 10/25 [00:02<00:03,  4.61it/s, loss=0.516, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  40%|████      | 10/25 [00:02<00:03,  4.61it/s, loss=0.478, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  44%|████▍     | 11/25 [00:02<00:03,  4.60it/s, loss=0.478, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  44%|████▍     | 11/25 [00:02<00:03,  4.60it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  48%|████▊     | 12/25 [00:02<00:02,  4.59it/s, loss=0.689, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  48%|████▊     | 12/25 [00:02<00:02,  4.59it/s, loss=0.713, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  52%|█████▏    | 13/25 [00:02<00:02,  4.59it/s, loss=0.713, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  52%|█████▏    | 13/25 [00:02<00:02,  4.59it/s, loss=0.555, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  56%|█████▌    | 14/25 [00:02<00:02,  4.59it/s, loss=0.555, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  56%|█████▌    | 14/25 [00:03<00:02,  4.59it/s, loss=0.525, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  60%|██████    | 15/25 [00:03<00:02,  4.59it/s, loss=0.525, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  60%|██████    | 15/25 [00:03<00:02,  4.59it/s, loss=0.658, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  64%|██████▍   | 16/25 [00:03<00:01,  4.58it/s, loss=0.658, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  64%|██████▍   | 16/25 [00:03<00:01,  4.58it/s, loss=0.456, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  68%|██████▊   | 17/25 [00:03<00:01,  4.59it/s, loss=0.456, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  68%|██████▊   | 17/25 [00:03<00:01,  4.59it/s, loss=0.438, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  72%|███████▏  | 18/25 [00:03<00:01,  4.58it/s, loss=0.438, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  72%|███████▏  | 18/25 [00:03<00:01,  4.58it/s, loss=0.69, dist=0, acc=0] \u001b[A\n",
            "Train step of epoch 2:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, loss=0.69, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, loss=0.625, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  80%|████████  | 20/25 [00:04<00:01,  4.58it/s, loss=0.625, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  80%|████████  | 20/25 [00:04<00:01,  4.58it/s, loss=0.553, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  84%|████████▍ | 21/25 [00:04<00:00,  4.58it/s, loss=0.553, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  84%|████████▍ | 21/25 [00:04<00:00,  4.58it/s, loss=0.575, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  88%|████████▊ | 22/25 [00:04<00:00,  4.58it/s, loss=0.575, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  88%|████████▊ | 22/25 [00:04<00:00,  4.58it/s, loss=0.515, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  92%|█████████▏| 23/25 [00:04<00:00,  4.59it/s, loss=0.515, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  92%|█████████▏| 23/25 [00:05<00:00,  4.59it/s, loss=0.54, dist=0, acc=0] \u001b[A\n",
            "Train step of epoch 2:  96%|█████████▌| 24/25 [00:05<00:00,  4.59it/s, loss=0.54, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2:  96%|█████████▌| 24/25 [00:05<00:00,  4.59it/s, loss=0.599, dist=0, acc=0]\u001b[A\n",
            "Train step of epoch 2: 100%|██████████| 25/25 [00:05<00:00,  4.58it/s, loss=0.599, dist=0, acc=0]\u001b[A\n",
            "Train epoch: 100%|██████████| 3/3 [00:18<00:00,  6.06s/it]\n",
            "Train step of epoch 2: 100%|██████████| 25/25 [00:06<00:00,  4.17it/s, dist=0.0589, acc=0.5]\n",
            "Train epoch: 100%|██████████| 3/3 [00:18<00:00,  6.08s/it]\n"
          ]
        }
      ],
      "source": [
        "# Train!!!\n",
        "trainer.fit()\n",
        "\n",
        "# Save model checkpoint after fitting on only rank0.\n",
        "# strategy.save_model(model, os.path.join(args.output_dir, \"rm.pt\"), only_rank0=True)\n",
        "trainer.save_model(path=os.path.join(args.output_dir, \"rm.pt\"), only_rank0=True)\n",
        "\n",
        "# Save optimizer checkpoint on all ranks.\n",
        "if args.need_optim_ckpt:\n",
        "    strategy.save_optimizer(trainer.optimizer,\n",
        "                            os.path.join(args.output_dir, \"rm_optim_checkpoint_%d.pt\" % (torch.cuda.current_device())),\n",
        "                            only_rank0=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI7qm5N262EZ"
      },
      "source": [
        "# Step 3) PPO: Proximal Policy Optimization\n",
        "Further fine-tune the LLM from step 1 with the reward model and this dataset using RL (eg. PPO).\n",
        "\n",
        "- References\n",
        "    - [train_prompts.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fiD6OSKpOrc"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from copy import deepcopy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "\n",
        "from nextgpt.models.base import RewardModel\n",
        "from nextgpt.models.bloom import BLOOMActor, BLOOMCritic\n",
        "from nextgpt.models.gpt import GPTActor, GPTCritic\n",
        "from nextgpt.models.opt import OPTActor, OPTCritic\n",
        "from nextgpt.trainer import PPOTrainer\n",
        "from nextgpt.trainer.strategies import DDPStrategy, NaiveStrategy\n",
        "from nextgpt.dataset import PromptDataset, SupervisedDataset, DataCollatorForSupervisedDataset\n",
        "\n",
        "import json\n",
        "import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIs7m2m9pmWN",
        "outputId": "da58da84-bd83-40b8-fb2d-b09a3d6a1be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(output_dir='./output_3_ppo', strategy='naive', model='gpt2', pretrain='./output_1_sft', rm_model='gpt2', rm_path='./output_2_rm/rm.pt', rm_pretrain='gpt2', need_optim_ckpt=False, num_episodes=1, max_timesteps=3, update_timesteps=3, max_epochs=1, train_batch_size=8, ptx_batch_size=1, experience_batch_size=8, lora_rank=0, kl_coef=0.1, ptx_coef=0.9)\n"
          ]
        }
      ],
      "source": [
        "# Define arguments.\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"./output_3_ppo\")\n",
        "parser.add_argument(\"--strategy\",\n",
        "                    type=str,\n",
        "                    choices=[\"naive\", \"ddp\"],\n",
        "                    default=\"naive\")\n",
        "parser.add_argument(\"--model\", \n",
        "                    type=str, \n",
        "                    choices=[\"gpt2\", \"bloom\", \"opt\"],\n",
        "                    default=\"gpt2\")\n",
        "parser.add_argument(\"--pretrain\", type=str, default=None)\n",
        "parser.add_argument(\"--rm_model\", \n",
        "                    type=str, \n",
        "                    choices=[\"gpt2\", \"bloom\", \"opt\"],\n",
        "                    default=\"gpt2\")\n",
        "parser.add_argument(\"--rm_path\", type=str, default=None)\n",
        "parser.add_argument(\"--rm_pretrain\", type=str, default=None)\n",
        "parser.add_argument(\"--need_optim_ckpt\", type=bool, default=False)\n",
        "parser.add_argument(\"--num_episodes\", type=int, default=10)\n",
        "parser.add_argument(\"--max_timesteps\", type=int, default=3)\n",
        "parser.add_argument(\"--update_timesteps\", type=int, default=3)\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=5)\n",
        "parser.add_argument(\"--train_batch_size\", type=int, default=8)\n",
        "parser.add_argument(\"--ptx_batch_size\", type=int, default=1)\n",
        "parser.add_argument(\"--experience_batch_size\", type=int, default=8)\n",
        "parser.add_argument(\"--lora_rank\", type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument(\"--kl_coef\", type=float, default=0.1)\n",
        "parser.add_argument(\"--ptx_coef\", type=float, default=0.9)\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# For test\n",
        "# args.pretrain= \"gpt2\"\n",
        "args.pretrain= \"./output_1_sft\"\n",
        "args.rm_path = \"./output_2_rm/rm.pt\" # RM model path\n",
        "args.rm_pretrain= \"gpt2\"\n",
        "\n",
        "args.num_episodes = 1\n",
        "args.max_epochs   = 1\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyHx9jXoq0yi"
      },
      "outputs": [],
      "source": [
        "# Configure strategy.\n",
        "if args.strategy == \"naive\":\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == \"ddp\":\n",
        "    strategy = DDPStrategy()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported strategy: {args.strategy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH1wPr4Nq-bM"
      },
      "outputs": [],
      "source": [
        "if args.rm_path is not None:\n",
        "    rm_state_dict = torch.load(args.rm_path, map_location=\"cpu\")\n",
        "\n",
        "# Configure intial model.\n",
        "if args.model == \"gpt2\":\n",
        "    initial_model = GPTActor(pretrained=args.pretrain)\n",
        "elif args.model == \"bloom\":\n",
        "    initial_model = BLOOMActor(pretrained=args.pretrain)\n",
        "elif args.model == \"opt\":\n",
        "    initial_model = OPTActor(pretrained=args.pretrain)\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported actor model: {args.model}\")\n",
        "\n",
        "# Configure reward model.\n",
        "if args.rm_model == \"gpt2\":\n",
        "    reward_model = GPTRM(pretrained=args.rm_pretrain)\n",
        "elif args.rm_model == \"bloom\":\n",
        "    reward_model = BLOOMRM(pretrained=args.rm_pretrain)\n",
        "elif args.rm_model == \"opt\":\n",
        "    reward_model = OPTRM(pretrained=args.rm_pretrain)\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported reward model: {args.rm_model}\")\n",
        "\n",
        "if args.rm_path is not None:\n",
        "    reward_model.load_state_dict(rm_state_dict)\n",
        "\n",
        "# initial_model.to(torch.float16).to(torch.cuda.current_device())\n",
        "# reward_model.to(torch.float16).to(torch.cuda.current_device())\n",
        "initial_model.to(torch.cuda.current_device())\n",
        "reward_model.to(torch.cuda.current_device())\n",
        "\n",
        "# Configure actor and critic.\n",
        "with strategy.model_init_context():\n",
        "    # Actor\n",
        "    if args.model == \"gpt2\":\n",
        "        actor = GPTActor(pretrained=args.pretrain, lora_rank=args.lora_rank)\n",
        "    elif args.model == \"bloom\":\n",
        "        actor = BLOOMActor(pretrained=args.pretrain_actor, lora_rank=args.lora_rank)\n",
        "    elif args.model == \"opt\":\n",
        "        actor = OPTActor(pretrained=args.pretrain, lora_rank=args.lora_rank)        \n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported actor model: {args.model}\")\n",
        "\n",
        "    # Critic\n",
        "    if args.rm_model == \"gpt2\":\n",
        "        critic = GPTCritic(pretrained=args.rm_pretrain, lora_rank=args.lora_rank)\n",
        "    elif args.rm_model == \"bloom\":\n",
        "        critic = BLOOMCritic(pretrained=args.rm_pretrain, lora_rank=args.lora_rank)\n",
        "    elif args.rm_model == \"opt\":\n",
        "        critic = OPTCritic(pretrained=args.rm_pretrain, lora_rank=args.lora_rank)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported reward model: {args.rm_model}\")\n",
        "\n",
        "    if args.rm_path is not None:\n",
        "        critic.load_state_dict(rm_state_dict)\n",
        "        del rm_state_dict\n",
        "\n",
        "# critic.to(torch.float16).to(torch.cuda.current_device())\n",
        "# actor.to(torch.float16).to(torch.cuda.current_device())\n",
        "critic.to(torch.cuda.current_device())\n",
        "actor.to(torch.cuda.current_device())\n",
        "\n",
        "# Configure tokenizer.\n",
        "if args.model == \"gpt2\":\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "        \"gpt2\", \n",
        "        # bos_token=\"<|startoftext|>\",\n",
        "        # eos_token=\"<|endoftext|>\", \n",
        "        # pad_token=\"<|pad|>\",\n",
        "        # padding_side=\"right\", \n",
        "        model_max_length=512,\n",
        "        )\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "elif args.model == \"bloom\":\n",
        "    tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token            \n",
        "elif args.model == \"opt\":\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-xAImuVqh46"
      },
      "outputs": [],
      "source": [
        "# Configure optimizer.\n",
        "actor_optim = Adam(actor.parameters(), lr=1e-7)\n",
        "critic_optim = Adam(critic.parameters(), lr=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKBzMklPqijJ"
      },
      "outputs": [],
      "source": [
        "# Setting the models.\n",
        "(actor, actor_optim), (critic, critic_optim) = strategy.prepare((actor, actor_optim), (critic, critic_optim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzDpPXr7rRTL"
      },
      "outputs": [],
      "source": [
        "def tokenize_fn(texts):\n",
        "    # MUST padding to max length to ensure inputs of all ranks have the same length\n",
        "    # Different length may lead to hang when using gemini, as different generation steps\n",
        "    batch = tokenizer(texts, return_tensors=\"pt\", max_length=96, padding=\"max_length\", truncation=True)\n",
        "    return {k: v.to(torch.cuda.current_device()) for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEMpasbTrgzF",
        "outputId": "25f91d77-ec64-46b0-db76-0c9bbb0a4b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset webgpt_comparisons (/root/.cache/huggingface/datasets/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'instruction': 'Voiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?', 'completion': 'The Simpsons character that was possibly based on Ted Koppel is Kent Brockman.  He is a local news anchor in Springfield and is modeled after Ted Koppel. [1]'}]\n"
          ]
        }
      ],
      "source": [
        "# Prepare dataset.\n",
        "dataset_webgpt_comp = load_dataset(\"openai/webgpt_comparisons\", split=\"train[:20%]\")\n",
        "\n",
        "data_list = []\n",
        "for row in dataset_webgpt_comp:\n",
        "    question = row[\"question\"][\"full_text\"]\n",
        "    answer_0 = row[\"answer_0\"]\n",
        "    data_list.append({\n",
        "        \"instruction\": question,\n",
        "        \"completion\": answer_0\n",
        "    })\n",
        "\n",
        "print(data_list[:1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure dataloader.\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
        "\n",
        "prompt_dataset = PromptDataset(\n",
        "    dataset=data_list, \n",
        "    tokenizer=tokenizer, \n",
        "    prompt_template=PROMPT_TEMPLATE, \n",
        "    max_datasets_size=10000)\n",
        "\n",
        "prompt_sampler = None\n",
        "if dist.is_initialized() and dist.get_world_size() > 1:\n",
        "    prompt_sampler = DistributedSampler(prompt_dataset, shuffle=True, seed=42, drop_last=True)\n",
        "\n",
        "prompt_dataloader = DataLoader(\n",
        "    prompt_dataset,\n",
        "    shuffle=(prompt_sampler is None),\n",
        "    sampler=prompt_sampler,\n",
        "    batch_size=args.train_batch_size)\n",
        "\n",
        "pretrain_dataset = SupervisedDataset(\n",
        "    dataset=data_list,\n",
        "    tokenizer=tokenizer, \n",
        "    prompt_template=PROMPT_TEMPLATE,\n",
        "    completion_field=\"completion\",\n",
        "    max_datasets_size=10000,\n",
        "    max_length=512,\n",
        "    verbose=True)\n",
        "\n",
        "pretrain_sampler = None\n",
        "if dist.is_initialized() and dist.get_world_size() > 1:\n",
        "    pretrain_sampler = DistributedSampler(pretrain_dataset, shuffle=True, seed=42, drop_last=True)\n",
        "\n",
        "pretrain_dataloader = DataLoader(\n",
        "    pretrain_dataset,\n",
        "    shuffle=(pretrain_sampler is None),\n",
        "    sampler=pretrain_sampler,\n",
        "    batch_size=args.ptx_batch_size,\n",
        "    collate_fn=data_collator)\n",
        "\n",
        "def tokenize_fn(texts):\n",
        "    # MUST padding to max length to ensure inputs of all ranks have the same length\n",
        "    # Different length may lead to hang when using gemini, as different generation steps\n",
        "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding='max_length', truncation=True)\n",
        "    return {k: v.to(torch.cuda.current_device()) for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmuTC7hIgWa",
        "outputId": "1a78c3de-6359-4ab7-9654-010b379d8901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Limiting dataset to 10000 examples.\n",
            "Loading data...\n",
            "Limiting dataset to 10000 examples.\n",
            "Formatting inputs...\n",
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Voiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?\n",
            "\n",
            "### Response:\n",
            "The Simpsons character that was possibly based on Ted Koppel is Kent Brockman.  He is a local news anchor in Springfield and is modeled after Ted Koppel. [1]<|endoftext|>\n",
            "Tokenizing inputs... This may take some time...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MihLfe26u-4g",
        "outputId": "9de667b0-669b-4083-9215-38a7a69c629c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episode [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.17it/s]\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, reward=-1.36]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:00,  4.04it/s, reward=-1.36]\u001b[A\n",
            "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:00,  4.04it/s, reward=-.964]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:00<00:00,  4.80it/s, reward=-.964]\u001b[A\n",
            "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:00<00:00,  4.80it/s, reward=-1.21]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 3/3 [00:00<00:00,  4.94it/s, reward=-1.21]\n",
            "Episode [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]\n"
          ]
        }
      ],
      "source": [
        "# Configure trainer.\n",
        "trainer = PPOTrainer(\n",
        "    strategy,\n",
        "    actor,\n",
        "    critic,\n",
        "    reward_model,\n",
        "    initial_model,\n",
        "    actor_optim,\n",
        "    critic_optim,\n",
        "    kl_coef=args.kl_coef,\n",
        "    ptx_coef=args.ptx_coef,\n",
        "    max_epochs=args.max_epochs,\n",
        "    train_batch_size=args.train_batch_size,\n",
        "    experience_batch_size=args.experience_batch_size,\n",
        "    tokenizer=tokenize_fn,\n",
        "    max_length=128,\n",
        "    do_sample=True,\n",
        "    temperature=1.0,\n",
        "    top_k=50,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    prompt_dataloader=prompt_dataloader,\n",
        "    pretrain_dataloader=pretrain_dataloader,\n",
        "    num_episodes=args.num_episodes,\n",
        "    max_timesteps=args.max_timesteps,\n",
        "    update_timesteps=args.update_timesteps)\n",
        "\n",
        "# Save model checkpoint after fitting on only rank0.\n",
        "trainer.save_model(os.path.join(args.output_dir, \"actor.pt\"), only_rank0=True, tokenizer=tokenizer)\n",
        "# Save optimizer checkpoint on all ranks.\n",
        "strategy.save_optimizer(actor_optim,\n",
        "                        os.path.join(args.output_dir, \"actor_optim_checkpoint_%d.pt\" % (torch.cuda.current_device())),\n",
        "                        only_rank0=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecCC92TM7w3g",
        "outputId": "0adcc1b6-59d6-4694-f200-952dec1e4a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Heterophobia is the irrational fear of what\n",
            "\n",
            "### Response:Heterophobia is the irrational fear of what will happen to you\n",
            "\n",
            "If you ever read an internet article that claims your friend's boyfriend has a mental disorder, the first thing you would do is get on the internet, and the person in question will think you\n"
          ]
        }
      ],
      "source": [
        "#  Inference test.\n",
        "def generation(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(torch.cuda.current_device())\n",
        "    outputs = actor.generate(input_ids,\n",
        "                             max_length=100,\n",
        "                             do_sample=True,\n",
        "                             top_k=50,\n",
        "                             top_p=0.95,\n",
        "                             num_return_sequences=1)\n",
        "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
        "    print(\"#\" * 70)\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "test_isntruction_list = [\n",
        "    \"Heterophobia is the irrational fear of what\",\n",
        "    ]\n",
        "\n",
        "test_prompt_list = [PROMPT_TEMPLATE.format_map({\"instruction\": tmp}) for tmp in test_isntruction_list]\n",
        "\n",
        "for input_text in test_prompt_list:\n",
        "    output = generation(input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Ju8fgt_is2"
      },
      "source": [
        "# Inference by PPO actor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOiwh9lTBSMS"
      },
      "outputs": [],
      "source": [
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd5AIx3nAJ35"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model\", \n",
        "                    type=str, \n",
        "                    choices=[\"gpt2\", \"bloom\", \"opt\"],\n",
        "                    default=\"gpt2\")\n",
        "# We suggest to use the pretrained model from HuggingFace, use pretrain to configure model\n",
        "parser.add_argument(\"--pretrain\", type=str, default=None)\n",
        "parser.add_argument(\"--model_path\", type=str, default=None)\n",
        "parser.add_argument(\"--input\", type=str, default=\"Question: How are you ? Answer:\")\n",
        "parser.add_argument(\"--max_length\", type=int, default=100)\n",
        "args = parser.parse_args([])\n",
        "\n",
        "# args.pretrain= \"gpt2\"\n",
        "args.pretrain= \"./output_1_sft\"\n",
        "args.model_path = \"./output_3_ppo/actor.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wg_mvSAAfZu"
      },
      "outputs": [],
      "source": [
        "def eval(args):\n",
        "    # Configure model.\n",
        "    if args.model == \"gpt2\":\n",
        "        actor = GPTActor(pretrained=args.pretrain).to(torch.cuda.current_device())\n",
        "    elif args.model == \"bloom\":\n",
        "        actor = BLOOMActor(pretrained=args.pretrain).to(torch.cuda.current_device())\n",
        "    elif args.model == \"opt\":\n",
        "        actor = OPTActor(pretrained=args.pretrain).to(torch.cuda.current_device())\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {args.model}\")\n",
        "\n",
        "    state_dict = torch.load(args.model_path)\n",
        "    # actor.model.load_state_dict(state_dict)\n",
        "    actor.load_state_dict(state_dict)\n",
        "\n",
        "    # Configure tokenizer.\n",
        "    if args.model == \"gpt2\":\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    elif args.model == \"bloom\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    elif args.model == \"opt\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {args.model}\")\n",
        "\n",
        "    actor.eval()\n",
        "    input = args.input\n",
        "    input_ids = tokenizer.encode(input, return_tensors=\"pt\").to(torch.cuda.current_device())\n",
        "    outputs = actor.generate(input_ids,\n",
        "                             max_length=args.max_length,\n",
        "                             do_sample=True,\n",
        "                             top_k=10,\n",
        "                             top_p=0.95,\n",
        "                             num_return_sequences=1)\n",
        "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY7IyQs3B7Gw",
        "outputId": "52ebc983-3b38-4166-8b68-7322969c48e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['model.transformer.wte.weight', 'model.transformer.wpe.weight', 'model.transformer.h.0.ln_1.weight', 'model.transformer.h.0.ln_1.bias', 'model.transformer.h.0.attn.bias', 'model.transformer.h.0.attn.masked_bias', 'model.transformer.h.0.attn.c_attn.weight', 'model.transformer.h.0.attn.c_attn.bias', 'model.transformer.h.0.attn.c_proj.weight', 'model.transformer.h.0.attn.c_proj.bias', 'model.transformer.h.0.ln_2.weight', 'model.transformer.h.0.ln_2.bias', 'model.transformer.h.0.mlp.c_fc.weight', 'model.transformer.h.0.mlp.c_fc.bias', 'model.transformer.h.0.mlp.c_proj.weight', 'model.transformer.h.0.mlp.c_proj.bias', 'model.transformer.h.1.ln_1.weight', 'model.transformer.h.1.ln_1.bias', 'model.transformer.h.1.attn.bias', 'model.transformer.h.1.attn.masked_bias', 'model.transformer.h.1.attn.c_attn.weight', 'model.transformer.h.1.attn.c_attn.bias', 'model.transformer.h.1.attn.c_proj.weight', 'model.transformer.h.1.attn.c_proj.bias', 'model.transformer.h.1.ln_2.weight', 'model.transformer.h.1.ln_2.bias', 'model.transformer.h.1.mlp.c_fc.weight', 'model.transformer.h.1.mlp.c_fc.bias', 'model.transformer.h.1.mlp.c_proj.weight', 'model.transformer.h.1.mlp.c_proj.bias', 'model.transformer.h.2.ln_1.weight', 'model.transformer.h.2.ln_1.bias', 'model.transformer.h.2.attn.bias', 'model.transformer.h.2.attn.masked_bias', 'model.transformer.h.2.attn.c_attn.weight', 'model.transformer.h.2.attn.c_attn.bias', 'model.transformer.h.2.attn.c_proj.weight', 'model.transformer.h.2.attn.c_proj.bias', 'model.transformer.h.2.ln_2.weight', 'model.transformer.h.2.ln_2.bias', 'model.transformer.h.2.mlp.c_fc.weight', 'model.transformer.h.2.mlp.c_fc.bias', 'model.transformer.h.2.mlp.c_proj.weight', 'model.transformer.h.2.mlp.c_proj.bias', 'model.transformer.h.3.ln_1.weight', 'model.transformer.h.3.ln_1.bias', 'model.transformer.h.3.attn.bias', 'model.transformer.h.3.attn.masked_bias', 'model.transformer.h.3.attn.c_attn.weight', 'model.transformer.h.3.attn.c_attn.bias', 'model.transformer.h.3.attn.c_proj.weight', 'model.transformer.h.3.attn.c_proj.bias', 'model.transformer.h.3.ln_2.weight', 'model.transformer.h.3.ln_2.bias', 'model.transformer.h.3.mlp.c_fc.weight', 'model.transformer.h.3.mlp.c_fc.bias', 'model.transformer.h.3.mlp.c_proj.weight', 'model.transformer.h.3.mlp.c_proj.bias', 'model.transformer.h.4.ln_1.weight', 'model.transformer.h.4.ln_1.bias', 'model.transformer.h.4.attn.bias', 'model.transformer.h.4.attn.masked_bias', 'model.transformer.h.4.attn.c_attn.weight', 'model.transformer.h.4.attn.c_attn.bias', 'model.transformer.h.4.attn.c_proj.weight', 'model.transformer.h.4.attn.c_proj.bias', 'model.transformer.h.4.ln_2.weight', 'model.transformer.h.4.ln_2.bias', 'model.transformer.h.4.mlp.c_fc.weight', 'model.transformer.h.4.mlp.c_fc.bias', 'model.transformer.h.4.mlp.c_proj.weight', 'model.transformer.h.4.mlp.c_proj.bias', 'model.transformer.h.5.ln_1.weight', 'model.transformer.h.5.ln_1.bias', 'model.transformer.h.5.attn.bias', 'model.transformer.h.5.attn.masked_bias', 'model.transformer.h.5.attn.c_attn.weight', 'model.transformer.h.5.attn.c_attn.bias', 'model.transformer.h.5.attn.c_proj.weight', 'model.transformer.h.5.attn.c_proj.bias', 'model.transformer.h.5.ln_2.weight', 'model.transformer.h.5.ln_2.bias', 'model.transformer.h.5.mlp.c_fc.weight', 'model.transformer.h.5.mlp.c_fc.bias', 'model.transformer.h.5.mlp.c_proj.weight', 'model.transformer.h.5.mlp.c_proj.bias', 'model.transformer.h.6.ln_1.weight', 'model.transformer.h.6.ln_1.bias', 'model.transformer.h.6.attn.bias', 'model.transformer.h.6.attn.masked_bias', 'model.transformer.h.6.attn.c_attn.weight', 'model.transformer.h.6.attn.c_attn.bias', 'model.transformer.h.6.attn.c_proj.weight', 'model.transformer.h.6.attn.c_proj.bias', 'model.transformer.h.6.ln_2.weight', 'model.transformer.h.6.ln_2.bias', 'model.transformer.h.6.mlp.c_fc.weight', 'model.transformer.h.6.mlp.c_fc.bias', 'model.transformer.h.6.mlp.c_proj.weight', 'model.transformer.h.6.mlp.c_proj.bias', 'model.transformer.h.7.ln_1.weight', 'model.transformer.h.7.ln_1.bias', 'model.transformer.h.7.attn.bias', 'model.transformer.h.7.attn.masked_bias', 'model.transformer.h.7.attn.c_attn.weight', 'model.transformer.h.7.attn.c_attn.bias', 'model.transformer.h.7.attn.c_proj.weight', 'model.transformer.h.7.attn.c_proj.bias', 'model.transformer.h.7.ln_2.weight', 'model.transformer.h.7.ln_2.bias', 'model.transformer.h.7.mlp.c_fc.weight', 'model.transformer.h.7.mlp.c_fc.bias', 'model.transformer.h.7.mlp.c_proj.weight', 'model.transformer.h.7.mlp.c_proj.bias', 'model.transformer.h.8.ln_1.weight', 'model.transformer.h.8.ln_1.bias', 'model.transformer.h.8.attn.bias', 'model.transformer.h.8.attn.masked_bias', 'model.transformer.h.8.attn.c_attn.weight', 'model.transformer.h.8.attn.c_attn.bias', 'model.transformer.h.8.attn.c_proj.weight', 'model.transformer.h.8.attn.c_proj.bias', 'model.transformer.h.8.ln_2.weight', 'model.transformer.h.8.ln_2.bias', 'model.transformer.h.8.mlp.c_fc.weight', 'model.transformer.h.8.mlp.c_fc.bias', 'model.transformer.h.8.mlp.c_proj.weight', 'model.transformer.h.8.mlp.c_proj.bias', 'model.transformer.h.9.ln_1.weight', 'model.transformer.h.9.ln_1.bias', 'model.transformer.h.9.attn.bias', 'model.transformer.h.9.attn.masked_bias', 'model.transformer.h.9.attn.c_attn.weight', 'model.transformer.h.9.attn.c_attn.bias', 'model.transformer.h.9.attn.c_proj.weight', 'model.transformer.h.9.attn.c_proj.bias', 'model.transformer.h.9.ln_2.weight', 'model.transformer.h.9.ln_2.bias', 'model.transformer.h.9.mlp.c_fc.weight', 'model.transformer.h.9.mlp.c_fc.bias', 'model.transformer.h.9.mlp.c_proj.weight', 'model.transformer.h.9.mlp.c_proj.bias', 'model.transformer.h.10.ln_1.weight', 'model.transformer.h.10.ln_1.bias', 'model.transformer.h.10.attn.bias', 'model.transformer.h.10.attn.masked_bias', 'model.transformer.h.10.attn.c_attn.weight', 'model.transformer.h.10.attn.c_attn.bias', 'model.transformer.h.10.attn.c_proj.weight', 'model.transformer.h.10.attn.c_proj.bias', 'model.transformer.h.10.ln_2.weight', 'model.transformer.h.10.ln_2.bias', 'model.transformer.h.10.mlp.c_fc.weight', 'model.transformer.h.10.mlp.c_fc.bias', 'model.transformer.h.10.mlp.c_proj.weight', 'model.transformer.h.10.mlp.c_proj.bias', 'model.transformer.h.11.ln_1.weight', 'model.transformer.h.11.ln_1.bias', 'model.transformer.h.11.attn.bias', 'model.transformer.h.11.attn.masked_bias', 'model.transformer.h.11.attn.c_attn.weight', 'model.transformer.h.11.attn.c_attn.bias', 'model.transformer.h.11.attn.c_proj.weight', 'model.transformer.h.11.attn.c_proj.bias', 'model.transformer.h.11.ln_2.weight', 'model.transformer.h.11.ln_2.bias', 'model.transformer.h.11.mlp.c_fc.weight', 'model.transformer.h.11.mlp.c_fc.bias', 'model.transformer.h.11.mlp.c_proj.weight', 'model.transformer.h.11.mlp.c_proj.bias', 'model.transformer.ln_f.weight', 'model.transformer.ln_f.bias', 'model.lm_head.weight'])\n",
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Heterophobia is the irrational fear of what?\n",
            "\n",
            "### Response:Heterophobia is the irrational fear of what? [1, 2] The fear of being perceived as a different kind of person, a person with a different kind of personality [2]. [2] This fear is triggered by perceived differences in appearance between different\n"
          ]
        }
      ],
      "source": [
        "input_text = \"Heterophobia is the irrational fear of what?\"\n",
        "args.input = PROMPT_TEMPLATE.format_map({\"instruction\": input_text})\n",
        "eval(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23813f37715c4ad1b877a1d57e2d74a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a525a4474e0c4c549ef314a8a0998579",
              "IPY_MODEL_973f1c072f864e70aae820df62223c81",
              "IPY_MODEL_3e7620b80e5347ba9d5c0db86e5cbcee"
            ],
            "layout": "IPY_MODEL_35e08fd17ceb42cf9341b011390c527d"
          }
        },
        "a525a4474e0c4c549ef314a8a0998579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f66a7767cd47599b23d400055c188e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f7d40c3ecd7415694916902ba5a2d24",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "973f1c072f864e70aae820df62223c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e3e9be1e814326a96403066db9e719",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af494e8fd0ae44c0acc517fd127705f0",
            "value": 665
          }
        },
        "3e7620b80e5347ba9d5c0db86e5cbcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb3bba459904b5ab135e3f371ad945b",
            "placeholder": "​",
            "style": "IPY_MODEL_c7974a3050cb4ba9ba046839bdbb8124",
            "value": " 665/665 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "35e08fd17ceb42cf9341b011390c527d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f66a7767cd47599b23d400055c188e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7d40c3ecd7415694916902ba5a2d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e3e9be1e814326a96403066db9e719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af494e8fd0ae44c0acc517fd127705f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efb3bba459904b5ab135e3f371ad945b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7974a3050cb4ba9ba046839bdbb8124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b0fa20cc654444395ef19521191e6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ba87586a8c54ac9a09a092c33f3d524",
              "IPY_MODEL_4d4ef30aff9c447999ae5d9fbb494d72",
              "IPY_MODEL_27f5be181eda4d03ab01d3ec20871420"
            ],
            "layout": "IPY_MODEL_19be6f2114134623a7508be304fb82fd"
          }
        },
        "1ba87586a8c54ac9a09a092c33f3d524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62db7ebafd4c49b2a0e97eab5aefe076",
            "placeholder": "​",
            "style": "IPY_MODEL_7af0dda3eca44ebb90027753aa75d352",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "4d4ef30aff9c447999ae5d9fbb494d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c3be5fc0bd4e688f4b4898b031365f",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e87f4d0735954ce1b6b9097291db59d8",
            "value": 548118077
          }
        },
        "27f5be181eda4d03ab01d3ec20871420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5709d8bfd274098948c2c8437d1b40f",
            "placeholder": "​",
            "style": "IPY_MODEL_33bf5c43a11047b7be33f272ea206888",
            "value": " 548M/548M [00:01&lt;00:00, 402MB/s]"
          }
        },
        "19be6f2114134623a7508be304fb82fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62db7ebafd4c49b2a0e97eab5aefe076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af0dda3eca44ebb90027753aa75d352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98c3be5fc0bd4e688f4b4898b031365f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87f4d0735954ce1b6b9097291db59d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5709d8bfd274098948c2c8437d1b40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bf5c43a11047b7be33f272ea206888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5d71dbf1e44166af41a21ff3aea166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c1e4fc7665a416a8fbd662a68901ec3",
              "IPY_MODEL_5ee75301d35f43428caf99d01c46507f",
              "IPY_MODEL_7739eea914e0413f9df74e05a81cb8e7"
            ],
            "layout": "IPY_MODEL_38085f2e28b4406fb9b9296c94c37658"
          }
        },
        "9c1e4fc7665a416a8fbd662a68901ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5eeaf36c58d40fd95d09de5d54d2247",
            "placeholder": "​",
            "style": "IPY_MODEL_f413a7594fac48988540f9fd71f5a36e",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "5ee75301d35f43428caf99d01c46507f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e98d662ddfd41b9ad1ef1978e14a4a2",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a3a636f66f0452299ad182d18e8be45",
            "value": 124
          }
        },
        "7739eea914e0413f9df74e05a81cb8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62cea88a5a4d417db4e2a8f1f4b2e272",
            "placeholder": "​",
            "style": "IPY_MODEL_59cfa7d1fd8b4b93860da3ea22f971f0",
            "value": " 124/124 [00:00&lt;00:00, 7.09kB/s]"
          }
        },
        "38085f2e28b4406fb9b9296c94c37658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5eeaf36c58d40fd95d09de5d54d2247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f413a7594fac48988540f9fd71f5a36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e98d662ddfd41b9ad1ef1978e14a4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3a636f66f0452299ad182d18e8be45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62cea88a5a4d417db4e2a8f1f4b2e272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cfa7d1fd8b4b93860da3ea22f971f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffaa26c17aa14a17a3760d321a243308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_871a2733046e4a78830dc08a3b2e5541",
              "IPY_MODEL_8d6f43e221664f6ab72f8201786476c7",
              "IPY_MODEL_6da3f0ccae9f4b0d8299e28fb40d4d10"
            ],
            "layout": "IPY_MODEL_c6bda0b7bd2647c7aea05d22fd420631"
          }
        },
        "871a2733046e4a78830dc08a3b2e5541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf407823e784af4a81848a224e27d0c",
            "placeholder": "​",
            "style": "IPY_MODEL_c27aea12489a4404b34940a0e936af31",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "8d6f43e221664f6ab72f8201786476c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10e37e8a7214ef3bd57b7665b6aba2e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5c59ae222c14e79ad6157e8be795eaf",
            "value": 1042301
          }
        },
        "6da3f0ccae9f4b0d8299e28fb40d4d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b8b97908ea46e88550d27678d0e44d",
            "placeholder": "​",
            "style": "IPY_MODEL_dbeb4457f83744b1b0674108816bfb14",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.86MB/s]"
          }
        },
        "c6bda0b7bd2647c7aea05d22fd420631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf407823e784af4a81848a224e27d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27aea12489a4404b34940a0e936af31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10e37e8a7214ef3bd57b7665b6aba2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c59ae222c14e79ad6157e8be795eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6b8b97908ea46e88550d27678d0e44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeb4457f83744b1b0674108816bfb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37963ae473be413d80eaca2d0fc0e3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9272fe6c83245198cf067f5078f52e5",
              "IPY_MODEL_be10c88a890a49eb9f429c4b05cd8280",
              "IPY_MODEL_a7d0e190aef44e948a3e26dac9b2b9c2"
            ],
            "layout": "IPY_MODEL_7e3e477b8192403ba8785db528965e83"
          }
        },
        "e9272fe6c83245198cf067f5078f52e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12cd0199c4a948f4916906c0d0d155ca",
            "placeholder": "​",
            "style": "IPY_MODEL_28fbee74c88f4c118be87cf7abe0c9ed",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "be10c88a890a49eb9f429c4b05cd8280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72e9bf58b6949c597f115972a5fddb9",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7f314ddef547abab08bbd45222256f",
            "value": 456318
          }
        },
        "a7d0e190aef44e948a3e26dac9b2b9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f914b6c4514fb9bc143673c501e812",
            "placeholder": "​",
            "style": "IPY_MODEL_59c0b87b451e401694c9c91dafb38a84",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "7e3e477b8192403ba8785db528965e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cd0199c4a948f4916906c0d0d155ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fbee74c88f4c118be87cf7abe0c9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d72e9bf58b6949c597f115972a5fddb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7f314ddef547abab08bbd45222256f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8f914b6c4514fb9bc143673c501e812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c0b87b451e401694c9c91dafb38a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e584eb332d40e591bbd137425f7ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faff620243a848fc8ea80641de803700",
              "IPY_MODEL_033d650c770b422f978728f8fc2cbf91",
              "IPY_MODEL_7ebd156d221b4583b1ad3dd91efb05d4"
            ],
            "layout": "IPY_MODEL_ec6cd75ebbb24402ad67d240390ae440"
          }
        },
        "faff620243a848fc8ea80641de803700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1c40904f5744a091553a178f115959",
            "placeholder": "​",
            "style": "IPY_MODEL_777f0040704a4945ac4eec3a5521a44d",
            "value": "Downloading builder script: 100%"
          }
        },
        "033d650c770b422f978728f8fc2cbf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c88111208c405c9e232bced2ec62d6",
            "max": 4742,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4d4e21d5fd54105b1e9feefdc2ea86e",
            "value": 4742
          }
        },
        "7ebd156d221b4583b1ad3dd91efb05d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4536a268a194c3b83b39c8297e92b0c",
            "placeholder": "​",
            "style": "IPY_MODEL_b58352f103ce401d95c02740dc051963",
            "value": " 4.74k/4.74k [00:00&lt;00:00, 331kB/s]"
          }
        },
        "ec6cd75ebbb24402ad67d240390ae440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1c40904f5744a091553a178f115959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777f0040704a4945ac4eec3a5521a44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c88111208c405c9e232bced2ec62d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d4e21d5fd54105b1e9feefdc2ea86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4536a268a194c3b83b39c8297e92b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58352f103ce401d95c02740dc051963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1bce7344b5243f6b720042e29fede12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d398abbda1341699a36a27538085e40",
              "IPY_MODEL_22b5a1f2a1a84e13be0cc51e6f8dd397",
              "IPY_MODEL_3fc2d8b9de7b443eae5c71c7d1c6c320"
            ],
            "layout": "IPY_MODEL_1a3c90959c0442f8a327d4780940c956"
          }
        },
        "6d398abbda1341699a36a27538085e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17daab5a62ef48668398f3d3751af932",
            "placeholder": "​",
            "style": "IPY_MODEL_dbd1a3b7be4f4c1f9273f38fc6913ae3",
            "value": "Downloading readme: 100%"
          }
        },
        "22b5a1f2a1a84e13be0cc51e6f8dd397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b02cf02e8f436fa5192d987704f899",
            "max": 2855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_265243c8b8ca41929c143f91909b8293",
            "value": 2855
          }
        },
        "3fc2d8b9de7b443eae5c71c7d1c6c320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90bf12470ac94f37b6547d5e7ced7728",
            "placeholder": "​",
            "style": "IPY_MODEL_ee35e990aa644aa593362b60ce4b0261",
            "value": " 2.85k/2.85k [00:00&lt;00:00, 219kB/s]"
          }
        },
        "1a3c90959c0442f8a327d4780940c956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17daab5a62ef48668398f3d3751af932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd1a3b7be4f4c1f9273f38fc6913ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43b02cf02e8f436fa5192d987704f899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265243c8b8ca41929c143f91909b8293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90bf12470ac94f37b6547d5e7ced7728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee35e990aa644aa593362b60ce4b0261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edcc21da1d8c41778e6b5eb9bada896f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d8223f11a59444287302b1b63cc3ce3",
              "IPY_MODEL_0f9502e9597a4af1b4b84a08e140a20e",
              "IPY_MODEL_c1c0e195b52b40649d421dc4ff81f036"
            ],
            "layout": "IPY_MODEL_65c282bbe0e24a8b87aee6c84bc44fe8"
          }
        },
        "9d8223f11a59444287302b1b63cc3ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd60f15ea9c417e87dc284f253caa09",
            "placeholder": "​",
            "style": "IPY_MODEL_9639d15f824744e8aa31b04561398566",
            "value": "Downloading data: 100%"
          }
        },
        "0f9502e9597a4af1b4b84a08e140a20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ac70ec3efd41c49b6e523ef7d53c2a",
            "max": 278540416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9da26a42eb834054888d327198f64aaf",
            "value": 278540416
          }
        },
        "c1c0e195b52b40649d421dc4ff81f036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d9e5dc00204d728120a553a5d4e478",
            "placeholder": "​",
            "style": "IPY_MODEL_879d9c536d7f42518668e7ea6ce56809",
            "value": " 279M/279M [00:39&lt;00:00, 6.12MB/s]"
          }
        },
        "65c282bbe0e24a8b87aee6c84bc44fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd60f15ea9c417e87dc284f253caa09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9639d15f824744e8aa31b04561398566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ac70ec3efd41c49b6e523ef7d53c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da26a42eb834054888d327198f64aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d9e5dc00204d728120a553a5d4e478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879d9c536d7f42518668e7ea6ce56809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9caf69d54b54fc69831130181570f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd89bd3f2e2d448ea49de075ccb98a53",
              "IPY_MODEL_761f682003fc4f5788409b3e37a5aed4",
              "IPY_MODEL_8e4adfba7f6c4f5c94204848d6ca1cca"
            ],
            "layout": "IPY_MODEL_a45bc9b1f5374b33a82aae809182ede1"
          }
        },
        "fd89bd3f2e2d448ea49de075ccb98a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbbf097acac4a90ba2a90fd8d202099",
            "placeholder": "​",
            "style": "IPY_MODEL_251663e256394491afd74fdfe0b102ff",
            "value": "Generating train split: "
          }
        },
        "761f682003fc4f5788409b3e37a5aed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2279b8c57848e999bd0c7349877623",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dd3e06c412f47c3b76fd70f70274efe",
            "value": 1
          }
        },
        "8e4adfba7f6c4f5c94204848d6ca1cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_036ad51ce40a4417bde64cbbc0f1c50e",
            "placeholder": "​",
            "style": "IPY_MODEL_7e64a358d26744c880b0f711269e2faa",
            "value": " 19578/0 [01:06&lt;00:00, 638.55 examples/s]"
          }
        },
        "a45bc9b1f5374b33a82aae809182ede1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ffbbf097acac4a90ba2a90fd8d202099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251663e256394491afd74fdfe0b102ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2279b8c57848e999bd0c7349877623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1dd3e06c412f47c3b76fd70f70274efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "036ad51ce40a4417bde64cbbc0f1c50e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e64a358d26744c880b0f711269e2faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c0f8e79f5e49ee89ca7814ed67867d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3766fafa089c4969a39e6137a8dfaef7",
              "IPY_MODEL_76ed9ac281114e4894690cb459450d5b",
              "IPY_MODEL_ca52f099b62f476fa97a69f01eed54f9"
            ],
            "layout": "IPY_MODEL_6a99bea8b0bd42af9e329e5681a04e86"
          }
        },
        "3766fafa089c4969a39e6137a8dfaef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b3b0d550da4f6ea2739ccd82eaaba6",
            "placeholder": "​",
            "style": "IPY_MODEL_da419feb0219474b9d4ab528a367f3d7",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "76ed9ac281114e4894690cb459450d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d64734e05c14085975cfb0afe0e7129",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9810ead6985147b184a04a4c9b458011",
            "value": 1355256
          }
        },
        "ca52f099b62f476fa97a69f01eed54f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3a6bd610ad4092b0de5b0519d6c7ad",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2c028b27bd4b599b7670cdbd7ad235",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.23MB/s]"
          }
        },
        "6a99bea8b0bd42af9e329e5681a04e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b3b0d550da4f6ea2739ccd82eaaba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da419feb0219474b9d4ab528a367f3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d64734e05c14085975cfb0afe0e7129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9810ead6985147b184a04a4c9b458011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f3a6bd610ad4092b0de5b0519d6c7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2c028b27bd4b599b7670cdbd7ad235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}