{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louiezzang/next-gpt/blob/main/examples/chatgpt_replica_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o5OIi7jDa9K"
      },
      "source": [
        "# chatGPT replica\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TMz3aiLECTk"
      },
      "source": [
        "What is RLHF? <br>\n",
        "See [this link](https://gist.github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093).\n",
        "\n",
        "<br>\n",
        "\n",
        "**Example of RLHF dataset**:\n",
        "\n",
        "Total 3 datasets are needed for training the 3 steps(SFT, RM and PPO)\n",
        "- [Example of dataset](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama#dataset-preparation)\n",
        "- [Example of dataset 1](https://huggingface.co/datasets/stanfordnlp/SHP)\n",
        "- [Example of dataset 2](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n",
        "\n",
        "step1) Dataset for SFT(Supervised Fine-tuning training)\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion\": \"\"        \n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "\n",
        "step2) Dataset for RM(Reward Model) training: There are multiple completetions with human rated ranking score for one prompt.\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion_1\": \"\",\n",
        "        \"completion_2\": \"\",\n",
        "        \"completion_3\": \"\",            \n",
        "        \"ranking\": [1, 0, 2]\n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "    \n",
        "step3) Dataset for PPO(RLHF) training: It only consists of prompt.\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\"\n",
        "    }, ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_5Fvkx9fH0"
      },
      "source": [
        "# Colab environment setup\n",
        "\n",
        "#### Installation (python>=3.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdbMmQE5Zsjw",
        "outputId": "0345f3e0-1e54-413a-93a4-bd2e17a70feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'next-gpt'...\n",
            "remote: Enumerating objects: 564, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 564 (delta 104), reused 147 (delta 68), pack-reused 348\u001b[K\n",
            "Receiving objects: 100% (564/564), 195.64 KiB | 7.83 MiB/s, done.\n",
            "Resolving deltas: 100% (272/272), done.\n",
            "/content/next-gpt\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/next-gpt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (4.27.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (2.11.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (0.1.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (from next-gpt==1.0.0) (0.0.133)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (2023.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (0.13.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets->next-gpt==1.0.0) (23.0)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (1.2.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (0.5.7)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (1.4.47)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (8.2.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->next-gpt==1.0.0) (1.10.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->next-gpt==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->next-gpt==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->next-gpt==1.0.0) (3.10.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->next-gpt==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->next-gpt==1.0.0) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->next-gpt==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->next-gpt==1.0.0) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->next-gpt==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->next-gpt==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain->next-gpt==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->next-gpt==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->next-gpt==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->next-gpt==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->next-gpt==1.0.0) (1.0.0)\n",
            "Building wheels for collected packages: next-gpt\n",
            "  Building wheel for next-gpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for next-gpt: filename=next_gpt-1.0.0-py3-none-any.whl size=58894 sha256=d809070da201811a3213cffde44e0c6227b4eca5aaf39055f8eedfbd35b617e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/0d/a2/307ec9a6214260bfd63facee827d7bbef5c1ba9618277ea1b5\n",
            "Successfully built next-gpt\n",
            "Installing collected packages: next-gpt\n",
            "  Attempting uninstall: next-gpt\n",
            "    Found existing installation: next-gpt 1.0.0\n",
            "    Uninstalling next-gpt-1.0.0:\n",
            "      Successfully uninstalled next-gpt-1.0.0\n",
            "Successfully installed next-gpt-1.0.0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Install next-gpt lib.\n",
        "!rm -rf ./next-gpt/\n",
        "!git clone https://github.com/louiezzang/next-gpt.git\n",
        "%cd next-gpt/\n",
        "!pip install .\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JezJ8wz3_A7B"
      },
      "source": [
        "# Step 1) SFT: Surpervised Fine-tuning\n",
        "Build a Supervised Fine-tuning model to answer well to the question.\n",
        "\n",
        "- Refereneces\n",
        "  - [fine tuning code_1](https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb)\n",
        "  - [fine tuning code_2](https://github.com/Beomi/KoAlpaca/blob/main/train.py)\n",
        "\n",
        "\n",
        "- SFT(Supervised Fine Tuning)\n",
        "- Fine-tune a pretrained LLM on a specific domain or corpus of instructions and human demonstrations\n",
        "\n",
        "- Dataset example\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion\": \"\"        \n",
        "    }, ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fpoPqaBfAkqW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import json\n",
        "import yaml\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline, \n",
        "    TrainingArguments, AutoModelWithLMHead,\n",
        "    ProgressCallback\n",
        ")\n",
        "from nextgpt.finetuning import (\n",
        "    SupervisedDataset, DataCollatorForSupervisedDataset,\n",
        "    SupervisedTrainer, LoggingCallback\n",
        ")\n",
        "\n",
        "PT_MODEL_NAME = \"gpt2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define arguments.\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"gpt2\", choices=[\"gpt2'\", \"bloom\", \"opt\"])\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=1)\n",
        "parser.add_argument(\"--train_batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"./output_1_sft\")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "print(args)"
      ],
      "metadata": {
        "id": "FVXvBXyhPxwf",
        "outputId": "3a3c96c3-de85-4576-faed-a38e5f22220a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(model_name='gpt2', max_epochs=1, train_batch_size=4, output_dir='./output_1_sft')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9M1fZh_A80h",
        "outputId": "8b95fdde-8c34-4916-90b3-e0d4a5eadd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'})\n"
          ]
        }
      ],
      "source": [
        "# Get the tokenizer.\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name, \n",
        "                                          bos_token=\"<|startoftext|>\",\n",
        "                                          eos_token=\"<|endoftext|>\", \n",
        "                                          pad_token=\"<|pad|>\")\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vji8AkHflB0b",
        "outputId": "5894435b-8d67-4181-dfac-d2e3a9b12fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset webgpt_comparisons (/root/.cache/huggingface/datasets/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)\n"
          ]
        }
      ],
      "source": [
        "dataset_webgpt_comp = load_dataset(\"openai/webgpt_comparisons\", split=\"train[:20%]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "azsnYbQtmQ3j"
      },
      "outputs": [],
      "source": [
        "data_list = []\n",
        "for row in dataset_webgpt_comp:\n",
        "  question = row[\"question\"][\"full_text\"]\n",
        "  answer_0 = row[\"answer_0\"]\n",
        "  data_list.append({\n",
        "      \"prompt\": question,\n",
        "      \"completion\": answer_0\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i4bLuGNRlh9-"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = (\n",
        "  \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n\"\n",
        "  \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "  \"### Instruction:\\n{prompt}\\n\\n### Response:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NhIhWL0lAVp",
        "outputId": "ec8d77cc-7918-403d-bf2b-33bb9087c38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3916/3916 [00:00<00:00, 221622.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context.\n",
            "\n",
            "Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Voiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?\n",
            "\n",
            "### Response:\n",
            "The Simpsons character that was possibly based on Ted Koppel is Kent Brockman.  He is a local news anchor in Springfield and is modeled after Ted Koppel. [1]<|endoftext|>\n",
            "Tokenizing inputs... This may take some time...\n",
            "Loading data done!!: 3916\n"
          ]
        }
      ],
      "source": [
        "dataset = SupervisedDataset(\n",
        "    data=data_list,\n",
        "    tokenizer=tokenizer, \n",
        "    prompt_template=PROMPT_TEMPLATE,\n",
        "    completion_field=\"completion\",\n",
        "    verbose=True)\n",
        "\n",
        "# Split train and val dataset.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Data collator.\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_9-GV97sf9O",
        "outputId": "c320fe3e-1152-4bff-d9a3-8ace909b473e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load the pretrained model.\n",
        "model = AutoModelForCausalLM.from_pretrained(args.model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "XRbskFS7sq84",
        "outputId": "05dc163a-adc1-459b-abd6-6893bed0e775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='321' max='783' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [321/783 02:27 < 03:33, 2.17 it/s, Epoch 0.41/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train arguments.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./train_1_sft\", # the output directory\n",
        "    overwrite_output_dir=True, # overwrite the content of the output directory\n",
        "    num_train_epochs=args.max_epochs, # number of training epochs\n",
        "    per_device_train_batch_size=args.train_batch_size, # batch size for training\n",
        "    per_device_eval_batch_size=4, # batch size for evaluation\n",
        "    eval_steps=3, # number of update steps between two evaluations.\n",
        "    save_steps=100, # after # steps model is saved \n",
        "    warmup_steps=5, # number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "trainer = SupervisedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=None,\n",
        "    # callbacks=[ProgressCallback, LoggingCallback(logger=None)],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_state()\n",
        "trainer.safe_save_model(output_dir=args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhp5IFF0vQ-m"
      },
      "outputs": [],
      "source": [
        "# Inference test.\n",
        "generator = pipeline(\"text-generation\", model=args.output_dir, tokenizer=tokenizer)\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    # bos_token=\"<|startoftext|>\",\n",
        "    # eos_token=\"<|endoftext|>\", \n",
        "    # pad_token=\"<|pad|>\",\n",
        "    max_new_tokens=64,\n",
        "    do_sample=True,\n",
        "    top_k=30,\n",
        "    top_p=0.95,\n",
        "    temperature=1.9, \n",
        "    #max_length=300, \n",
        "    #num_return_sequences=20\n",
        "    early_stopping=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rnWI0iWwLb1"
      },
      "outputs": [],
      "source": [
        "test_list = data_list[-5:]\n",
        "\n",
        "test_prompt_list = []\n",
        "actual_completion_list = []\n",
        "for row in test_list:\n",
        "    text_input = row\n",
        "    prompt = PROMPT_TEMPLATE.format_map(text_input)\n",
        "    test_prompt_list.append(prompt)\n",
        "    actual_completion_list.append(text_input[\"completion\"])\n",
        "\n",
        "result_list = generator(test_prompt_list, **generation_args)\n",
        "for prompt, result, actual_response in zip(test_prompt_list, result_list, actual_completion_list):\n",
        "    print(\"\")\n",
        "    print(\"-\" * 70)\n",
        "    print((\"completion: %s\" % (result[0][\"generated_text\"])))\n",
        "    print(f\"\\n### Actual answer:\\n{actual_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2) RM: Reward Model\n",
        "Train Reward Model to generate the better answer by giving a reward to the better answer.\n",
        "- Dataset example\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"prompt\": \"\",\n",
        "        \"completion_1\": \"\",\n",
        "        \"completion_2\": \"\",\n",
        "        \"completion_3\": \"\",            \n",
        "        \"ranking\": [1, 0, 2]\n",
        "    }, ...\n",
        "]\n",
        "```\n",
        "- Dataset sources\n",
        "  - [Dahoas/rm-static](https://huggingface.co/datasets/Dahoas/rm-static)\n",
        "  - [openai/webgpt_comparisons](https://huggingface.co/datasets/openai/webgpt_comparisons)\n",
        "  - [openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)\n",
        "  - [Dahoas/instruct-synthetic-prompt-responses](https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise)\n",
        "\n",
        "- References\n",
        "    - [train_reward_model.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_reward_model.py)\n",
        "    - [train_prompts.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py)"
      ],
      "metadata": {
        "id": "8JoJpv-wAvY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "import loralib as lora\n",
        "\n",
        "from nextgpt.rlhf.dataset import RewardDataset\n",
        "from nextgpt.rlhf.models.base import RewardModel\n",
        "from nextgpt.rlhf.models.bloom import BLOOMRM\n",
        "from nextgpt.rlhf.models.gpt import GPTRM\n",
        "from nextgpt.rlhf.models.opt import OPTRM\n",
        "from nextgpt.rlhf.models import LogExpLoss, LogSigLoss\n",
        "from nextgpt.rlhf.trainer import RewardModelTrainer\n",
        "from nextgpt.rlhf.trainer.strategies import DDPStrategy, NaiveStrategy"
      ],
      "metadata": {
        "id": "esYui6hPCuF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define arguments.\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--output_dir\", type=str, default=\"/output_2_rm\")\n",
        "parser.add_argument(\"--strategy\",\n",
        "                    choices=[\"naive\", \"ddp\"],\n",
        "                    default=\"naive\")\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"gpt2\", choices=[\"gpt2\", \"bloom\", \"opt\"])\n",
        "parser.add_argument(\"--pretrain\", type=str, default=\"gpt2\")\n",
        "parser.add_argument(\"--model_path\", type=str, default=None)\n",
        "parser.add_argument('--need_optim_ckpt', type=bool, default=False)\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--lora_rank\", type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument(\"--loss_fn\", type=str, default=\"log_sig\", choices=[\"log_sig\", \"log_exp\"])\n",
        "parser.add_argument(\"--max_len\", type=int, default=512)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# For test.\n",
        "args.max_epochs = 3\n",
        "args.pretrain = \"gpt2\" # pretrained initial model.\n",
        "args.max_len = 1024\n",
        "args.verbose = True\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ],
      "metadata": {
        "id": "WGnVyFvLSAjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure strategy.\n",
        "if args.strategy == \"naive\":\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == \"ddp\":\n",
        "    strategy = DDPStrategy()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported strategy: {args.strategy}\")"
      ],
      "metadata": {
        "id": "KHEdwfvCwZTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure model, tokenizer.\n",
        "with strategy.model_init_context():\n",
        "    # Load pretrained gpt2.\n",
        "    if args.model_name == \"gpt2\":\n",
        "        # Get the tokenizer.\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "            args.model_name, \n",
        "            bos_token=\"<|startoftext|>\",\n",
        "            eos_token=\"<|endoftext|>\", \n",
        "            pad_token=\"<|pad|>\",\n",
        "            padding_side=\"right\", \n",
        "            model_max_length=args.max_len,\n",
        "            )\n",
        "        print(tokenizer)\n",
        "        model = GPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "        model.resize_token_embeddings(len(tokenizer)) \n",
        "    elif args.model == \"bloom\":\n",
        "        model = BLOOMRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)\n",
        "    elif args.model == \"opt\":\n",
        "        model = OPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")      \n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {args.model_name}\")\n",
        "\n",
        "    # Load the supervised finetuning model state dict if it is specified.\n",
        "    # However, we will train the reward model from the initial language model instead of supervised finetuning model.\n",
        "    if args.model_path is not None:\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        state_dict = torch.load(args.model_path)\n",
        "        model.model.load_state_dict(state_dict)\n",
        "\n",
        "    # This float16 or `model.half()` might cause loss NaN issue!!!\n",
        "    # See:\n",
        "    #   https://stackoverflow.com/questions/65332165/loss-is-nan-when-fine-tuning-huggingface-nli-model-both-roberta-bart\n",
        "    #   https://github.com/huggingface/transformers/issues/9160\n",
        "    model = model.to(torch.float16)"
      ],
      "metadata": {
        "id": "jnR1YKD2Zuyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset.\n",
        "dataset_webgpt_comp = load_dataset(\"openai/webgpt_comparisons\", split=\"train[:20%]\")"
      ],
      "metadata": {
        "id": "JQU-3QqH65FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data into ranking format.\n",
        "data_list_ranking = []\n",
        "for row in dataset_webgpt_comp:\n",
        "    question = row[\"question\"][\"full_text\"]\n",
        "    answer_0 = row[\"answer_0\"]\n",
        "    answer_1 = row[\"answer_1\"]\n",
        "    score_0 = row[\"score_0\"]\n",
        "    score_1 = row[\"score_1\"]\n",
        "    if answer_0 == \"\" or answer_1 == \"\" or (score_0 == score_1):\n",
        "        continue\n",
        "\n",
        "    ranking = [0 if score_0 > score_1 else 1, 0 if score_0 < score_1 else 1]\n",
        "    data_list_ranking.append({\n",
        "        \"prompt\": PROMPT_TEMPLATE.format_map({\"prompt\": question}),\n",
        "        \"completion_0\": answer_0,\n",
        "        \"completion_1\": answer_1,\n",
        "        \"ranking\": ranking\n",
        "    })\n",
        "\n",
        "data_list_ranking[:2]"
      ],
      "metadata": {
        "id": "x2H18pYX7akp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make ranking data to chosen, rejetced data for reward model dataset.\n",
        "total_data_ranking2chosen = []\n",
        "for tmp in data_list_ranking:\n",
        "    one_data_ranking2chosen = []\n",
        "\n",
        "    # data 1) 0 VS 1\n",
        "    data = {}\n",
        "    data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    if tmp[\"ranking\"][0] < tmp[\"ranking\"][1]:\n",
        "        data[\"chosen\"] = tmp[\"completion_0\"]\n",
        "        data[\"rejected\"] = tmp[\"completion_1\"]\n",
        "    else:\n",
        "        data[\"chosen\"] = tmp[\"completion_1\"]\n",
        "        data[\"rejected\"] = tmp[\"completion_0\"]\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # # data 2) 0 VS 2\n",
        "    # data = {}\n",
        "    # data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    # if tmp[\"ranking\"][0] < tmp[\"ranking\"][2]:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_0\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_2\"]\n",
        "    # else:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_2\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_0\"]\n",
        "    # one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # # data 1) 1 VS 2\n",
        "    # data = {}\n",
        "    # data[\"prompt\"] = tmp[\"prompt\"]\n",
        "    # if tmp[\"ranking\"][1] < tmp[\"ranking\"][2]:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_1\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_2\"]\n",
        "    # else:\n",
        "    #     data[\"chosen\"] = tmp[\"completion_2\"]\n",
        "    #     data[\"rejected\"] = tmp[\"completion_1\"]\n",
        "    # one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
        "\n",
        "\n",
        "print(\"before data num: %d\" % (len(data_list_ranking)))\n",
        "print(\"after data num: %d\" % (len(total_data_ranking2chosen)))\n",
        "print(\"data example: \\n%s\" % total_data_ranking2chosen[1])"
      ],
      "metadata": {
        "id": "DeTW6fIE_c2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for data and dataset.\n",
        "import random\n",
        "random.seed(230319)\n",
        "\n",
        "random.shuffle(total_data_ranking2chosen)\n",
        "print(total_data_ranking2chosen[1])\n",
        "\n",
        "# train_data = total_data_ranking2chosen[:-1000]\n",
        "# eval_data = total_data_ranking2chosen[-1000:0]\n",
        "# We just select very small set of data for a quicker training.\n",
        "train_data = total_data_ranking2chosen[:100]\n",
        "val_data = total_data_ranking2chosen[100:130]\n",
        "eval_data = total_data_ranking2chosen[130:160]\n",
        "\n",
        "train_dataset = RewardDataset(train_data, tokenizer, args.max_len)\n",
        "val_dataset = RewardDataset(val_data, tokenizer, args.max_len)\n",
        "eval_dataset = RewardDataset(eval_data, tokenizer, args.max_len)\n",
        "\n",
        "# Check\n",
        "idx = 10\n",
        "print(\"#\" * 70)\n",
        "print(\"## prompt ##\")\n",
        "print(train_data[idx][\"prompt\"])\n",
        "print(\"#\" * 70)\n",
        "print(\"## chosen ##\")\n",
        "print(train_data[idx][\"chosen\"])\n",
        "print(\"#\" * 70)\n",
        "print(\"## rejected ##\")\n",
        "print(train_data[idx][\"rejected\"])"
      ],
      "metadata": {
        "id": "o1FpHo5jAf81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure optimizer.\n",
        "optim = Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Configure loss function.\n",
        "if args.loss_fn == \"log_sig\":\n",
        "    loss_fn = LogSigLoss()\n",
        "elif args.loss_fn == \"log_exp\":\n",
        "    loss_fn = LogExpLoss()\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported loss function: {args.loss_fn}\")"
      ],
      "metadata": {
        "id": "JqCnhM_SXw9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = RewardModelTrainer(model=model,\n",
        "                            strategy=strategy,\n",
        "                            optim=optim,\n",
        "                            loss_fn=loss_fn,\n",
        "                            train_dataset=train_dataset,\n",
        "                            valid_dataset=val_dataset,\n",
        "                            eval_dataset=eval_dataset,\n",
        "                            batch_size=args.batch_size,\n",
        "                            max_epochs=args.max_epochs)"
      ],
      "metadata": {
        "id": "tC6Sf3qMX2A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train!!!\n",
        "trainer.fit()\n",
        "\n",
        "# Save model checkpoint after fitting on only rank0.\n",
        "# strategy.save_model(model, os.path.join(args.output_dir, \"rm.pt\"), only_rank0=True)\n",
        "trainer.save_model(path=os.path.join(args.output_dir, \"rm.pt\"), only_rank0=True)\n",
        "\n",
        "# Save optimizer checkpoint on all ranks.\n",
        "if args.need_optim_ckpt:\n",
        "    strategy.save_optimizer(trainer.optimizer,\n",
        "                            os.path.join(args.output_dir, \"rm_optim_checkpoint_%d.pt\" % (torch.cuda.current_device())),\n",
        "                            only_rank0=False)"
      ],
      "metadata": {
        "id": "WJO46OBraGOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3) PPO: Proximal Policy Optimization\n",
        "Further fine-tune the LLM from step 1 with the reward model and this dataset using RL (eg. PPO).\n",
        "\n",
        "- References\n",
        "    - [train_prompts.py](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py)"
      ],
      "metadata": {
        "id": "EI7qm5N262EZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}